from django.contrib.auth import authenticate, login, logout
from django.shortcuts import render, redirect, get_object_or_404
from django.contrib.auth.forms import AuthenticationForm
from django.contrib.auth.decorators import login_required
from .decorators import role_required
from django.http import JsonResponse
from django.db.models import Q, Count, F
from django.utils.timezone import now, timedelta
from supplies.models import ContainerUnloadingZone2Inspection as Inspection, Post, Detail, Defect
from .models import Notification, HelpdeskContact, ExportHistory, Selection, Employee, CustomUser, OvertimeRecord, KTVDefect
from django.http import HttpResponse
from supplies.models import ContainerUnloadingZoneSBInspection
from supplies.forms import MainUnloadingZoneDKDForm, BodyUnloadingZoneDKDForm
from assembly.forms import AssemblyTemplateForm
from vehicle_history.models import VINHistory, VINHistoryBackup, ContainerHistory, AssemblyPassLog, VESPassLog
from django.db.models.functions import Lower
from django.db.models import Q
from django.urls import reverse
from django.utils.dateparse import parse_datetime
from django.utils import timezone
from django.utils.dateparse import parse_date
from collections import Counter
import json
from .forms import (ControllerCreationForm, ControllerPasswordChangeForm, ProfileUpdateForm, EmployeeSearchForm,
                    EmployeeSelectionForm, CustomPasswordChangeForm, ControllerEditForm,
                    AssemblyZoneForm, AssemblyUnitForm, AssemblyDefectForm)
from assembly.models import AssemblyZone, AssemblyUnit, AssemblyDefect, PostAssembly
from django.contrib.auth import get_user_model
from django.contrib import messages
from collections import defaultdict
from datetime import datetime, date, time
from supplies.models import Post, BodyDetail, Defect, DefectGrade, DefectResponsible
from django.conf import settings
import os
from vehicle_history.utils import now_almaty_iso
from supplies.models import TraceData
from django.contrib.auth.forms import PasswordChangeForm
from django.contrib.auth import update_session_auth_hash
from django.utils.timezone import localtime
from django.contrib.auth.decorators import login_required
from django.shortcuts import render
from datetime import datetime, time
from django.utils.timezone import make_aware
from PIL import Image, ImageOps
from io import BytesIO
from django.core.files.uploadedfile import InMemoryUploadedFile
import sys
from django.utils.dateparse import parse_datetime
from django.utils.timezone import get_current_timezone
from datetime import timedelta
import pandas as pd
import urllib.parse  # –¥–ª—è urlencode
import openpyxl
from openpyxl.styles import Alignment, Border, Side, Font
from docx import Document
from urllib.parse import quote
from django.http import HttpResponseForbidden
import io
from openpyxl.styles import Alignment, Font
from openpyxl.utils import get_column_letter
from users.reports.report_generator import generate_summary_report
from itertools import chain
from django.db import IntegrityError, transaction
from django.views.decorators.http import require_POST
from django.core.serializers.json import DjangoJSONEncoder
from datetime import datetime
from django.contrib.auth.decorators import login_required
from django.shortcuts import render
from django.utils.timezone import localdate
from django.http import JsonResponse, HttpResponseBadRequest, HttpResponseNotAllowed
from django.views.decorators.http import require_POST, require_http_methods
from django.contrib.auth import authenticate, login, logout
from django.shortcuts import render, redirect, get_object_or_404
from django.contrib.auth.forms import AuthenticationForm
from django.contrib.auth.decorators import login_required
from .decorators import role_required
from django.http import JsonResponse
from django.db.models import Q, Count, F
from django.utils.timezone import now, timedelta
from supplies.models import ContainerUnloadingZone2Inspection as Inspection, Post, Detail, Defect
from .models import Notification, HelpdeskContact, ExportHistory, Selection, Employee, CustomUser, OvertimeRecord
from django.http import HttpResponse
from supplies.models import ContainerUnloadingZoneSBInspection
from supplies.forms import MainUnloadingZoneDKDForm, BodyUnloadingZoneDKDForm
from assembly.forms import AssemblyTemplateForm
from vehicle_history.models import VINHistory, VINHistoryBackup
from django.db.models.functions import Lower
from django.db.models import Q
from django.urls import reverse
from django.utils.dateparse import parse_datetime
from django.utils import timezone
from django.utils.dateparse import parse_date
from collections import Counter
import json
from .forms import (ControllerCreationForm, ControllerPasswordChangeForm, ProfileUpdateForm, EmployeeSearchForm,
                    EmployeeSelectionForm, CustomPasswordChangeForm, ControllerEditForm,
                    AssemblyZoneForm, AssemblyUnitForm, AssemblyDefectForm)
from assembly.models import AssemblyZone, AssemblyUnit, AssemblyDefect, PostAssembly
from django.contrib.auth import get_user_model
from django.contrib import messages
from collections import defaultdict
from datetime import datetime, date, time
from supplies.models import Post, BodyDetail, Defect, DefectGrade, DefectResponsible
from django.conf import settings
import os
from vehicle_history.utils import now_almaty_iso
from supplies.models import TraceData
from django.contrib.auth.forms import PasswordChangeForm
from django.contrib.auth import update_session_auth_hash
from django.utils.timezone import localtime
from django.contrib.auth.decorators import login_required
from django.shortcuts import render
from datetime import datetime, time
from django.utils.timezone import make_aware
from PIL import Image, ImageOps
from io import BytesIO
from django.core.files.uploadedfile import InMemoryUploadedFile
import sys
from django.utils.dateparse import parse_datetime
from django.utils.timezone import get_current_timezone
from datetime import timedelta
import pandas as pd
import urllib.parse  # –¥–ª—è urlencode
import openpyxl
from openpyxl.styles import Alignment, Border, Side, Font
from docx import Document
from urllib.parse import quote
from django.http import HttpResponseForbidden
import io
from openpyxl.styles import Alignment, Font
from openpyxl.utils import get_column_letter
from users.reports.report_generator import generate_summary_report
from itertools import chain
from django.db import IntegrityError, transaction
from django.views.decorators.http import require_POST
from django.core.serializers.json import DjangoJSONEncoder
import re
from django.db import DatabaseError
from django.db.models import Q, F, Value, CharField
from django.db.models.functions import Lower
from django.db.models import Func
from qrr.views import QRR_WHITELIST_USERS, ensure_qrr_or_whitelist
from django.urls import resolve, Resolver404
from urllib.parse import urlparse, parse_qs
from django.core.exceptions import PermissionDenied
from django.contrib.auth.decorators import permission_required



MASTER_DASHBOARD_PERMISSION = f"{CustomUser._meta.app_label}.access_to_the_master_dashboard"
APP_LABEL = CustomUser._meta.app_label


# –£–¥–∞–ª—è–µ—Ç –≤—Å–µ –Ω–µ—Ü–∏—Ñ—Ä—ã
def normalize_digits(s: str) -> str:
    return re.sub(r"\D+", "", s or "")



# –ê–Ω–∞–ª–æ–≥ PostgreSQL REGEXP_REPLACE(text, pattern, replacement, flags)
class RegexReplace(Func):
    function = "REGEXP_REPLACE"
    arity = 4  # text, pattern, replacement, flags
    output_field = CharField()


few_roles = ['m.adylbayev', 't.tokshekenov', 'ai.kaldybek', 'lidacain', 'p.kalinin', 'e.fedorova']


# === –ù–µ–¥–∞–≤–Ω–∏–µ –ø–æ—Å—Ç—ã —Å–±–æ—Ä–∫–∏ (—Ö—Ä–∞–Ω–∏–º –≤ —Å–µ—Å—Å–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è) ===
RECENT_POST_LABELS = {
    "assembly:gaps_and_drops": "–ó–∞–∑–æ—Ä—ã –∏ –ø–µ—Ä–µ–ø–∞–¥—ã",
    "assembly:exterior": "–≠–∫—Å—Ç–µ—Ä—å–µ—Ä",
    "assembly:interior": "–ò–Ω—Ç–µ—Ä—å–µ—Ä",
    "assembly:trunk": "–ë–∞–≥–∞–∂–Ω–∏–∫",
    "assembly:the_motor": "–ú–æ—Ç–æ—Ä–Ω—ã–π –æ—Ç—Å–µ–∫",
    "assembly:functional": "–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª",
    "assembly:geometry_of_wheels": "–ì–µ–æ–º–µ—Ç—Ä–∏—è –∫–æ–ª–µ—Å",
    "assembly:adjusting_the_headlights_and_calibrating_the_steering_wheel": "–†–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ —Å–≤–µ—Ç–∞ —Ñ–∞—Ä –∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ä—É–ª—è",
    "assembly:breaking_system": "–¢–æ—Ä–º–æ–∑–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞",
    "assembly:underbody": "Underbody",
    "assembly:adas_chery": "ADAS (Chery)",
    "assembly:adas_gwm": "ADAS (GWM)",
    "assembly:adas_changan": "ADAS (Changan)",
    "assembly:avm_chery": "AVM (Chery)",
    "assembly:avm_gwm": "AVM (GWM)",
    "assembly:avm_changan": "AVM (Changan)",
    "assembly:tightness_of_the_body": "–ì–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –∫—É–∑–æ–≤–∞",
    "assembly:diagnostics": "–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞",
    "assembly:test_track": "–¢–µ—Å—Ç —Ç—Ä–µ–∫",
    "assembly:documentation": "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è",
    "assembly:final_current_control_chery": "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å (Chery)",
    "assembly:final_current_control_gwm": "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å (GWM)",
    "assembly:final_current_control_changan": "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å (Changan)",
    "assembly:chassis_chery": "Chassis (Chery)",
    "assembly:chassis_gwm": "Chassis (GWM)",
    "assembly:chassis_changan": "Chassis (Changan)",
    "assembly:torque_control_chery": "–ú–æ–º–µ–Ω—Ç –∑–∞—Ç—è–∂–µ–∫ (Chery)",
    "assembly:torque_control_gwm": "–ú–æ–º–µ–Ω—Ç –∑–∞—Ç—è–∂–µ–∫ (GWM)",
    "assembly:torque_control_changan": "–ú–æ–º–µ–Ω—Ç –∑–∞—Ç—è–∂–µ–∫ (Changan)",
    "assembly:ves_pass_view": "VES –ø–µ—Ä–µ–¥–∞—á–∞/–ø—Ä–∏–µ–º",
}


def _push_recent_post(request, view_name: str, post_id: str, max_items: int = 6) -> None:
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º ¬´–Ω–µ–¥–∞–≤–Ω–∏–µ –ø–æ—Å—Ç—ã¬ª –≤ —Å–µ—Å—Å–∏–∏ ‚Äî —ç–ª–µ–º–µ–Ω—Ç—ã –≤–∏–¥–∞ {"label": ..., "href": ...}."""
    try:
        label = RECENT_POST_LABELS.get(view_name, view_name)
        href = f"{reverse(view_name)}?post_id={post_id}" if post_id else reverse(view_name)
    except Exception:
        return  # –µ—Å–ª–∏ reverse –Ω–µ —É–¥–∞–ª—Å—è, –º–æ–ª—á–∞ –≤—ã—Ö–æ–¥–∏–º

    item = {"label": label, "href": href}
    current = request.session.get("recent_posts", [])
    current = [it for it in current if it.get("href") != item["href"]]  # —É–±—Ä–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç
    current.insert(0, item)
    request.session["recent_posts"] = current[:max_items]  # –º–∞–∫—Å–∏–º—É–º N —à—Ç—É–∫


@login_required
@require_POST
def remember_recent_post(request):
    """
    AJAX-—ç–Ω–¥–ø–æ–∏–Ω—Ç: –ø—Ä–∏–Ω–∏–º–∞–µ—Ç {"url": "/assembly/...?...post_id=18"}, —Ä–µ–∑–æ–ª–≤–∏—Ç view_name + post_id
    –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø–æ—Å—Ç –≤ —Å–µ—Å—Å–∏—é –∫–∞–∫ ¬´–Ω–µ–¥–∞–≤–Ω–∏–π¬ª.
    """
    try:
        payload = json.loads(request.body.decode("utf-8"))
        raw_url = (payload.get("url") or "").strip()
        if not raw_url:
            return JsonResponse({"ok": False, "error": "empty url"}, status=400)

        parsed = urlparse(raw_url)
        path = parsed.path
        query = parse_qs(parsed.query)

        try:
            match = resolve(path)
            view_name = match.view_name
        except Resolver404:
            return JsonResponse({"ok": False, "error": "unresolvable url"}, status=400)

        post_id = ""
        if "post_id" in query and query["post_id"]:
            post_id = str(query["post_id"][0])
        elif "post_id" in match.kwargs:
            post_id = str(match.kwargs.get("post_id") or "")

        _push_recent_post(request, view_name, post_id)
        return JsonResponse({"ok": True})
    except Exception as e:
        return JsonResponse({"ok": False, "error": str(e)}, status=500)



def compress_uploaded_image(uploaded_file, quality=60, max_width=1600):
    """–°–∂–∏–º–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ JPEG/PNG –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç InMemoryUploadedFile"""
    try:
        image = Image.open(uploaded_file)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ RGB (–µ—Å–ª–∏ PNG —Å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é)
        if image.mode in ("RGBA", "P"):
            image = image.convert("RGB")

        # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä (–µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
        if image.width > max_width:
            ratio = max_width / float(image.width)
            height = int(float(image.height) * float(ratio))
            image = image.resize((max_width, height), Image.Resampling.LANCZOS)

        output_io = BytesIO()
        image.save(output_io, format="JPEG", quality=quality, optimize=True)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è
        new_filename = f"photo_{time.strftime('%Y-%m-%dT%H-%M-%S')}.jpg"

        return InMemoryUploadedFile(
            output_io,
            'ImageField',
            new_filename,
            'image/jpeg',
            sys.getsizeof(output_io),
            None
        )
    except Exception as e:
        print("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∂–∞—Ç–∏–∏:", e)
        return uploaded_file  # –í–µ—Ä–Ω—É—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å

@login_required
def profile(request):
    form = ProfileUpdateForm(instance=request.user)
    password_form = CustomPasswordChangeForm(user=request.user)

    if request.method == 'POST':
        action = request.POST.get('action')
        if action == 'update_profile':
            form = ProfileUpdateForm(request.POST, request.FILES, instance=request.user)
            if form.is_valid():
                form.save()
                messages.success(request, "‚úÖ –ü—Ä–æ—Ñ–∏–ª—å –æ–±–Ω–æ–≤–ª—ë–Ω.")
                return redirect('profile')
            else:
                messages.error(request, "‚ùå –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –≤–≤–µ–¥—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.")
        elif action == 'change_password':
            password_form = CustomPasswordChangeForm(user=request.user, data=request.POST)
            if password_form.is_valid():
                user = password_form.save()
                update_session_auth_hash(request, user)
                messages.success(request, "‚úÖ –ü–∞—Ä–æ–ª—å —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω—ë–Ω.")
                return redirect('profile')
            else:
                messages.error(request, "‚ùå –ü–∞—Ä–æ–ª—å –Ω–µ –∏–∑–º–µ–Ω—ë–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ—à–∏–±–∫–∏ –Ω–∏–∂–µ.")

    return render(request, "users/profile.html", {
        "form": form,
        "password_form": password_form,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False
    })


def in_development(request):
    return render(request, "users/in_development.html")


# ‚úÖ –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∫ —Å–≤–æ–µ–π –ø–∞–Ω–µ–ª–∏
@login_required
def controller_dashboard(request):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞: —Ç–æ–ª—å–∫–æ controller + –ø—Ä–∞–≤–æ
    if not (
        request.user.role == "controller"
        or request.user.has_perm("users.access_to_post_of_the_controller")
    ):
        raise PermissionDenied

    allowed_usernames = ["QC-006", "QC-007", "QC-003", "QC-043", "QC-002", "QC-034", "QC-035"]
    master_usernames = ['lidacain_m', "lidacain_c", 'tima_c', 'a.boranchayev', 'an.zhakupov', 'g.mukhanbetov', 'M-02', 'M-06', 'm.akhmetzhanov', 'miko_m', 'n.myrzagul', 'd.zabridze']
    head_area_usernames = ['n.tikkeldiyev', 'nu.mukhambetov', 'p.kalinin', 'p.shen', 't.bostanov', 't.tokshekenov', 'a.yerikov', 'lidacain', 'm.adylbayev', 'miko', 'a.bykov', 'a.alpysbay']


    counter_changan = ['counter_changan']
    show_button_for_counter_changan = request.user.username in counter_changan

    counter_chery = ['counter_chery']
    show_button_for_counter_chery = request.user.username in counter_chery

    counter_gwm = ['counter_gwm']
    show_button_for_counter_gwm = request.user.username in counter_gwm

    counter_frame = ['counter_frame']
    show_button_for_counter_frame = request.user.username in counter_frame


    counter_trim_out_changan = ['counter_trim_out_changan']
    show_button_for_counter_trim_out_changan = request.user.username in counter_trim_out_changan

    counter_trim_out_chery = ['counter_trim_out_chery']
    show_button_for_counter_trim_out_chery = request.user.username in counter_trim_out_chery

    counter_trim_out_gwm = ['counter_trim_out_gwm']
    show_button_for_counter_trim_out_gwm = request.user.username in counter_trim_out_gwm

    counter_trim_out_frame = ['counter_trim_out_frame']
    show_button_for_counter_trim_out_frame = request.user.username in counter_trim_out_frame


    show_manual_buttons = request.user.username in allowed_usernames
    show_head_area_posts_buttons = request.user.username in head_area_usernames
    show_master_posts_buttons = request.user.username in master_usernames

    return render(request, "users/controller_dashboard.html", {
        "show_manual_buttons": show_manual_buttons,
        "show_head_area_posts_buttons": show_head_area_posts_buttons,
        "show_master_posts_buttons": show_master_posts_buttons,

        'show_button_for_counter_changan': show_button_for_counter_changan,
        'show_button_for_counter_chery': show_button_for_counter_chery,
        'show_button_for_counter_gwm': show_button_for_counter_gwm,
        'show_button_for_counter_frame': show_button_for_counter_frame,

        'show_button_for_counter_trim_out_changan': show_button_for_counter_trim_out_changan,
        'show_button_for_counter_trim_out_chery': show_button_for_counter_trim_out_chery,
        'show_button_for_counter_trim_out_gwm': show_button_for_counter_trim_out_gwm,
        'show_button_for_counter_trim_out_frame': show_button_for_counter_trim_out_frame,

        "recent_posts": request.session.get("recent_posts", []),
        "is_controller": getattr(request.user, "role", "") == "controller",
    })

    # Counter123!

@login_required
@role_required(["uud_controller"])
def uud_uniq(request):
    from assembly.views import uud_uniq as assembly_uud_uniq
    return assembly_uud_uniq(request)



# ‚úÖ –ú–∞—Å—Ç–µ—Ä –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∫ —Å–≤–æ–µ–π –ø–∞–Ω–µ–ª–∏
@login_required
@permission_required('users.access_to_the_master_dashboard', raise_exception=True)
def master_dashboard(request):
    can_view_qrr = request.user.has_perm(f"{APP_LABEL}.access_to_the_qrr_responsible")

    show_head_area_posts_buttons = request.user.has_perm(f"{APP_LABEL}.access_to_post_of_the_controller")
    show_uud_tables_username      = request.user.has_perm(f"{APP_LABEL}.access_to_the_uud_table")
    show_marriage_tables_username = request.user.has_perm(f"{APP_LABEL}.access_to_the_marriage_table")

    special_usernames = request.user.has_perm(f"{APP_LABEL}.access_to_dp_rvd")

    return render(request, "users/master_dashboard.html", {
        "special_usernames": special_usernames,
        "can_view_qrr": can_view_qrr,
        'show_head_area_posts_buttons': show_head_area_posts_buttons,
        'show_uud_tables_username': show_uud_tables_username,
        'show_marriage_tables_username': show_marriage_tables_username,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False
    })


# ‚úÖ –ê–¥–º–∏–Ω –∏–º–µ–µ—Ç –¥–æ—Å—Ç—É–ø —Ç–æ–ª—å–∫–æ –∫ —Å–≤–æ–µ–π –ø–∞–Ω–µ–ª–∏
@login_required
@role_required(["admin"])
def admin_dashboard(request):
    return render(request, "users/admin_dashboard.html")


def csrf_failure(request, reason=""):
    return render(request, "users/403_csrf.html", {"reason": reason}, status=403)


# ‚úÖ –¢–æ–ª—å–∫–æ –º–∞—Å—Ç–µ—Ä–∞ –º–æ–≥—É—Ç –∑–∞—Ö–æ–¥–∏—Ç—å –≤ —Ç–∞–±–ª–∏—Ü—É –¥–µ—Ñ–µ–∫—Ç–æ–≤
@login_required
@role_required(["master", "head_area"])
def defect_table(request):
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å —Ç–∞–±–ª–∏—Ü–µ–π –≤—Å–µ—Ö –¥–µ—Ñ–µ–∫—Ç–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è –º–∞—Å—Ç–µ—Ä–∞)"""
    search_query = request.GET.get("search", "")
    sort_by = request.GET.get("sort_by", "-created_at")
    start_date = request.GET.get("start_date", "")
    end_date = request.GET.get("end_date", "")

    defects = Inspection.objects.all()  # ‚úÖ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∏ –Ω–∞ –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å

    if search_query:
        defects = defects.filter(
            Q(container_number__icontains=search_query) |
            Q(pallet_number__icontains=search_query) |
            Q(detail__name__icontains=search_query) |
            Q(defect__name__icontains=search_query)
        )

    if start_date:
        defects = defects.filter(created_at__gte=start_date)
    if end_date:
        defects = defects.filter(created_at__lte=end_date)

    defects = defects.order_by(sort_by)

    return render(request, "users/master_defects_table.html", {
        "defects": defects,
        "search_query": search_query,
        "sort_by": sort_by,
        "start_date": start_date,
        "end_date": end_date
    })


# ‚úÖ API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–µ—Ñ–µ–∫—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
@login_required
@role_required(["master", "head_area"])
def get_defect_stats(request):
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–µ—Ñ–µ–∫—Ç–æ–≤ (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)"""
    today = now().date()
    start_of_week = today - timedelta(days=today.weekday())
    start_of_month = today.replace(day=1)

    # üü¢ –¢–æ–ø-5 –¥–µ—Ñ–µ–∫—Ç–æ–≤
    top_all_time = list(
        Inspection.objects.values("detail__name", "defect__name")
        .annotate(total=Count("id"))
        .order_by("-total")[:5]
    )

    top_today = list(
        Inspection.objects.filter(created_at__gte=today)
        .values("detail__name", "defect__name")
        .annotate(total=Count("id"))
        .order_by("-total")[:5]
    )

    top_week = list(
        Inspection.objects.filter(created_at__gte=start_of_week)
        .values("detail__name", "defect__name")
        .annotate(total=Count("id"))
        .order_by("-total")[:5]
    )

    top_month = list(
        Inspection.objects.filter(created_at__gte=start_of_month)
        .values("detail__name", "defect__name")
        .annotate(total=Count("id"))
        .order_by("-total")[:5]
    )

    return JsonResponse({
        "top_all_time": top_all_time,
        "top_today": top_today,
        "top_week": top_week,
        "top_month": top_month,
    }, safe=False)


# ‚úÖ API –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –¥–µ—Ñ–µ–∫—Ç–æ–≤
@login_required
@role_required(["master", "head_area"])
def get_defects(request):
    """API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –±–µ–∑ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    defects = Inspection.objects.all().order_by("-created_at")

    data = []
    for defect in defects:
        data.append({
            "container_number": defect.container_number,
            "pallet_number": defect.pallet_number,
            "detail_name": defect.detail.name if defect.detail else "-",
            "defect_name": defect.defect.name if defect.defect else "-",
            "controller_username": defect.controller.username if defect.controller else "-",
            "created_at": defect.created_at.strftime("%Y-%m-%d %H:%M:%S"),
            "container_image": request.build_absolute_uri(defect.container_image.url) if defect.container_image else None,
            "pallet_image": request.build_absolute_uri(defect.pallet_image.url) if defect.pallet_image else None,
            "defect_images": [request.build_absolute_uri(img) for img in defect.get_defect_images()]
        })

    return JsonResponse(data, safe=False)


# ‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –≤—Ö–æ–¥–∞ —Å —Ä–µ–¥–∏—Ä–µ–∫—Ç–æ–º –ø–æ —Ä–æ–ª—è–º
def login_view(request):
    form = AuthenticationForm(request, data=request.POST or None)

    # –ï—Å–ª–∏ —É–∂–µ –∑–∞–ª–æ–≥–∏–Ω–µ–Ω –∫–∞–∫ guest ‚Äî —Å—Ä–∞–∑—É –≤ MES
    if request.user.is_authenticated and request.user.get_username() == "guest":
        return redirect("mes_dashboard")

    if request.method == "POST":
        if form.is_valid():
            user = form.get_user()
            login(request, user)
            # –°–ø–µ—Ü-–ø—Ä–∞–≤–∏–ª–æ: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å "guest" –≤—Å–µ–≥–¥–∞ —É—Ö–æ–¥–∏—Ç –Ω–∞ MES –¥–∞—à–±–æ—Ä–¥
            if user.get_username() == "guest":
                return redirect("mes_dashboard")
            role = user.role

            # üîÅ –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–æ–ª–∏
            if role in ["qrr_specialist", "qrr_supervisor", "qrr_shift_lead"]:
                return redirect(reverse("qrr_dashboard"))
            elif role == "controller":
                return redirect("controller_dashboard")
            elif role in ["master", "head_area", "dp"]:
                return redirect("master_dashboard")
            elif role == "admin":
                return redirect("admin_dashboard")
            elif user.role == 'uud_controller':
                return redirect('uud_uniq')
            return redirect("/")  # fallback
        else:
            messages.error(request, "–ù–µ–≤–µ—Ä–Ω–æ–µ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –ø–∞—Ä–æ–ª—å.")

    return render(request, "users/login.html", {"form": form})


# ‚úÖ –í—ã—Ö–æ–¥ –∏–∑ –∞–∫–∫–∞—É–Ω—Ç–∞
@login_required
def logout_view(request):
    logout(request)
    return redirect("login")


# ‚úÖ –†–µ–¥–∏—Ä–µ–∫—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –º–∞—Å—Ç–µ—Ä–∞
def master_redirect(request):
    return redirect("master_dashboard")


# ‚úÖ –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø–æ—Å—Ç–∞
def post_detail(request, post_id):
    return render(request, "users/post_detail.html", {"post_id": post_id})


# ‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
@login_required
@role_required(["admin"])
def create_controller(request):
    return render(request, "users/create_controller.html")


def defect_reports(request):
    return render(request, "users/master_defect_reports.html")


@login_required
@role_required(["master", "head_area"])
def notifications_view(request):
    notifications = Notification.objects.filter(recipient=request.user).order_by('-created_at')
    return render(request, "users/notifications.html", {"notifications": notifications})


@login_required
def get_notifications(request):
    notifications = Notification.objects.filter(recipient=request.user, is_read=False).order_by('-created_at')
    unread_count = notifications.count()
    latest_message = notifications.first().message if notifications.exists() else ""

    return JsonResponse({
        "unread_count": unread_count,
        "latest_message": latest_message
    })


@login_required
def sb_defect_details_view(request, defect_id):
    defect = get_object_or_404(ContainerUnloadingZoneSBInspection, id=defect_id)

    # –û—Ç–º–µ—á–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∫–∞–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω–æ–µ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
    Notification.objects.filter(recipient=request.user, message__icontains=defect.container_number).update(is_read=True)

    return render(request, "users/sb_notification_defect.html", {"defect": defect})


@login_required
@role_required(["master", "head_area"])
def uud_defect_details_view(request, vin_number):
    history_entry = get_object_or_404(VINHistory, vin=vin_number)

    # –û—Ç–º–µ—á–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∫–∞–∫ –ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–µ
    Notification.objects.filter(recipient=request.user, vin_number=vin_number).update(is_read=True)

    history = history_entry.history
    uud_data = None

    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    zone_data = history.get("–¶–µ—Ö –£–£–î", {})
    post_data = zone_data.get("–£—á–∞—Å—Ç–æ–∫ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤, DKD", [])

    if isinstance(post_data, list) and post_data:
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∑–∞–ø–∏—Å—å (–º–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –ø–µ—Ä–µ–±—Ä–∞—Ç—å, –µ—Å–ª–∏ –Ω–∞–¥–æ)
        uud_data = post_data[-1]

    return render(request, "users/uud_notification.html", {
        "vin": vin_number,
        "uud_data": uud_data,
    })

@login_required
@role_required(["master", "head_area"])
def master_panel(request):
    vins = VINHistory.objects.values_list('vin', flat=True).distinct()
    return render(request, 'users/master_dashboard.html', {'vin_list': vins})


@login_required
@permission_required('users.access_to_the_guide', raise_exception=True)
def helpdesk_directory(request):
    query = request.GET.get("q", "").strip()
    contacts = HelpdeskContact.objects.all().order_by(Lower("department"))

    if query:
        q_objects = Q()
        for variant in (query, query.lower(), query.title(), query.upper()):
            q_objects |= Q(employee_name__icontains=variant)
            q_objects |= Q(department__icontains=variant)
            q_objects |= Q(position__icontains=variant)
            q_objects |= Q(email__icontains=variant)

        q_digits = normalize_digits(query)
        if q_digits:
            try:
                contacts = contacts.annotate(
                    phone_digits=RegexReplace(F("phone_number"), Value(r"\D+"), Value(""), Value("g"))
                )
                q_objects |= Q(phone_digits__icontains=q_digits)
                contacts = contacts.filter(q_objects)
            except DatabaseError:
                ids = [c.id for c in contacts if q_digits in normalize_digits(c.phone_number)]
                contacts = contacts.filter(q_objects | Q(id__in=ids))
        else:
            contacts = contacts.filter(q_objects)

    return render(request, "users/helpdesk_directory.html", {
        "contacts": contacts,
        "query": query,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False
    })








@login_required
@permission_required('users.access_to_tracking_by_vin', raise_exception=True)
def vin_tracking_overview(request):
    today = localtime(now()).date()
    start_of_day = make_aware(datetime.combine(today, time.min))
    end_of_day = make_aware(datetime.combine(today, time.max))

    posts_by_zone = {
        "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏": [
            "–ó–æ–Ω–∞ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤, DKD",
            "–ó–æ–Ω–∞ –≤—ã–≥—Ä—É–∑–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö, DKD",
            "–ó–æ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏ DKD"
        ],
        "–¶–µ—Ö —Å–±–æ—Ä–∫–∏": [
            "–ü–æ—Å—Ç –º–æ–º–µ–Ω—Ç–∞ –∑–∞—Ç—è–∂–µ–∫",
            "Chassis Chery",
            "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å",
            "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
            "–ì–µ–æ–º–µ—Ç—Ä–∏—è –∫–æ–ª–µ—Å",
            "–†–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ —Å–≤–µ—Ç–∞ —Ñ–∞—Ä",
            "–¢–æ—Ä–º–æ–∑–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞",
            "ADAS",
            "AVM",
            "–ì–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –∫—É–∑–æ–≤–∞",
            "–§–∏–Ω–∞–ª",
            "–¢–ï–°–¢ —Ç—Ä–µ–∫",
            "Underbody",
            "Shower Test",
        ]
    }

    counters = {(zone, post): 0 for zone, posts in posts_by_zone.items() for post in posts}

    for history in VINHistory.objects.all():
        for zone, posts in posts_by_zone.items():
            zone_data = history.history.get(zone, {})
            for post in posts:
                entries = zone_data.get(post, [])
                for entry in entries:
                    date_str = entry.get("date_added")
                    if not date_str:
                        continue
                    dt = parse_datetime(date_str)
                    if dt and start_of_day <= dt <= end_of_day:
                        counters[(zone, post)] += 1
                        break

    return render(request, "users/tracking/vin_tracking_overview.html", {
        "posts_by_zone": posts_by_zone,
        "counters": counters,
    })


@login_required
@permission_required('users.access_to_tracking_by_vin', raise_exception=True)
def vin_tracking_post_vins(request, post):
    today = now().date()
    vins_today = set()

    for history in VINHistory.objects.all():
        for zone_data in history.history.values():
            entries = zone_data.get(post, [])
            for entry in entries:
                date_str = entry.get("date_added")
                if date_str and parse_datetime(date_str).date() == today:
                    vins_today.add(history.vin)
                    break

    return render(request, "users/tracking/vin_tracking_post_vins.html", {
        "post": post,
        "vins": sorted(vins_today),
    })


@login_required
@permission_required('users.access_to_tracking_by_vin', raise_exception=True)
def vin_tracking_select(request):
    vins = VINHistory.objects.values_list("vin", flat=True).distinct()
    return render(request, "users/tracking/vin_tracking_select.html", {
        "vins": vins,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    })


def get_worst_grade(defects):
    grades_order = ["V1+", "V1", "V2", "V3"]
    for grade in grades_order:
        for defect in defects:
            if defect.get("grade") == grade:
                return grade
    return None


from collections import defaultdict
from django.utils.dateparse import parse_datetime




@login_required
@permission_required('users.access_to_tracking_by_vin', raise_exception=True)
def vin_tracking_view(request, vin):
    # --- TRIM IN –ø–æ—Å—Ç ---
    TRIM_IN_POST = "TRIM IN"

    # –ö–∞—Ä—Ç–∞ –ø–æ—Å—Ç ‚Üí —É—á–∞—Å—Ç–æ–∫
    base_mapping = {
        # –¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å
        "–ü–æ—Å—Ç –º–æ–º–µ–Ω—Ç–∞ –∑–∞—Ç—è–∂–µ–∫": "–¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å",
        "Chassis": "–¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å",
        "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å": "–¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å",

        # –ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è
        "–ó–∞–∑–æ—Ä—ã –∏ –ø–µ—Ä–µ–ø–∞–¥—ã": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–≠–∫—Å—Ç–µ—Ä—å–µ—Ä": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–ò–Ω—Ç–µ—Ä—å–µ—Ä": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–ë–∞–≥–∞–∂–Ω–∏–∫": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–ú–æ—Ç–æ—Ä": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–§—É–Ω–∫—Ü–æ–Ω–∞–ª": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",

        # –¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è
        "–ì–µ–æ–º–µ—Ç—Ä–∏—è –∫–æ–ª–µ—Å": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "–†–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ —Å–≤–µ—Ç–∞ —Ñ–∞—Ä –∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ä—É–ª—è": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "–¢–æ—Ä–º–æ–∑–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "Underbody": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "ADAS": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "AVM": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "–ì–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –∫—É–∑–æ–≤–∞": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è
        "–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞": "–§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–¢–µ—Å—Ç —Ç—Ä–µ–∫": "–§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è": "–§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
    }
    # –í—Å—Ç–∞–≤–ª—è–µ–º TRIM IN –ø–µ—Ä–≤—ã–º –≤ ¬´–¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å¬ª
    POST_AREA_MAPPING = {TRIM_IN_POST: "–¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å", **base_mapping}

    posts_by_zone = {
        "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏": [
            "–ó–æ–Ω–∞ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤, DKD",
            "–ó–æ–Ω–∞ –≤—ã–≥—Ä—É–∑–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö, DKD",
            "–ó–æ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏ DKD",
        ],
        "–¶–µ—Ö —Å–±–æ—Ä–∫–∏": list(POST_AREA_MAPPING.keys()),  # TRIM IN —Ç–æ–∂–µ –≤ —ç—Ç–æ–º —Å–ø–∏—Å–∫–µ
    }

    # –°–∞–π–¥–±–∞—Ä VIN-–æ–≤
    vins = list(VINHistory.objects.values_list("vin", flat=True).order_by("vin"))
    try:
        current_index = vins.index(vin)
    except ValueError:
        current_index = -1

    trace = TraceData.objects.filter(vin_rk=vin).first()
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏/—Ü–≤–µ—Ç–∞ –¥–ª—è –í–°–ï–• VIN –≤ —Å–ø–∏—Å–∫–µ (–¥–ª—è —Å–∞–π–¥–±–∞—Ä–∞)
    traces_qs = TraceData.objects.filter(vin_rk__in=vins)
    trace_map = {t.vin_rk: t for t in traces_qs}
    vin_items = [
        {
            "vin": v,
            "model": (trace_map.get(v).model if trace_map.get(v) else ""),
            "color_1c": (trace_map.get(v).color_1c if trace_map.get(v) else ""),
        }
        for v in vins
    ]
    vin_history = VINHistory.objects.filter(vin=vin).first()
    post_statuses = []                    # –∫–∞—Ä—Ç–æ—á–∫–∏: –¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏
    grouped_statuses = defaultdict(list)  # –∫–∞—Ä—Ç–æ—á–∫–∏: –¶–µ—Ö —Å–±–æ—Ä–∫–∏ (–ø–æ —É—á–∞—Å—Ç–∫–∞–º)
    timeline = []                         # –æ–±—â–∞—è –ª–µ–Ω—Ç–∞ —Å–æ–±—ã—Ç–∏–π —Å–æ step‚Äô–∞–º–∏

    # Default initializations for certain status variables
    last_step_post = None
    is_on_uud = False
    is_on_ves = False
    uud_latest_name = None
    uud_latest_time = None
    ves_latest_name = None
    ves_latest_time = None
    is_on_sgp = False
    sgp_latest_time = None

    if vin_history:
        history_data = vin_history.history or {}

        # === Flag: was there ANY defect with UUD status "impossible" at any time? ===
        has_uud_impossible = False
        try:
            for zone_dict in (history_data or {}).values():
                if has_uud_impossible:
                    break
                for entries in (zone_dict or {}).values():
                    if has_uud_impossible:
                        break
                    for entry in (entries or []):
                        defects = entry.get("defects", []) or []
                        if not isinstance(defects, list):
                            continue
                        for d in defects:
                            if not isinstance(d, dict):
                                continue
                            extra = d.get("extra", {}) or {}
                            uud = extra.get("UUD", {}) or {}
                            status = (uud.get("status") or "").lower()
                            if status == "impossible":
                                has_uud_impossible = True
                                break
                        if has_uud_impossible:
                            break
        except Exception:
            has_uud_impossible = False

        # --- –°–æ–±–∏—Ä–∞–µ–º –í–°–ï —Å–æ–±—ã—Ç–∏—è –≤ raw_events ---

        raw_events = []  # (dt, zone_name, post_name)
        last_at = {}  # –±—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω –ø–æ–∑–∂–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º –∏–º—è –¥–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
        post_steps = defaultdict(list)
        timeline = []

        # 1) TRIM IN –∏–∑ AssemblyPassLog
        trim_in_datetimes = []
        if AssemblyPassLog is not None:
            for log in AssemblyPassLog.objects.filter(vin=vin).order_by("scanned_at"):
                if log.scanned_at:
                    raw_events.append((log.scanned_at, "–¶–µ—Ö —Å–±–æ—Ä–∫–∏", TRIM_IN_POST))
                    trim_in_datetimes.append(log.scanned_at)

        # 2) –ü–æ—Å—Ç—ã –∏–∑ VINHistory (–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏ + –¶–µ—Ö —Å–±–æ—Ä–∫–∏)
        for zone_name, posts in posts_by_zone.items():
            zone_dict = history_data.get(zone_name, {}) or {}
            for post in posts:
                if post == TRIM_IN_POST:
                    continue
                for entry in zone_dict.get(post, []) or []:
                    dt = parse_datetime(entry.get("date_added") or entry.get("date") or "")
                    if dt:
                        raw_events.append((dt, zone_name, post))

        # 3) –£–£–î: 4 —à–∞–≥–∞
        uud_zone = history_data.get("–£–£–î", {}) or {}
        uud_entries = uud_zone.get("–£–£–î", []) or []
        uud_posts = {
            "step1_at": "–£–£–î ‚Äî –®–∞–≥ 1 (–æ—Ç–¥–∞–Ω–∞ –Ω–∞ –£–£–î)",
            "step2_at": "–£–£–î ‚Äî –®–∞–≥ 2 (–ø—Ä–∏–Ω—è—Ç–∞ –Ω–∞ –£–£–î)",
            "step3_at": "–£–£–î ‚Äî –®–∞–≥ 3 (–æ—Ç–¥–∞–Ω–∞ –Ω–∞ –ª–∏–Ω–∏—é)",
            "step4_at": "–£–£–î ‚Äî –®–∞–≥ 4 (–ø—Ä–∏–Ω—è—Ç–∞ –Ω–∞ –ª–∏–Ω–∏—é)",
        }
        for entry in uud_entries:
            extra = entry.get("extra_data", {}) or {}
            for step_key, post_name in uud_posts.items():
                dt_str = extra.get(step_key)
                if not dt_str:
                    continue
                dt = parse_datetime(dt_str)
                if dt:
                    raw_events.append((dt, "–£–£–î", post_name))

        # 4) VES: –æ—Ç–¥–∞–Ω/–ø—Ä–∏–Ω—è—Ç
        ves_logs = VESPassLog.objects.filter(vin=vin).order_by("given_at")
        ves_posts = {"given": "VES ‚Äî –û—Ç–¥–∞–Ω", "received": "VES ‚Äî –ü—Ä–∏–Ω—è—Ç"}
        for log in ves_logs:
            if log.given_at:
                raw_events.append((log.given_at, "VES", ves_posts["given"]))
            if log.received_at:
                raw_events.append((log.received_at, "VES", ves_posts["received"]))

        from datetime import timedelta

        def _minute(dt):
            return dt.replace(second=0, microsecond=0)

        # –ò–Ω–¥–µ–∫—Å —Å—Ç–∞—Ç—É—Å–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: (zone, post, dt_minute) -> 'ok' | 'defect'
        entry_status_by_minute = {}

        for zname in ("–¶–µ—Ö —Å–±–æ—Ä–∫–∏", "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"):
            zdict = history_data.get(zname, {}) or {}
            for pname, entries in zdict.items():
                for e in entries or []:
                    dt_e = parse_datetime(e.get("date_added") or e.get("date") or "")
                    if not dt_e:
                        continue
                    status_e = "defect" if (e.get("has_defect") == "yes" or e.get("defects")) else "ok"
                    entry_status_by_minute[(zname, pname, _minute(dt_e))] = status_e



        # --- –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –ø–µ—Ä–µ—Å—á—ë—Ç –≥–ª–æ–±–∞–ª—å–Ω–æ–π —à–∫–∞–ª—ã —à–∞–≥–æ–≤ ---
        raw_events.sort(key=lambda t: t[0])
        post_steps.clear()
        last_at = {}
        timeline.clear()

        # –î–æ–ø—É—Å–∫, –µ—Å–ª–∏ –º–∏–Ω—É—Ç—ã –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç (–º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å 0 –º–∏–Ω—É—Ç, –µ—Å–ª–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç —Ç–æ—á–Ω–æ)
        TOL = timedelta(minutes=3)

        for step, (dt, zone_name, post_name) in enumerate(raw_events, start=1):
            status = "ok"
            if zone_name in {"–¶–µ—Ö —Å–±–æ—Ä–∫–∏", "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"}:
                key = (zone_name, post_name, _minute(dt))
                if key in entry_status_by_minute:
                    status = entry_status_by_minute[key]
                else:
                    # –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π ¬´–ø–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–µ–π –∑–∞–ø–∏—Å–∏¬ª –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö TOL
                    nearest = None
                    nearest_diff = None
                    # –ø–µ—Ä–µ–±–æ—Ä –≤–æ–∫—Ä—É–≥ –Ω—É–∂–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥/–≤–ø–µ—Ä—ë–¥)
                    for shift in range(-int(TOL.total_seconds() // 60), int(TOL.total_seconds() // 60) + 1):
                        k = (zone_name, post_name, _minute(dt + timedelta(minutes=shift)))
                        if k in entry_status_by_minute:
                            diff = abs((dt - (dt + timedelta(minutes=shift))).total_seconds())
                            if nearest_diff is None or diff < nearest_diff:
                                nearest = entry_status_by_minute[k]
                                nearest_diff = diff
                    if nearest is not None:
                        status = nearest
                    # –∏–Ω–∞—á–µ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è 'ok'

            timeline.append({"step": step, "dt": dt, "zone": zone_name, "post": post_name, "status": status})
            post_steps[post_name].append({"step": step, "dt": dt, "status": status})
            last_at[post_name] = dt

        # --- –ö–∞—Ä—Ç–æ—á–∫–∏ –¥–ª—è VES (–æ—Ç–¥–∞–Ω / –ø—Ä–∏–Ω—è—Ç) ---
        ves_given = "VES ‚Äî –û—Ç–¥–∞–Ω"
        ves_received = "VES ‚Äî –ü—Ä–∏–Ω—è—Ç"

        grouped_statuses["VES"] = [
            {
                "zone": "VES",
                "post": ves_given,
                "status": "ok" if last_at.get(ves_given) else "missing",
                "grade": None,
                "last_at": last_at.get(ves_given),
                "steps": post_steps.get(ves_given, []),
            },
            {
                "zone": "VES",
                "post": ves_received,
                "status": "ok" if last_at.get(ves_received) else "missing",
                "grade": None,
                "last_at": last_at.get(ves_received),
                "steps": post_steps.get(ves_received, []),
            },
        ]

        uud_posts_map = {
            "–£–£–î ‚Äî –®–∞–≥ 1 (–æ—Ç–¥–∞–Ω–∞ –Ω–∞ –£–£–î)": "step1_at",
            "–£–£–î ‚Äî –®–∞–≥ 2 (–ø—Ä–∏–Ω—è—Ç–∞ –Ω–∞ –£–£–î)": "step2_at",
            "–£–£–î ‚Äî –®–∞–≥ 3 (–æ—Ç–¥–∞–Ω–∞ –Ω–∞ –ª–∏–Ω–∏—é)": "step3_at",
            "–£–£–î ‚Äî –®–∞–≥ 4 (–ø—Ä–∏–Ω—è—Ç–∞ –Ω–∞ –ª–∏–Ω–∏—é)": "step4_at",
        }
        grouped_statuses["–£–£–î"] = [
            {
                "zone": "–£–£–î",
                "post": post_name,
                "status": "ok" if last_at.get(post_name) else "missing",
                "grade": None,
                "last_at": last_at.get(post_name),
                "steps": post_steps.get(post_name, []),
            }
            for post_name in uud_posts_map.keys()
        ]


        # --- –ö–∞—Ä—Ç–æ—á–∫–∏ ¬´–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏¬ª ---
        post_statuses = []
        for post in posts_by_zone["–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"]:
            entries = (history_data.get("–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏", {}) or {}).get(post, []) or []
            if entries:
                defects = []
                has_defect_flag = any(e.get("has_defect") == "yes" for e in entries)
                for e in entries:
                    d = e.get("defects", [])
                    if isinstance(d, list):
                        defects.extend(d)
                worst_grade = get_worst_grade(defects)
                overall_status = "defect" if defects or has_defect_flag else "ok"
            else:
                overall_status = "missing"
                worst_grade = None

            post_statuses.append({
                "zone": "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏",
                "post": post,
                "status": overall_status,
                "grade": worst_grade,
                "last_at": last_at.get(post),
                "steps": post_steps.get(post, []),  # –ì–õ–û–ë–ê–õ–¨–ù–´–ï —à–∞–≥–∏
            })

        # --- –ö–∞—Ä—Ç–æ—á–∫–∏ ¬´–¶–µ—Ö —Å–±–æ—Ä–∫–∏¬ª, –≤–∫–ª—é—á–∞—è TRIM IN ---
        for post, area in POST_AREA_MAPPING.items():
            if post == TRIM_IN_POST:
                present = bool(trim_in_datetimes)
                status = "ok" if present else "missing"
                grouped_statuses[area].append({
                    "zone": "–¶–µ—Ö —Å–±–æ—Ä–∫–∏",
                    "post": post,
                    "status": status,
                    "grade": None,
                    "last_at": last_at.get(post),
                    "steps": post_steps.get(post, []),  # –ì–õ–û–ë–ê–õ–¨–ù–´–ï —à–∞–≥–∏
                })
                continue

            entries = (history_data.get("–¶–µ—Ö —Å–±–æ—Ä–∫–∏", {}) or {}).get(post, []) or []
            if entries:
                defects = []
                has_defect_flag = any(e.get("has_defect") == "yes" for e in entries)
                for e in entries:
                    d = e.get("defects", [])
                    if isinstance(d, list):
                        defects.extend(d)
                worst_grade = get_worst_grade(defects)
                overall_status = "defect" if defects or has_defect_flag else "ok"
            else:
                overall_status = "missing"
                worst_grade = None

            grouped_statuses[area].append({
                "zone": "–¶–µ—Ö —Å–±–æ—Ä–∫–∏",
                "post": post,
                "status": overall_status,
                "grade": worst_grade,
                "last_at": last_at.get(post),
                "steps": post_steps.get(post, []),  # –ì–õ–û–ë–ê–õ–¨–ù–´–ï —à–∞–≥–∏
            })

        # --- –ü–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ—Å—Ç ---
        last_step_post = timeline[-1] if timeline else None

        # --- –°—Ç–∞—Ç—É—Å—ã –£–£–î/ VES / –°–ì–ü (—Ç–µ –∂–µ, —á—Ç–æ –±—ã–ª–∏) ---
        uud_step1 = "–£–£–î ‚Äî –®–∞–≥ 1 (–æ—Ç–¥–∞–Ω–∞ –Ω–∞ –£–£–î)"
        uud_step2 = "–£–£–î ‚Äî –®–∞–≥ 2 (–ø—Ä–∏–Ω—è—Ç–∞ –Ω–∞ –£–£–î)"
        uud_step3 = "–£–£–î ‚Äî –®–∞–≥ 3 (–æ—Ç–¥–∞–Ω–∞ –Ω–∞ –ª–∏–Ω–∏—é)"
        uud_step4 = "–£–£–î ‚Äî –®–∞–≥ 4 (–ø—Ä–∏–Ω—è—Ç–∞ –Ω–∞ –ª–∏–Ω–∏—é)"

        def _latest_named(names):
            latest_t = None
            latest_name = None
            for nm in names:
                t = last_at.get(nm)
                if t and (latest_t is None or t > latest_t):
                    latest_t = t
                    latest_name = nm
            return latest_t, latest_name

        uud_latest_time, uud_latest_name = _latest_named([uud_step1, uud_step2, uud_step3, uud_step4])
        is_on_uud = bool(uud_latest_name in {uud_step1, uud_step2})

        ves_given = "VES ‚Äî –û—Ç–¥–∞–Ω"
        ves_received = "VES ‚Äî –ü—Ä–∏–Ω—è—Ç"
        t_given = last_at.get(ves_given)
        t_received = last_at.get(ves_received)
        is_on_ves = bool(t_given and (not t_received or t_given > t_received))
        ves_latest_time = t_given if (t_given and (not t_received or t_given >= t_received)) else t_received
        ves_latest_name = ves_given if (t_given and (not t_received or t_given > t_received)) else (
            ves_received if t_received else None)

        sgp_post = "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
        sgp_latest_time = last_at.get(sgp_post)
        is_on_sgp = bool(sgp_latest_time)

    return render(request, "users/tracking/vin_tracking_view.html", {
        "vin": vin,
        "vins": vins,
        "current_index": current_index,
        "post_statuses": post_statuses,
        "grouped_statuses": dict(grouped_statuses),
        "last_step_post": last_step_post,
        "timeline": timeline,
        "trace": trace,
        "is_on_uud": is_on_uud,
        "is_on_ves": is_on_ves,
        "uud_latest_name": uud_latest_name,
        "uud_latest_time": uud_latest_time,
        "ves_latest_name": ves_latest_name,
        "ves_latest_time": ves_latest_time,
        "is_on_sgp": is_on_sgp,
        "sgp_latest_time": sgp_latest_time,
        "vin_items": vin_items,
        "trace_map": trace_map,
        "has_uud_impossible": has_uud_impossible,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    })






from collections import defaultdict
from django.utils.dateparse import parse_datetime

from collections import defaultdict
from django.contrib.auth.decorators import login_required
from users.utils.post_extractors import extract_entries

@login_required
@permission_required('users.access_to_tracking_by_vin', raise_exception=True)
def vin_post_detail(request, vin, post):
    vin_history = VINHistory.objects.filter(vin=vin).first()
    if not vin_history:
        return render(request, "users/tracking/not_found.html", {"message": "VIN –Ω–µ –Ω–∞–π–¥–µ–Ω"})

    trace_data   = TraceData.objects.filter(vin_rk=vin).first()
    history_data = vin_history.history or {}

    entries = extract_entries(history_data, post, vin=vin)  # <-- –ø–µ—Ä–µ–¥–∞–π vin

    # –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–ª–∞–≥–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ –ø–æ—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–±—ã–ª –Ω–µ–≤–æ–∑–º–æ–∂–Ω—ã–π —Ä–µ–º–æ–Ω—Ç¬ª)
    has_uud_impossible = any(e.get("flags", {}).get("uud_impossible") for e in entries)

    return render(request, "users/tracking/vin_post_detail.html", {
        "vin": vin,
        "post": post,
        "entries": entries,
        "trace_data": trace_data,
        "has_uud_impossible": has_uud_impossible,
    })









@login_required
@permission_required('users.access_to_tracking_by_vin', raise_exception=True)
def export_vin_excel(request, vin):
    from openpyxl import Workbook
    from openpyxl.styles import Alignment
    from collections import defaultdict
    import os

    vin_history = VINHistory.objects.filter(vin=vin).first()
    if not vin_history:
        return HttpResponse("‚ùå VIN –Ω–µ –Ω–∞–π–¥–µ–Ω", status=404)

    trace = TraceData.objects.filter(vin_rk=vin).first()
    brand = trace.brand if trace else ""
    model = trace.model if trace else ""
    config_code = trace.config_code if trace else ""

    data_rows = []
    max_photos = 0

    for zone_name, posts in vin_history.history.items():
        for post_name, entries in posts.items():
            for entry in entries:
                date_raw = entry.get("date_added")
                if not date_raw:
                    continue
                date = parse_datetime(date_raw)
                controller = entry.get("controller", "") or entry.get("extra_data", {}).get("controller", "")
                line = entry.get("line", "")
                duration = entry.get("inspection_duration_seconds", "")

                if "defects" in entry and isinstance(entry["defects"], list) and entry["defects"]:
                    for defect in entry["defects"]:
                        photos = defect.get("photos", [])
                        max_photos = max(max_photos, len(photos))
                        data_rows.append({
                            "zone": zone_name,
                            "post": post_name,
                            "vin": vin,
                            "brand": brand,
                            "model": model,
                            "config_code": config_code,
                            "date": date,
                            "line": line,
                            "controller": controller,
                            "defect": defect.get("name", ""),
                            "comment": defect.get("comment", ""),
                            "grade": defect.get("grade", ""),
                            "unit": defect.get("unit", ""),
                            "responsible": defect.get("responsible", ""),
                            "duration": duration,
                            "photos": photos,
                        })
                elif entry.get("defect_description") or entry.get("defect_photos"):
                    photos = entry.get("defect_photos", [])
                    max_photos = max(max_photos, len(photos))
                    data_rows.append({
                        "zone": zone_name,
                        "post": post_name,
                        "vin": vin,
                        "brand": brand,
                        "model": model,
                        "config_code": config_code,
                        "date": date,
                        "line": line,
                        "controller": controller,
                        "defect": entry.get("defect_description", ""),
                        "comment": "",
                        "grade": "",
                        "unit": "",
                        "responsible": "",
                        "duration": duration,
                        "photos": photos,
                    })

    # üìó Excel
    wb = Workbook()
    ws = wb.active
    ws.title = f"VIN {vin}"

    headers = [
        "–£—á–∞—Å—Ç–æ–∫", "–ü–æ—Å—Ç", "VIN", "–ë—Ä–µ–Ω–¥", "–ú–æ–¥–µ–ª—å", "–ö–æ–¥ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏", "–î–∞—Ç–∞", "–õ–∏–Ω–∏—è", "–ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä",
        "–î–µ—Ñ–µ–∫—Ç", "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", "–ì—Ä–µ–π–¥", "–ï–¥–∏–Ω–∏—Ü–∞", "–ö—Ç–æ –≤–∏–Ω–æ–≤–∞—Ç", "–í—Ä–µ–º—è –æ—Å–º–æ—Ç—Ä–∞ (—Å–µ–∫)"
    ] + [f"–§–æ—Ç–æ {i+1}" for i in range(max_photos)]

    ws.append(headers)

    for row in data_rows:
        excel_row = [
            row["zone"],
            row["post"],
            row["vin"],
            row["brand"],
            row["model"],
            row["config_code"],
            row["date"].strftime("%d.%m.%Y %H:%M"),
            row["line"],
            row["controller"],
            row["defect"],
            row["comment"],
            row["grade"],
            row["unit"],
            row["responsible"],
            row["duration"],
        ]
        excel_row += [""] * max_photos
        ws.append(excel_row)

        row_idx = ws.max_row
        for i, img_path in enumerate(row["photos"]):
            insert_single_image(ws, row_idx, 16 + i, img_path)
        ws.row_dimensions[row_idx].height = 75

    for col in ws.columns:
        for cell in col:
            cell.alignment = Alignment(wrap_text=True, vertical='top')

    # –û—Ç–≤–µ—Ç
    response = HttpResponse(content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    response['Content-Disposition'] = f'attachment; filename="vin_report_{vin}.xlsx"'
    wb.save(response)
    return response















import os
from django.http import HttpResponse
from django.conf import settings
from openpyxl import Workbook
from openpyxl.drawing.image import Image as XLImage
from openpyxl.styles import Alignment
from openpyxl.utils import get_column_letter
from vehicle_history.models import VINHistory
from collections import defaultdict
from PIL import Image as PILImage
from io import BytesIO
import json
from django.utils.dateparse import parse_date
from django.utils.timezone import make_aware
from datetime import datetime
import io
import zipfile
from django.contrib.auth.decorators import login_required
from users.decorators import role_required
from django.utils.dateparse import parse_datetime
from supplies.models import TraceData


def insert_single_image(ws, row_idx, col_idx, path):
    try:
        rel_path = path.replace(settings.MEDIA_URL, "")
        abs_path = os.path.join(settings.MEDIA_ROOT, rel_path)

        if os.path.exists(abs_path):
            img = XLImage(abs_path)
            img.width = 85
            img.height = 85

            col_letter = get_column_letter(col_idx)
            ws.add_image(img, f"{col_letter}{row_idx}")

            # üí° –£—Å—Ç–∞–Ω–æ–≤–∏–º —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–∫–∏ (–æ–¥–∏–Ω —Ä–∞–∑)
            if col_letter not in ws.column_dimensions:
                ws.column_dimensions[col_letter].width = 17  # –ø–æ–¥ 90px –∫–∞—Ä—Ç–∏–Ω–∫–∏

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {path}: {e}")


@login_required
@permission_required('users.access_to_the_rvd', raise_exception=True)
def employee_search(request):
    search_form = EmployeeSearchForm(request.GET)

    selected_employee_ids = request.GET.getlist('employees') if request.method == 'GET' else []

    # –í–ê–ñ–ù–û: –ø–æ–¥–Ω–∏–º–∞–µ–º —Å—é–¥–∞!
    employees = Employee.objects.all()

    employees_queryset = Employee.objects.filter(id__in=selected_employee_ids)

    if request.method == 'GET':
        form_data = request.GET.copy()
        selection_form = EmployeeSelectionForm(data=form_data, initial={'employees': selected_employee_ids})
        selection_form.fields['employees'].queryset = Employee.objects.filter(
            Q(id__in=selected_employee_ids) | Q(id__in=employees.values_list('id', flat=True))
        )
    else:
        selection_form = EmployeeSelectionForm()

    if search_form.is_valid():
        query = search_form.cleaned_data['search_query']
        position = search_form.cleaned_data['position']
        department = search_form.cleaned_data['department']

        if query:
            employees = employees.filter(name__iregex=query)
        if position:
            employees = employees.filter(position__iregex=position)
        if department:
            employees = employees.filter(department__iregex=department)

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤—ã–±–æ—Ä–∞
    if request.method == 'POST':
        selection_form = EmployeeSelectionForm(request.POST)
        if selection_form.is_valid():
            try:
                selected_employees = selection_form.cleaned_data['employees']
                selected_dates = selection_form.cleaned_data['selected_dates']
                is_xtk = selection_form.cleaned_data['is_xtk']
                justification = selection_form.cleaned_data['justification']
                start_time_str = selection_form.cleaned_data['start_time']
                end_time_str = selection_form.cleaned_data['end_time']
                start_time = datetime.strptime(start_time_str, "%H:%M").time()
                end_time = datetime.strptime(end_time_str, "%H:%M").time()

                created_count = 0
                for employee in selected_employees:
                    for date_str in selected_dates:
                        selected_date = datetime.strptime(date_str, "%Y-%m-%d").date()
                        if not Selection.objects.filter(
                            manager=request.user,
                            employee=employee,
                            selected_date=selected_date
                        ).exists():
                            Selection.objects.create(
                                manager=request.user,
                                employee=employee,
                                selected_date=selected_date,
                                is_xtk=is_xtk,
                                justification=justification,
                                start_time=start_time,
                                end_time=end_time
                            )
                            created_count += 1

                messages.success(
                    request,
                    f'‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {created_count} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {len(selected_employees)} —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞(–æ–≤)'
                )
                return redirect('employee_search')

            except Exception as e:
                messages.error(request, f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {str(e)}')

    selections = Selection.objects.filter(manager=request.user)

    context = {
        'search_form': search_form,
        'selection_form': selection_form,
        'employees': employees,
        'selections': selections,
        'employee_ids': selected_employee_ids,  # –¥–ª—è —Å–∫—Ä—ã—Ç—ã—Ö input –≤ —à–∞–±–ª–æ–Ω–µ
        'enable_particles': True,
        'enable_background': True,
        'enable_white_square': False
    }
    return render(request, 'users/management/search.html', context)


@login_required
@permission_required('users.access_to_the_rvd', raise_exception=True)
def edit_selection(request, selection_id):
    selection = get_object_or_404(Selection, id=selection_id, manager=request.user)

    if request.method == 'POST':
        form = EmployeeSelectionForm(request.POST)
        if form.is_valid():
            employee = form.cleaned_data['employee']
            selected_dates = form.cleaned_data['selected_dates']
            is_xtk = form.cleaned_data['is_xtk']

            if len(selected_dates) != 1:
                messages.error(request, '–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É –¥–∞—Ç—É')
            else:
                selected_date = datetime.strptime(selected_dates[0], "%Y-%m-%d").date()

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç
                if Selection.objects.filter(
                        manager=request.user,
                        employee=employee,
                        selected_date=selected_date
                ).exclude(id=selection.id).exists():
                    messages.error(request, '–¢–∞–∫–æ–π –≤—ã–±–æ—Ä —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç')
                else:
                    selection.employee = employee
                    selection.selected_date = selected_date
                    selection.is_xtk = is_xtk
                    selection.save()
                    messages.success(request, f'–í—ã–±–æ—Ä —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω')
                    return redirect('employee_search')
    else:
        form = EmployeeSelectionForm(initial={
            'employee': selection.employee,
            'selected_dates': [selection.selected_date.strftime("%Y-%m-%d")],
            'is_xtk': selection.is_xtk
        })

    return render(request, 'users/management/edit_selection.html', {
        'form': form,
        'selection': selection
    })


@login_required
@permission_required('users.access_to_the_rvd', raise_exception=True)
def delete_all_selections(request):
    if request.method == 'POST':
        deleted_count, _ = Selection.objects.filter(manager=request.user).delete()
        messages.success(request, f'üóë –£–¥–∞–ª–µ–Ω–æ {deleted_count} –≤—ã–±–æ—Ä–æ–≤.')
    return redirect('employee_search')


@login_required
@permission_required('users.access_to_the_rvd', raise_exception=True)
def delete_selection(request, selection_id):
    selection = get_object_or_404(Selection, id=selection_id, manager=request.user)

    # ‚úÖ –£–¥–∞–ª—è–µ–º —Å—Ä–∞–∑—É, –±–µ–∑ —Ñ–æ—Ä–º—ã
    employee_name = selection.employee.name
    selection.delete()
    messages.success(request, f'–í—ã–±–æ—Ä –¥–ª—è {employee_name} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω')

    return redirect('employee_search')


@login_required
@permission_required('users.access_to_the_rvd', raise_exception=True)
def export_excel(request):
    try:
        selections = Selection.objects.filter(manager=request.user)

        data = [{
            '–°–æ—Ç—Ä—É–¥–Ω–∏–∫': sel.employee.name,
            '–î–æ–ª–∂–Ω–æ—Å—Ç—å': sel.employee.position,
            '–û—Ç–¥–µ–ª': sel.employee.department or '‚Äî',
            '–î–∞—Ç–∞': sel.selected_date.strftime("%d.%m.%Y"),
            '–•–¢–ö': '–î–∞' if sel.is_xtk else '–ù–µ—Ç',
            '–ß–∞—Å—ã': sel.hours
        } for sel in selections]

        if not data:
            messages.warning(request, '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞')
            return redirect('employee_search')

        df = pd.DataFrame(data)
        response = HttpResponse(
            content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )

        filename = f'employee_selections_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx'
        response['Content-Disposition'] = f'attachment; filename={filename}'

        df.to_excel(response, index=False)

        ExportHistory.objects.create(
            manager=request.user,
            file_name=filename,
            record_count=len(data),
            export_data=json.dumps(data, ensure_ascii=False)
        )

        return response

    except Exception as e:
        messages.error(request, f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ: {str(e)}')
        return redirect('employee_search')


@login_required
@permission_required('users.access_to_the_rvd', raise_exception=True)
def export_history(request):
    try:
        history = ExportHistory.objects.filter(manager=request.user)

        for record in history:
            try:
                data = record.get_data_as_list()
            except Exception as e:
                messages.error(request, f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–∏ {record.id}: {str(e)}')

        return render(request, 'users/management/export_history.html', {
            'history': history
        })
    except Exception as e:
        messages.error(request, f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}')
        return redirect('employee_search')


@login_required
@permission_required('users.access_to_the_rvd', raise_exception=True)
def load_export_to_selection(request, history_id):
    try:
        history_record = get_object_or_404(ExportHistory, id=history_id, manager=request.user)
        data = history_record.get_data_as_list()

        # Clear existing selections for this user
        Selection.objects.filter(manager=request.user).delete()

        # Create new selections from the export data
        for item in data:
            # Find or create employee
            employee, created = Employee.objects.get_or_create(
                name=item['Name'],
                defaults={
                    'position': item['Position'],
                    'department': item['Department']
                }
            )

            # Create selection
            Selection.objects.create(
                manager=request.user,
                employee=employee,
                selected_date=datetime.strptime(item['–î–∞—Ç–∞'], "%d.%m.%Y").date(),
                is_xtk=item.get('–•–¢–ö') == '–î–∞',
                hours=int(item.get('–ß–∞—Å—ã', 8))
            )

        messages.success(request, '–°–ø–∏—Å–æ–∫ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ —Ç–µ–∫—É—â–∏–µ –≤—ã–±–æ—Ä—ã')
        return redirect('users:employee_search')
    except Exception as e:
        messages.error(request, f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–ø–∏—Å–∫–∞: {str(e)}')
        return redirect('employee_search')


@login_required
@permission_required('users.access_to_the_rvd', raise_exception=True)
def re_export_excel(request, history_id):
    try:
        history_record = get_object_or_404(ExportHistory, id=history_id, manager=request.user)

        # Get the stored data
        try:
            data = history_record.get_data_as_list()
        except Exception as e:
            messages.error(request, f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {str(e)}')
            return redirect('employee_search')

        if not data:
            messages.warning(request, '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞')
            return redirect('employee_search')

        # Create new filename with timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f're_export_{history_record.file_name}'

        # Create Excel file
        df = pd.DataFrame(data)
        response = HttpResponse(
            content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
        response['Content-Disposition'] = f'attachment; filename={filename}'

        df.to_excel(response, index=False)

        # Record the re-export in history
        try:
            ExportHistory.objects.create(
                manager=request.user,
                file_name=filename,
                record_count=len(data),
                export_data=json.dumps(data, ensure_ascii=False)
            )
        except Exception as e:
            messages.error(request, f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏: {str(e)}')

        return response
    except Exception as e:
        messages.error(request, f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º —ç–∫—Å–ø–æ—Ä—Ç–µ: {str(e)}')
        return redirect('employee_search')


@login_required
@permission_required('users.access_to_the_rvd', raise_exception=True)
def edit_export_history(request, history_id):
    history_record = get_object_or_404(ExportHistory, id=history_id, manager=request.user)

    if request.method == 'POST':
        try:
            new_filename = request.POST.get('file_name')
            if new_filename:
                history_record.file_name = new_filename
                history_record.save()
                messages.success(request, '–ò–º—è —Ñ–∞–π–ª–∞ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–æ')
                return redirect('users:export_history')
        except Exception as e:
            messages.error(request, f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏: {str(e)}')

    return render(request, 'users/management/edit_export_history.html', {
        'record': history_record
    })


@login_required
@permission_required('users.access_to_the_rvd', raise_exception=True)
def delete_export_history(request, history_id):
    history_record = get_object_or_404(ExportHistory, id=history_id, manager=request.user)

    if request.method == 'POST':
        try:
            filename = history_record.file_name
            history_record.delete()
            messages.success(request, f'–ó–∞–ø–∏—Å—å {filename} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞')
            return redirect('users:export_history')
        except Exception as e:
            messages.error(request, f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏: {str(e)}')

    return render(request, 'users/management/delete_export_history.html', {
        'record': history_record
    })








@login_required
@permission_required('users.access_to_dp_rvd', raise_exception=True)
def office_overview(request):


    manager_filter = request.GET.get('manager')

    selections = Selection.objects.select_related('employee', 'manager') \
        .order_by('selected_date', 'employee__name')

    if manager_filter:
        selections = selections.filter(manager__id=manager_filter)

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
    grouped = {}
    for sel in selections:
        key = sel.employee.id
        if key not in grouped:
            grouped[key] = {
                'name': sel.employee.name,
                'position': sel.employee.position,
                'department': sel.employee.department,
                'dates': [],
                'is_xtk': sel.is_xtk,
                'justification': sel.justification,
                'manager': sel.manager.get_full_name_with_patronymic(),
                'start_time': sel.start_time.strftime('%H:%M') if sel.start_time else '',
                'end_time': sel.end_time.strftime('%H:%M') if sel.end_time else '',
                'hours': sel.hours,
            }
        grouped[key]['dates'].append(sel.selected_date.strftime("%d.%m.%Y"))

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    manager_ids = (
        Selection.objects.values('manager')
        .annotate(count=Count('employee', distinct=True))
    )

    user_map = {
        user.id: user for user in CustomUser.objects.filter(
            id__in=[item['manager'] for item in manager_ids]
        )
    }

    manager_stats = []
    for item in manager_ids:
        manager = user_map.get(item['manager'])
        manager_stats.append({
            'id': manager.id,
            'manager': manager,
            'count': item['count'],
        })

    return render(request, 'users/management/overview.html', {
        'grouped': grouped,
        'manager_stats': manager_stats,
        'current_manager': int(manager_filter) if manager_filter else None
    })


@login_required
@permission_required('users.access_to_dp_rvd', raise_exception=True)
def export_rvd_excel(request):


    selections = Selection.objects.select_related('employee', 'manager').order_by('employee__name', 'selected_date')

    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫—É
    grouped = {}
    for sel in selections:
        emp = sel.employee
        key = emp.id
        if key not in grouped:
            grouped[key] = {
                "name": emp.name,
                "position": emp.position,
                "subdivision": "–î–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞",
                "dates": [],
                "xtk": "‚úÖ" if sel.is_xtk else "‚Äî",
                "justification": sel.justification,
                "total_hours": 0
            }
        time_range = f"({sel.start_time.strftime('%H:%M')}‚Äì{sel.end_time.strftime('%H:%M')})" if sel.start_time and sel.end_time else ""
        date_str = f"{sel.selected_date.strftime('%d.%m.%Y')}\n{time_range}"
        grouped[key]["dates"].append(date_str)
        grouped[key]["total_hours"] += sel.hours

    # Excel
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "–†–í–î"

    headers = ["‚Ññ", "–°–æ—Ç—Ä—É–¥–Ω–∏–∫", "–î–æ–ª–∂–Ω–æ—Å—Ç—å", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ", "–î–∞—Ç—ã", "–ß–∞—Å—ã", "–•–¢–ö", "–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"]
    ws.append(headers)

    alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
    thin_border = Border(left=Side(style='thin'), right=Side(style='thin'),
                         top=Side(style='thin'), bottom=Side(style='thin'))
    font = Font(name='Arial', size=10)

    for i, (emp_id, data) in enumerate(grouped.items(), 1):
        row = [
            i,
            data["name"],
            data["position"],
            data["subdivision"],
            '\n'.join(data["dates"]),
            data["total_hours"],
            data["xtk"],
            data["justification"]
        ]
        ws.append(row)

    ws.column_dimensions['A'].width = 4
    ws.column_dimensions['B'].width = 30
    ws.column_dimensions['C'].width = 25
    ws.column_dimensions['D'].width = 35
    ws.column_dimensions['E'].width = 20
    ws.column_dimensions['F'].width = 7
    ws.column_dimensions['G'].width = 7
    ws.column_dimensions['H'].width = 25

    for row in ws.iter_rows(min_row=2, max_row=ws.max_row, max_col=8):
        for cell in row:
            cell.alignment = alignment
            cell.border = thin_border
            cell.font = font

    response = HttpResponse(content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    filename = "–†–í–î –æ—Ç –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç–∞ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞.xlsx"
    response['Content-Disposition'] = f"attachment; filename*=UTF-8''{quote(filename)}"
    wb.save(response)
    return response


@login_required
@permission_required('users.access_to_dp_rvd', raise_exception=True)
def delete_all_selections_dp(request):

    if request.method == 'POST':
        Selection.objects.all().delete()
        messages.success(request, "‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω—ã.")
    return redirect('office_overview')


@login_required
@permission_required('users.access_to_dp_rvd', raise_exception=True)
def export_word_rvd(request):

    selections = Selection.objects.select_related('employee').all()

    # üìå –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º
    from collections import defaultdict
    grouped = defaultdict(lambda: {"dates": [], "position": "", "name": ""})
    for sel in selections:
        grouped[sel.employee_id]["name"] = sel.employee.name
        grouped[sel.employee_id]["position"] = sel.employee.position
        grouped[sel.employee_id]["dates"].append({
            "date": sel.selected_date,
            "start_time": sel.start_time.strftime("%H:%M") if sel.start_time else "",
            "end_time": sel.end_time.strftime("%H:%M") if sel.end_time else "",
            "hours": sel.hours
        })

    # üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —à–∞–±–ª–æ–Ω
    doc = Document("media/templates/messages_template_v2.docx")

    # ‚¨áÔ∏è –¢–∞–±–ª–∏—Ü–∞ ‚Äî –ø–µ—Ä–≤–∞—è
    table = doc.tables[1]

    # –£–¥–∞–ª–∏–º —Å—Ç–∞—Ä—ã–µ —Å—Ç—Ä–æ–∫–∏ –∫—Ä–æ–º–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    while len(table.rows) > 1:
        table._tbl.remove(table.rows[1]._tr)

    # üßæ –ó–∞–ø–æ–ª–Ω—è–µ–º
    for idx, (emp_id, data) in enumerate(grouped.items(), start=1):
        row = table.add_row().cells
        if len(row) < 9:
            raise ValueError("‚ùå –í —à–∞–±–ª–æ–Ω–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–ª–æ–Ω–æ–∫ ‚Äî –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 9")

        row[0].text = str(idx)                          # ‚Ññ
        row[1].text = data["name"]                      # –§–ò–û
        row[2].text = data["position"]                  # –î–æ–ª–∂–Ω–æ—Å—Ç—å
        row[3].text = ""                                # –°–æ–≥–ª–∞—Å–∏–µ / –Ω–µ—Å–æ–≥–ª–∞—Å–∏–µ
        row[4].text = ""                                # –° –æ–ø–ª–∞—Ç–æ–π
        row[5].text = ""                               # –î–µ–Ω—å –æ—Ç–¥—ã—Ö–∞
        dates_sorted = sorted(data["dates"], key=lambda x: x["date"])
        row[6].text = "\n".join(
            f"{d['date'].strftime('%d.%m.%Y')}\n({d['start_time']}‚Äì{d['end_time']})" for d in dates_sorted
        )
        row[7].text = str(sum(d["hours"] for d in dates_sorted))

    # üì• –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∞–π–ª
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)

    response = HttpResponse(
        buffer.getvalue(),
        content_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )

    filename = f"–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ_–æ_—Ä–∞–±–æ—Ç–µ_–≤_–≤—ã—Ö–æ–¥–Ω–æ–π_{datetime.now().date()}.docx"
    quoted_filename = quote(filename)

    response["Content-Disposition"] = f"attachment; filename*=UTF-8''{quoted_filename}"
    return response



@login_required
@permission_required('users.access_to_dp_rvd', raise_exception=True)
def overtime_overview(request):


    manager_filter = request.GET.get('manager')
    records = OvertimeRecord.objects.select_related('employee', 'added_by').order_by('-date')
    if manager_filter:
        records = records.filter(added_by__id=manager_filter)

    grouped_with_day_off = {}
    grouped_without_day_off = {}

    for r in records:
        key = r.employee.id

        group = {
            'employee': r.employee,
            'manager': r.added_by.get_full_name_with_patronymic()
            if hasattr(r.added_by, 'get_full_name_with_patronymic')
            else r.added_by.get_full_name(),
        }

        if r.compensated_day:
            if key not in grouped_with_day_off:
                grouped_with_day_off[key] = {**group, 'records': [], 'day_off_count': 0}
            grouped_with_day_off[key]['records'].append(r)
            grouped_with_day_off[key]['day_off_count'] += 1
        else:
            if key not in grouped_without_day_off:
                grouped_without_day_off[key] = {**group, 'records': [], 'pending_day_off_count': 0}
            grouped_without_day_off[key]['records'].append(r)
            grouped_without_day_off[key]['pending_day_off_count'] += 1

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞–º
    manager_ids = (
        OvertimeRecord.objects.values('added_by')
        .annotate(count=Count('employee', distinct=True))
    )
    user_map = {
        user.id: user for user in CustomUser.objects.filter(
            id__in=[item['added_by'] for item in manager_ids]
        )
    }

    manager_stats = []
    for item in manager_ids:
        manager = user_map.get(item['added_by'])
        if manager:
            manager_stats.append({
                'id': manager.id,
                'manager': manager,
                'count': item['count'],
            })

    return render(request, 'users/management/overtime_overview.html', {
        'with_day_off': grouped_with_day_off,
        'without_day_off': grouped_without_day_off,
        'manager_stats': manager_stats,
        'current_manager': int(manager_filter) if manager_filter else None,
    })


@login_required
@permission_required('users.access_to_dp_rvd', raise_exception=True)
def assign_day_off(request):



    record_id = request.POST.get("record_id")
    day_off = request.POST.get("day_off")

    try:
        record = OvertimeRecord.objects.get(id=record_id)
        record.compensated_day = day_off
        record.save()
        messages.success(request, "–í—ã—Ö–æ–¥–Ω–æ–π —É—Å–ø–µ—à–Ω–æ –Ω–∞–∑–Ω–∞—á–µ–Ω.")
    except OvertimeRecord.DoesNotExist:
        messages.error(request, "–ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    except Exception as e:
        messages.error(request, f"–û—à–∏–±–∫–∞: {str(e)}")

    return redirect(request.META.get('HTTP_REFERER', '/'))


@login_required
@permission_required('users.access_to_dp_rvd', raise_exception=True)
def update_day_off(request):


    record_id = request.POST.get('record_id')
    record = get_object_or_404(OvertimeRecord, id=record_id)

    if 'delete_day_off' in request.POST:
        record.compensated_day = None
    else:
        new_day_off = request.POST.get('new_day_off')
        record.compensated_day = new_day_off

    record.save()
    return redirect(request.META.get('HTTP_REFERER', '/'))


@login_required
@permission_required('users.access_to_dp_rvd', raise_exception=True)
def export_pending_day_off(request):


    records = OvertimeRecord.objects.filter(compensated_day__isnull=True).select_related('employee')

    grouped = {}
    for r in records:
        key = r.employee.id
        if key not in grouped:
            grouped[key] = {
                'name': r.employee.name,
                'dates': [],
                'debt': 0,
            }
        grouped[key]['dates'].append(r.date.strftime('%d.%m.%Y'))
        grouped[key]['debt'] += 1

    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "–î–æ–ª–≥–∏ –ø–æ –≤—ã—Ö–æ–¥–Ω—ã–º"
    ws.append(["–§–ò–û", "–î–∞—Ç—ã –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–æ–∫", "–î–æ–ª–≥ (–¥–Ω–µ–π)"])

    # –°—Ç–∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    header_font = Font(bold=True, size=13)
    for col in range(1, 4):
        cell = ws.cell(row=1, column=col)
        cell.font = header_font
        ws.column_dimensions[get_column_letter(col)].width = 30

    for i, data in enumerate(grouped.values(), start=2):
        ws.cell(row=i, column=1, value=data['name'])

        dates_str = "\n".join(data['dates'])
        cell_dates = ws.cell(row=i, column=2, value=dates_str)
        cell_dates.alignment = Alignment(wrap_text=True, vertical='top')

        ws.cell(row=i, column=3, value=data['debt'])

        # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤—ã—Å–æ—Ç—ã —Å—Ç—Ä–æ–∫–∏
        ws.row_dimensions[i].height = 15 * len(data['dates'])

    output = io.BytesIO()
    wb.save(output)
    output.seek(0)

    filename = f"overtime_debt_{date.today()}.xlsx"
    response = HttpResponse(
        output,
        content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    )
    response['Content-Disposition'] = f'attachment; filename="{filename}"'
    return response






@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def incoming_workshop_dashboard(request):
    today_str = now().date().isoformat()
    zone = "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"

    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è ‚Üí –∫–ª—é—á–∏ –ø–æ—Å—Ç–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏–∏
    POST_NAME_MAP = {
        "–ü–æ—Å—Ç –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤": "–ó–æ–Ω–∞ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤, DKD",
        "–ü–æ—Å—Ç –ø—Ä–∏–µ–º–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö": "–ó–æ–Ω–∞ –≤—ã–≥—Ä—É–∑–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö, DKD",
        "–ü–æ—Å—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏": "–ó–æ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏ DKD",
        "–ü–æ—Å—Ç –ø—Ä–∏–µ–º–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤": "–ü—Ä–∏–µ–º–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤",
    }

    # –°—á—ë—Ç—á–∏–∫–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
    post_vin_set = defaultdict(set)
    post_defect_counts = defaultdict(int)

    for history in VINHistory.objects.all():
        vin = history.vin
        posts = (history.history or {}).get(zone, {})

        # –ü—Ä–æ—Ö–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –ø–æ –Ω—É–∂–Ω—ã–º –ø–æ—Å—Ç–∞–º
        for display_title, post_key in POST_NAME_MAP.items():
            entries = posts.get(post_key, []) or []
            for entry in entries:
                raw_date = entry.get("date_added") or entry.get("date") or ""
                date_str = raw_date[:10]
                if date_str != today_str:
                    continue

                # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã –∑–∞ —Å–µ–≥–æ–¥–Ω—è: –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ —Å—á–∏—Ç–∞–µ–º –ø–æ –Ω–æ–º–µ—Ä—É –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞, –∏–Ω–∞—á–µ –ø–æ VIN
                if post_key == "–ü—Ä–∏–µ–º–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤":
                    key_item = entry.get("container_number") or f"no-container-{vin}"
                else:
                    key_item = vin
                post_vin_set[post_key].add(key_item)

                # –ü–æ–¥—Å—á—ë—Ç –¥–µ—Ñ–µ–∫—Ç–æ–≤: –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç (—Å–ø–∏—Å–æ–∫ dict'–æ–≤) –∏–ª–∏ —Ñ–ª–∞–≥ has_defect
                defects = entry.get("defects")
                if isinstance(defects, list):
                    post_defect_counts[post_key] += len(defects)
                elif entry.get("has_defect") == "yes":
                    post_defect_counts[post_key] += 1

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞
    posts = [
        {
            "title": "–ü–æ—Å—Ç –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤",
            "icon": "",
            "report_url": reverse("body_inspection_report"),
            "table_url": reverse("body_inspection_table"),
            "export_url": reverse("body_inspection_export"),
            "form_url": reverse("body_inspection_form"),
            "today_vins": len(post_vin_set.get(POST_NAME_MAP["–ü–æ—Å—Ç –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤"], set())),
            "today_entries": post_defect_counts.get(POST_NAME_MAP["–ü–æ—Å—Ç –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤"], 0),
        },
        {
            "title": "–ü–æ—Å—Ç –ø—Ä–∏–µ–º–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö",
            "icon": "",
            "report_url": reverse("parts_acceptance_report"),
            "table_url": reverse("parts_acceptance_table"),
            "export_url": reverse("parts_acceptance_export"),
            "form_url": reverse("parts_acceptance_form"),
            "today_vins": len(post_vin_set.get(POST_NAME_MAP["–ü–æ—Å—Ç –ø—Ä–∏–µ–º–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö"], set())),
            "today_entries": post_defect_counts.get(POST_NAME_MAP["–ü–æ—Å—Ç –ø—Ä–∏–µ–º–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö"], 0),
        },
        {
            "title": "–ü–æ—Å—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏",
            "icon": "",
            "report_url": reverse("final_acceptance_report"),
            "table_url": reverse("final_acceptance_table"),
            "export_url": reverse("final_acceptance_export"),
            "form_url": reverse("final_acceptance_form"),
            "today_vins": len(post_vin_set.get(POST_NAME_MAP["–ü–æ—Å—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏"], set())),
            "today_entries": post_defect_counts.get(POST_NAME_MAP["–ü–æ—Å—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏"], 0),
        },
        {
            "title": "–ü–æ—Å—Ç –ø—Ä–∏–µ–º–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤",
            "icon": "",
            "report_url": "#",  # –∑–∞–≥–ª—É—à–∫–∞
            "table_url": reverse("containers_acceptance_table"),
            "export_url": reverse("containers_acceptance_export"),
            "form_url": "#",  # –∑–∞–≥–ª—É—à–∫–∞
            "today_vins": len(post_vin_set.get(POST_NAME_MAP["–ü–æ—Å—Ç –ø—Ä–∏–µ–º–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"], set())),
            "today_entries": post_defect_counts.get(POST_NAME_MAP["–ü–æ—Å—Ç –ø—Ä–∏–µ–º–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"], 0),
        },
    ]

    return render(request, "users/incoming/incoming_workshop_dashboard.html", {
        "posts": posts,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    })


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def incoming_general_report(request):
    posts_info = {
        "body_inspection": {
            "zone": "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏",
            "post": "–ó–æ–Ω–∞ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤, DKD",
            "title": "–ü–æ—Å—Ç –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤",
        },
        "parts_acceptance": {
            "zone": "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏",
            "post": "–ó–æ–Ω–∞ –≤—ã–≥—Ä—É–∑–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö, DKD",
            "title": "–ü–æ—Å—Ç –ø—Ä–∏—ë–º–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö",
        },
        "final_acceptance": {
            "zone": "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏",
            "post": "–ó–æ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏ DKD",
            "title": "–ü–æ—Å—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏—ë–º–∫–∏",
        }
    }

    # –ü–µ—Ä–∏–æ–¥
    period = request.GET.get("period", "week")
    today = now().date()

    start_date_str = request.GET.get("start_date")
    end_date_str = request.GET.get("end_date")

    try:
        start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date() if start_date_str else None
        end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date() if end_date_str else None
    except ValueError:
        start_date = end_date = None

    if not (start_date and end_date):
        if period == "day":
            start_date = end_date = today
        elif period == "month":
            start_date = today - timedelta(days=30)
            end_date = today
        elif period == "all":
            start_date = end_date = None
        else:
            start_date = today - timedelta(days=7)
            end_date = today

    overall_total_inspections = 0
    overall_inspections_with_defects = 0
    overall_total_defects = 0
    overall_bodies_without_offline_defects = 0

    posts_data = {}

    for key, info in posts_info.items():
        zone = info["zone"]
        post = info["post"]

        vins_with_entries = set()
        vins_with_defects = set()
        vins_without_offline = set()
        defect_counter = Counter()
        controller_counter = Counter()
        controller_vin_pairs = set()
        total_defects = 0

        for history in VINHistory.objects.all():
            vin = history.vin
            zone_data = history.history.get(zone, {})
            post_entries = zone_data.get(post, [])

            for entry in post_entries:
                raw_date = entry.get("date_added")
                if not raw_date:
                    continue

                entry_date = parse_date(raw_date[:10])
                if start_date and entry_date < start_date:
                    continue
                if end_date and entry_date > end_date:
                    continue

                vins_with_entries.add(vin)

                defects = entry.get("defects", [])
                controller = entry.get("controller", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                has_offline = False
                filtered = []

                for defect in defects:
                    if defect.get("repair_type") == "offline":
                        has_offline = True

                    detail = defect.get("detail", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                    name = defect.get("defect", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                    quantity = defect.get("quantity") or 1
                    try:
                        quantity = max(int(quantity), 1)
                    except (TypeError, ValueError):
                        quantity = 1

                    key = f"{detail} ‚Äî {name}"
                    defect_counter[key] += quantity
                    total_defects += quantity
                    filtered.append(defect)

                if defects:
                    vins_with_defects.add(vin)

                if not has_offline:
                    vins_without_offline.add(vin)

                if filtered and (controller, vin) not in controller_vin_pairs:
                    controller_counter[controller] += 1
                    controller_vin_pairs.add((controller, vin))

        total_inspections = len(vins_with_entries)
        inspections_with_defects = len(vins_with_defects)
        inspections_without_defects = total_inspections - inspections_with_defects
        total_without_offline = len(vins_without_offline)

        dpu = round(total_defects / total_inspections, 2) if total_inspections else 0
        str_percentage = round((total_without_offline / total_inspections) * 100, 2) if total_inspections else 0

        posts_data[key] = {
            "title": info["title"],
            "total_inspections": total_inspections,
            "inspections_with_defects": inspections_with_defects,
            "inspections_without_defects": inspections_without_defects,
            "without_defects": total_inspections - inspections_with_defects,
            "total_defects": total_defects,
            "dpu": dpu,
            "str_percentage": str_percentage,
            "top_defects": defect_counter.most_common(5),
            "top_controllers": controller_counter.most_common(5),
        }

        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        overall_total_inspections += total_inspections
        overall_inspections_with_defects += inspections_with_defects
        overall_total_defects += total_defects
        overall_bodies_without_offline_defects += total_without_offline

    inspections_without_defects = overall_total_inspections - overall_inspections_with_defects

    if overall_total_inspections == 0:
        overall_dpu = 0
        overall_str_percentage = 0
    else:
        overall_dpu = round(overall_total_defects / overall_total_inspections, 2)
        overall_str_percentage = round((overall_bodies_without_offline_defects / overall_total_inspections) * 100, 2)

    context = {
        "period": period,
        "start_date": start_date_str or '',
        "end_date": end_date_str or '',
        "overall_total_inspections": overall_total_inspections,
        "overall_inspections_with_defects": overall_inspections_with_defects,
        "overall_without_defects": inspections_without_defects,
        "overall_total_defects": overall_total_defects,
        "overall_dpu": overall_dpu,
        "overall_str_percentage": overall_str_percentage,
        "posts_data": posts_data,
    }

    return render(request, "users/incoming/incoming_general_report.html", context)


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def body_inspection_report(request):
    zone = "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"
    post = "–ó–æ–Ω–∞ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤, DKD"

    period = request.GET.get("period", "week")
    today = now().date()

    start_date_str = request.GET.get("start_date")
    end_date_str = request.GET.get("end_date")

    selected_brands = request.GET.getlist("brand")
    all_brands = TraceData.objects.values_list("brand", flat=True).distinct()

    try:
        custom_start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date() if start_date_str else None
        custom_end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date() if end_date_str else None
    except ValueError:
        custom_start_date = custom_end_date = None

    if custom_start_date and custom_end_date:
        start_date = custom_start_date
        end_date = custom_end_date
    elif period == "day":
        start_date = today
        end_date = today
    elif period == "month":
        start_date = today - timedelta(days=30)
        end_date = today
    elif period == "all":
        start_date = None
        end_date = None
    else:
        start_date = today - timedelta(days=7)
        end_date = today

    selected_grades = request.GET.getlist("grade")
    all_grades = ["V1+", "V1", "V2", "V3"]

    # ‚úÖ –ü—Ä–∏–≤–æ–¥–∏–º –±—Ä–µ–Ω–¥—ã –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    normalized_selected_brands = [b.strip().lower() for b in selected_brands]

    total_defects = 0
    defect_detail_counter = Counter()
    controller_counter = Counter()
    controller_vin_pairs = set()

    vins_with_entries = set()
    defective_vins = set()
    vins_with_offline_defects = set()

    for history in VINHistory.objects.all():
        vin = history.vin

        # ‚úÖ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–∞—Ä–∫–∞–º —á–µ—Ä–µ–∑ TraceData
        if normalized_selected_brands:
            trace = TraceData.objects.filter(vin_rk__iexact=vin).first()
            if not trace or trace.brand.strip().lower() not in normalized_selected_brands:
                continue

        zone_data = history.history.get(zone, {})
        post_entries = zone_data.get(post, [])

        for entry in post_entries:
            raw_date = entry.get("date_added")
            if not raw_date:
                continue

            entry_date = parse_date(raw_date[:10])
            if start_date and entry_date < start_date:
                continue
            if end_date and entry_date > end_date:
                continue

            vins_with_entries.add(vin)

            defects = entry.get("defects", [])
            controller = entry.get("controller", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
            has_offline_defect = False

            filtered_defects = []

            for defect in defects:
                grade = defect.get("grade", "")
                if not selected_grades or grade in selected_grades:
                    filtered_defects.append(defect)
                    if defect.get("repair_type") == "offline":
                        has_offline_defect = True

            if defects:
                defective_vins.add(vin)

            if has_offline_defect:
                vins_with_offline_defects.add(vin)

            if filtered_defects:
                for defect in filtered_defects:
                    defect_name = defect.get("defect", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                    detail_name = defect.get("detail", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                    try:
                        quantity = int(defect.get("quantity", 1))
                        quantity = max(quantity, 1)
                    except (TypeError, ValueError):
                        quantity = 1

                    key = f"{detail_name} ‚Äî {defect_name}"
                    defect_detail_counter[key] += quantity
                    total_defects += quantity

                if controller and vin and (controller, vin) not in controller_vin_pairs:
                    controller_counter[controller] += 1
                    controller_vin_pairs.add((controller, vin))

    total_inspections = len(vins_with_entries)
    inspections_with_defects = len(defective_vins)
    total_with_offline_defects = len(vins_with_offline_defects)

    if total_inspections == 0:
        dpu = 0
        str_percentage = 0
    else:
        dpu = round(total_defects / total_inspections, 2)
        str_percentage = round((total_inspections - total_with_offline_defects) / total_inspections * 100, 2)

    context = {
        "all_grades": all_grades,
        "selected_grades": selected_grades,
        "all_brands": all_brands,
        "selected_brands": selected_brands,  # ‚úÖ –ø–µ—Ä–µ–¥–∞—ë–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è —à–∞–±–ª–æ–Ω–∞
        "total_inspections": total_inspections,
        "total_defects": total_defects,
        "dpu": dpu,
        "str_percentage": str_percentage,
        "top_defects": defect_detail_counter.most_common(20),
        "top_controllers": controller_counter.most_common(20),
        "start_date": start_date_str or '',
        "end_date": end_date_str or '',
        "bodies_without_any_defects": total_inspections - inspections_with_defects,
        "inspections_with_defects": inspections_with_defects,
    }

    return render(request, "users/incoming/body_inspection_report.html", context)


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def body_inspection_table(request):
    zone = "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"
    post = "–ó–æ–Ω–∞ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤, DKD"

    records = []
    for history in VINHistory.objects.all():
        vin = history.vin
        zone_data = history.history.get(zone, {})
        post_entries = zone_data.get(post, [])

        for entry in post_entries:
            defects = entry.get("defects", [])
            raw_date = entry.get("date_added")
            date = parse_datetime(raw_date) if raw_date else None
            controller = entry.get("controller") or entry.get("extra_data", {}).get("controller", "")
            body_photos = entry.get("body_photos", []) or entry.get("extra_data", {}).get("body_photos", [])

            # üîπ –ù–æ–≤–æ–µ: –±–µ—Ä—ë–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –Ω–æ–º–µ—Ä –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ (—Å –∑–∞–ø–∞—Å–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º –∏–∑ extra_data)
            inspection_time = (
                entry.get("inspection_duration_seconds")
                or entry.get("extra_data", {}).get("inspection_duration_seconds")
            )
            container_number = (
                entry.get("container_number")
                or entry.get("extra_data", {}).get("container_number")
            )

            group_key = f"{vin}_{raw_date}"

            if defects:
                for defect in defects:
                    records.append({
                        "vin": vin,
                        "date": date,
                        "controller": controller,
                        "grade": defect.get("grade"),
                        "defect": defect.get("defect"),
                        "detail": defect.get("detail"),
                        "quantity": defect.get("quantity"),
                        "repair_type": defect.get("repair_type"),
                        "responsible": defect.get("responsible"),
                        "comment": defect.get("custom_detail_explanation"),
                        "extra_comment": defect.get("custom_defect_explanation"),
                        "photos": defect.get("defect_photos", []),
                        "photos_json": json.dumps(defect.get("defect_photos", [])),
                        "body_photos": body_photos,
                        "body_photos_json": json.dumps(body_photos),
                        "has_defect": True,
                        "group_key": group_key,

                        # üîπ –ù–æ–≤—ã–µ –ø–æ–ª—è –≤ –∑–∞–ø–∏—Å–∏
                        "inspection_time": inspection_time,
                        "container_number": container_number,
                    })
            else:
                records.append({
                    "vin": vin,
                    "date": date,
                    "controller": controller,
                    "grade": None,
                    "defect": "–ë–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤",
                    "detail": None,
                    "quantity": None,
                    "repair_type": None,
                    "responsible": None,
                    "comment": None,
                    "extra_comment": None,
                    "photos": [],
                    "photos_json": [],
                    "body_photos": body_photos,
                    "body_photos_json": json.dumps(body_photos),
                    "has_defect": False,
                    "group_key": group_key,

                    # üîπ –¢–æ–∂–µ –ø—Ä–æ–∫–∏–¥—ã–≤–∞–µ–º —Å—é–¥–∞
                    "inspection_time": inspection_time,
                    "container_number": container_number,
                })

    records.sort(key=lambda r: r["date"] or timezone.datetime.min, reverse=True)

    # --- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–æ–≤
    all_controllers = {r["controller"] for r in records if r.get("controller")}
    controller_users_qs = CustomUser.objects.filter(username__in=all_controllers)
    controller_users = {user.username: user for user in controller_users_qs}

    # --- TraceData –ø–æ VIN
    vin_list = list({r["vin"] for r in records if r.get("vin")})
    trace_data = TraceData.objects.filter(vin_rk__in=vin_list)
    vin_trace_map = {
        td.vin_rk: {"brand": td.brand, "model": td.model, "config_code": td.config_code}
        for td in trace_data
    }

    return render(request, "users/incoming/body_table.html", {
        "records": records,
        "controller_users": controller_users,
        "vin_trace_map": vin_trace_map,
    })


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def body_inspection_form(request):
    """–†—É—á–Ω–æ–µ –≤–Ω–µ—Å–µ–Ω–∏–µ –æ—Å–º–æ—Ç—Ä–∞ ‚Äî –ó–æ–Ω–∞ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤ (DKD)"""

    post = get_object_or_404(Post, name="–ó–æ–Ω–∞ –ø–µ—Ä–≤–∏—á–Ω–æ–≥–æ –æ—Å–º–æ—Ç—Ä–∞ –∫—É–∑–æ–≤–æ–≤, DKD")

    details = BodyDetail.objects.filter(posts=post)
    defects = Defect.objects.filter(posts=post)
    defect_grades = DefectGrade.objects.all()
    defect_responsibles = DefectResponsible.objects.filter(posts=post)

    if request.method == "POST":
        form = BodyUnloadingZoneDKDForm(request.POST, request.FILES, post_id=post.id)

        if form.is_valid():
            vin_number = form.cleaned_data.get("vin_number")
            container_number = form.cleaned_data.get("container_number", "").strip()
            manual_date_str = request.POST.get("manual_inspection_date")

            try:
                manual_date = datetime.strptime(manual_date_str, "%Y-%m-%d")
                manual_date_full = datetime.combine(manual_date.date(), time(0, 0))
                date_added = make_aware(manual_date_full).isoformat()
            except Exception:
                date_added = now_almaty_iso()

            history_entry, _ = VINHistory.objects.get_or_create(vin=vin_number)
            zone = post.location
            post_name = post.name

            body_photo_urls = []
            body_photos = form.cleaned_data["body_photos"]
            if body_photos:
                for file in body_photos:
                    compressed = compress_uploaded_image(file)
                    file_path = f"images/body_photos/{compressed.name}"
                    os.makedirs(os.path.join(settings.MEDIA_ROOT, "images/body_photos"), exist_ok=True)
                    with open(os.path.join(settings.MEDIA_ROOT, file_path), "wb+") as dest:
                        for chunk in compressed.chunks():
                            dest.write(chunk)
                    body_photo_urls.append(f"{settings.MEDIA_URL}{file_path}")

            has_defect = request.POST.get("has_defect", "")

            if has_defect == "no":
                inspection_data = {
                    "vin_number": vin_number,
                    "controller": request.user.username,
                    "defects": [],
                    "body_photos": body_photo_urls,
                    "date_added": date_added,
                }
                if container_number:
                    inspection_data["container_number"] = container_number

                try:
                    inspection_data["inspection_duration_seconds"] = int(request.POST.get("inspection_duration_seconds"))
                except (ValueError, TypeError):
                    inspection_data["inspection_duration_seconds"] = None

                history_entry.history.setdefault(zone, {}).setdefault(post_name, []).append(inspection_data)
                history_entry.save()

                messages.success(request, "‚úÖ –û—Å–º–æ—Ç—Ä –±–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω!")
                return redirect("body_inspection_form")

            # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–µ—Ñ–µ–∫—Ç—ã
            defect_index = 1
            while f"responsible_{defect_index}" in request.POST:
                responsible_obj = DefectResponsible.objects.filter(id=request.POST.get(f"responsible_{defect_index}")).first()
                detail_obj = BodyDetail.objects.filter(id=request.POST.get(f"detail_{defect_index}")).first()
                defect_obj = Defect.objects.filter(id=request.POST.get(f"defect_{defect_index}")).first()
                grade_obj = DefectGrade.objects.filter(id=request.POST.get(f"grade_{defect_index}")).first()

                defect_data = {
                    "responsible": responsible_obj.name if responsible_obj else None,
                    "detail": detail_obj.name if detail_obj else None,
                    "custom_detail_explanation": request.POST.get(f"custom_detail_explanation_{defect_index}"),
                    "defect": defect_obj.name if defect_obj else None,
                    "custom_defect_explanation": request.POST.get(f"custom_defect_explanation_{defect_index}"),
                    "quantity": request.POST.get(f"quantity_{defect_index}", 1),
                    "grade": grade_obj.name if grade_obj else None,
                    "repair_type": request.POST.get(f"repair_type_{defect_index}"),
                    "defect_photos": [],
                }

                defect_photo_urls = []
                for file in request.FILES.getlist(f"defect_photos_{defect_index}"):
                    compressed = compress_uploaded_image(file)
                    file_path = f"images/defects/{compressed.name}"
                    os.makedirs(os.path.join(settings.MEDIA_ROOT, "images/defects"), exist_ok=True)
                    with open(os.path.join(settings.MEDIA_ROOT, file_path), "wb+") as dest:
                        for chunk in compressed.chunks():
                            dest.write(chunk)
                    defect_photo_urls.append(f"{settings.MEDIA_URL}{file_path}")

                defect_data["defect_photos"] = defect_photo_urls

                inspection_data = {
                    "vin_number": vin_number,
                    "controller": request.user.username,
                    "defects": [defect_data],
                    "body_photos": body_photo_urls,
                    "date_added": date_added,
                }

                if container_number:
                    inspection_data["container_number"] = container_number

                try:
                    inspection_data["inspection_duration_seconds"] = int(request.POST.get("inspection_duration_seconds"))
                except (ValueError, TypeError):
                    inspection_data["inspection_duration_seconds"] = None

                history_entry.history.setdefault(zone, {}).setdefault(post_name, []).append(inspection_data)
                defect_index += 1

            history_entry.save()
            messages.success(request, "‚úÖ –ò–Ω—Å–ø–µ–∫—Ü–∏—è —Å –¥–µ—Ñ–µ–∫—Ç–∞–º–∏ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
            return redirect("body_inspection_form")

        else:
            messages.error(request, "‚ùå –û—à–∏–±–∫–∞: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ!")

    else:
        form = BodyUnloadingZoneDKDForm(post_id=post.id)

    return render(request, "users/incoming/body_inspection_form.html", {
        "form": form,
        "details": details,
        "defects": defects,
        "defect_grades": defect_grades,
        "defect_responsibles": defect_responsibles,
        "post": post,
    })


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def body_inspection_export(request):
    return render(request, "users/incoming/body_inspection_export.html")


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def parts_acceptance_report(request):
    zone = "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"
    post = "–ó–æ–Ω–∞ –≤—ã–≥—Ä—É–∑–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö, DKD"

    # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ
    period = request.GET.get("period", "week")
    today = now().date()

    start_date_str = request.GET.get("start_date")
    end_date_str = request.GET.get("end_date")

    try:
        custom_start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date() if start_date_str else None
        custom_end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date() if end_date_str else None
    except ValueError:
        custom_start_date = custom_end_date = None

    if custom_start_date and custom_end_date:
        start_date = custom_start_date
        end_date = custom_end_date
    elif period == "day":
        start_date = today
        end_date = today
    elif period == "month":
        start_date = today - timedelta(days=30)
        end_date = today
    elif period == "all":
        start_date = None
        end_date = None
    else:
        start_date = today - timedelta(days=7)
        end_date = today

    selected_grades = request.GET.getlist("grade")
    all_grades = ["V1+", "V1", "V2", "V3"]

    total_defects = 0
    defect_detail_counter = Counter()
    controller_counter = Counter()
    controller_vin_pairs = set()

    vins_with_entries = set()
    defective_vins = set()
    vins_with_offline_defects = set()

    for history in VINHistory.objects.all():
        vin = history.vin
        zone_data = history.history.get(zone, {})
        post_entries = zone_data.get(post, [])

        for entry in post_entries:
            raw_date = entry.get("date_added")
            if not raw_date:
                continue

            entry_date = parse_date(raw_date[:10])
            if start_date and entry_date < start_date:
                continue
            if end_date and entry_date > end_date:
                continue

            vins_with_entries.add(vin)

            defects = entry.get("defects", [])
            controller = entry.get("controller", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
            has_offline_defect = False

            filtered_defects = []

            for defect in defects:
                grade = defect.get("grade", "")
                if not selected_grades or grade in selected_grades:
                    filtered_defects.append(defect)
                    if defect.get("repair_type") == "offline":
                        has_offline_defect = True

            if defects:
                defective_vins.add(vin)

            if has_offline_defect:
                vins_with_offline_defects.add(vin)

            if filtered_defects:
                for defect in filtered_defects:
                    defect_name = defect.get("defect", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                    detail_name = defect.get("detail", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                    try:
                        quantity = int(defect.get("quantity", 1))
                        quantity = max(quantity, 1)
                    except (TypeError, ValueError):
                        quantity = 1

                    key = f"{detail_name} ‚Äî {defect_name}"
                    defect_detail_counter[key] += quantity
                    total_defects += quantity

                if controller and vin and (controller, vin) not in controller_vin_pairs:
                    controller_counter[controller] += 1
                    controller_vin_pairs.add((controller, vin))

    total_inspections = len(vins_with_entries)
    inspections_with_defects = len(defective_vins)
    total_with_offline_defects = len(vins_with_offline_defects)

    if total_inspections == 0:
        dpu = 0
        str_percentage = 0
    else:
        dpu = round(total_defects / total_inspections, 2)
        str_percentage = round((total_inspections - total_with_offline_defects) / total_inspections * 100, 2)

    context = {
        "all_grades": all_grades,
        "selected_grades": selected_grades,
        "total_inspections": total_inspections,
        "total_defects": total_defects,
        "dpu": dpu,
        "str_percentage": str_percentage,
        "top_defects": defect_detail_counter.most_common(20),
        "top_controllers": controller_counter.most_common(20),
        "start_date": start_date_str or '',
        "end_date": end_date_str or '',
        "bodies_without_any_defects": total_inspections - inspections_with_defects,
        "inspections_with_defects": inspections_with_defects,
    }

    return render(request, "users/incoming/parts_acceptance_report.html", context)


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def parts_acceptance_table(request):
    zone = "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"
    post = "–ó–æ–Ω–∞ –≤—ã–≥—Ä—É–∑–∫–∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö, DKD"

    records = []

    for history in VINHistory.objects.all():
        vin = history.vin
        post_entries = history.history.get(zone, {}).get(post, [])

        for entry in post_entries:
            raw_date = entry.get("date_added")
            date = parse_datetime(raw_date) if raw_date else None
            controller = entry.get("controller", "") or entry.get("extra_data", {}).get("controller", "")
            engine_number = entry.get("engine_number", "")
            engine_photo = entry.get("engine_photo", "")
            component_photos = entry.get("component_photos", [])
            inspection_time = entry.get("inspection_duration_seconds", None)
            defects = entry.get("defects", [])
            group_key = f"{vin}_{raw_date}"

            if defects:
                for defect in defects:
                    records.append({
                        "vin": vin,
                        "date": date,
                        "controller": controller,
                        "engine_number": engine_number,
                        "engine_photo": engine_photo,
                        "component_photos": component_photos,
                        "grade": defect.get("grade"),
                        "defect": defect.get("defect"),
                        "detail": defect.get("detail"),
                        "quantity": defect.get("quantity"),
                        "repair_type": defect.get("repair_type"),
                        "responsible": defect.get("responsible"),
                        "comment": defect.get("custom_defect_explanation"),
                        "extra_comment": defect.get("custom_detail_explanation"),
                        "photos": defect.get("defect_photos", []),
                        "has_defect": True,
                        "group_key": group_key,
                        "inspection_time": inspection_time,
                    })
            else:
                records.append({
                    "vin": vin,
                    "date": date,
                    "controller": controller,
                    "engine_number": engine_number,
                    "engine_photo": engine_photo,
                    "component_photos": component_photos,
                    "grade": None,
                    "defect": "–ë–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤",
                    "detail": None,
                    "quantity": None,
                    "repair_type": None,
                    "responsible": None,
                    "comment": None,
                    "extra_comment": None,
                    "photos": [],
                    "has_defect": False,
                    "group_key": group_key,
                    "inspection_time": inspection_time,
                })

    records.sort(key=lambda r: r["date"] or timezone.datetime.min, reverse=True)

    return render(request, "users/incoming/parts_acceptance_table.html", {"records": records})


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def parts_acceptance_export(request):
    return render(request, "users/incoming/part_acceptance_export.html")


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def parts_acceptance_form(request):
    return render(request, "users/incoming/forms/parts_acceptance_form.html")


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def final_acceptance_report(request):
    zone = "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"
    post = "–ó–æ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏ DKD"

    period = request.GET.get("period", "week")
    today = now().date()


    start_date_str = request.GET.get("start_date")
    end_date_str = request.GET.get("end_date")

    selected_brands = request.GET.getlist("brand")
    all_brands = TraceData.objects.values_list("brand", flat=True).distinct()

    try:
        custom_start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date() if start_date_str else None
        custom_end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date() if end_date_str else None
    except ValueError:
        custom_start_date = custom_end_date = None

    if custom_start_date and custom_end_date:
        start_date = custom_start_date
        end_date = custom_end_date
    elif period == "day":
        start_date = today
        end_date = today
    elif period == "month":
        start_date = today - timedelta(days=30)
        end_date = today
    elif period == "all":
        start_date = None
        end_date = None
    else:
        start_date = today - timedelta(days=7)
        end_date = today

    selected_grades = request.GET.getlist("grade")
    all_grades = ["V1+", "V1", "V2", "V3"]
    normalized_selected_brands = [b.strip().lower() for b in selected_brands]

    total_defects = 0
    defect_detail_counter = Counter()
    controller_counter = Counter()
    controller_vin_pairs = set()

    vins_with_entries = set()
    defective_vins = set()
    vins_with_offline_defects = set()

    for history in VINHistory.objects.all():
        zone_data = history.history.get(zone, {})
        post_entries = zone_data.get(post, [])

        for entry in post_entries:
            raw_date = entry.get("date_added")
            if not raw_date:
                continue

            entry_date = parse_date(raw_date[:10])
            if start_date and entry_date < start_date:
                continue
            if end_date and entry_date > end_date:
                continue

            vin_entry = entry.get("vin_number") or history.vin
            vins_with_entries.add(vin_entry)

            # ‚úÖ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –±—Ä–µ–Ω–¥—É
            if normalized_selected_brands:
                trace = TraceData.objects.filter(vin_rk__iexact=vin_entry).first()
                if not trace or trace.brand.strip().lower() not in normalized_selected_brands:
                    continue

            defects = entry.get("defects", [])
            controller = entry.get("controller", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
            has_offline_defect = False
            filtered_defects = []

            for defect in defects:
                grade = defect.get("grade", "")
                if not selected_grades or grade in selected_grades:
                    filtered_defects.append(defect)
                    if defect.get("repair_type") == "offline":
                        has_offline_defect = True

            if defects:
                defective_vins.add(vin_entry)

            if has_offline_defect:
                vins_with_offline_defects.add(vin_entry)

            if filtered_defects:
                for defect in filtered_defects:
                    defect_name = defect.get("defect", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                    detail_name = defect.get("detail", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                    try:
                        quantity = int(defect.get("quantity", 1))
                        quantity = max(quantity, 1)
                    except (TypeError, ValueError):
                        quantity = 1

                    key = f"{detail_name} ‚Äî {defect_name}"
                    defect_detail_counter[key] += quantity
                    total_defects += quantity

                if controller and vin_entry and (controller, vin_entry) not in controller_vin_pairs:
                    controller_counter[controller] += 1
                    controller_vin_pairs.add((controller, vin_entry))

    total_inspections = len(vins_with_entries)
    inspections_with_defects = len(defective_vins)
    total_with_offline_defects = len(vins_with_offline_defects)

    if total_inspections == 0:
        dpu = 0
        str_percentage = 0
    else:
        dpu = round(total_defects / total_inspections, 2)
        str_percentage = round((total_inspections - total_with_offline_defects) / total_inspections * 100, 2)

    context = {
        "all_grades": all_grades,
        "selected_grades": selected_grades,
        "all_brands": all_brands,
        "selected_brands": selected_brands,
        "total_inspections": total_inspections,
        "total_defects": total_defects,
        "dpu": dpu,
        "str_percentage": str_percentage,
        "top_defects": defect_detail_counter.most_common(20),
        "top_controllers": controller_counter.most_common(20),
        "start_date": start_date_str or '',
        "end_date": end_date_str or '',
        "bodies_without_any_defects": total_inspections - inspections_with_defects,
        "inspections_with_defects": inspections_with_defects,
    }

    return render(request, "users/incoming/final_acceptance_report.html", context)


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def final_acceptance_table(request):
    zone = "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"
    post = "–ó–æ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏ DKD"

    records = []

    for history in VINHistory.objects.all():
        vin = history.vin
        post_entries = history.history.get(zone, {}).get(post, [])

        for entry in post_entries:
            raw_date = entry.get("date_added")
            date = parse_datetime(raw_date) if raw_date else None
            controller = entry.get("controller", "") or entry.get("extra_data", {}).get("controller", "")
            body_photos = entry.get("body_photos", []) or entry.get("extra_data", {}).get("body_photos", [])
            inspection_time = entry.get("inspection_duration_seconds", None)
            defects = entry.get("defects", [])
            group_key = f"{vin}_{raw_date}"

            if defects:
                for defect in defects:
                    records.append({
                        "vin": vin,
                        "date": date,
                        "controller": controller,
                        "grade": defect.get("grade"),
                        "defect": defect.get("defect"),
                        "detail": defect.get("detail"),
                        "quantity": defect.get("quantity"),
                        "repair_type": defect.get("repair_type"),
                        "responsible": defect.get("responsible"),
                        "comment": defect.get("custom_detail_explanation"),
                        "extra_comment": defect.get("custom_defect_explanation"),
                        "photos": defect.get("defect_photos", []),
                        "body_photos": body_photos,
                        "inspection_time": inspection_time,
                        "has_defect": True,
                        "group_key": group_key,
                    })
            else:
                records.append({
                    "vin": vin,
                    "date": date,
                    "controller": controller,
                    "grade": None,
                    "defect": "–ë–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤",
                    "detail": None,
                    "quantity": None,
                    "repair_type": None,
                    "responsible": None,
                    "comment": None,
                    "extra_comment": None,
                    "photos": [],
                    "body_photos": body_photos,
                    "inspection_time": inspection_time,
                    "has_defect": False,
                    "group_key": group_key,
                })

    records.sort(key=lambda r: r["date"] or timezone.datetime.min, reverse=True)

    return render(request, "users/incoming/final_acceptance_table.html", {"records": records})


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def final_acceptance_export(request):
    return render(request, "users/incoming/final_acceptance_export.html")


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def final_acceptance_form(request):
    """–†—É—á–Ω–æ–µ –≤–Ω–µ—Å–µ–Ω–∏–µ –∏–Ω—Å–ø–µ–∫—Ü–∏–∏ ‚Äî –ó–æ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏—ë–º–∫–∏ DKD"""

    post = get_object_or_404(Post, name="–ó–æ–Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–µ–º–∫–∏ DKD")

    details = BodyDetail.objects.all()
    defects = Defect.objects.filter(posts=post)
    defect_grades = DefectGrade.objects.all()
    defect_responsibles = DefectResponsible.objects.filter(posts=post)

    vin_history = None

    if request.method == "POST":
        form = MainUnloadingZoneDKDForm(request.POST, request.FILES, post_id=post.id)

        if form.is_valid():
            vin_number = form.cleaned_data.get("vin_number")
            if not vin_number:
                messages.error(request, "‚ùå VIN –Ω–æ–º–µ—Ä –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω.")
                return redirect("final_acceptance_form")

            history_entry, _ = VINHistory.objects.get_or_create(vin=vin_number)

            zone = post.location
            post_name = post.name

            # üìå –î–∞—Ç–∞, –≤–≤–µ–¥—ë–Ω–Ω–∞—è –≤—Ä—É—á–Ω—É—é
            manual_date_str = request.POST.get("manual_inspection_date")
            try:
                manual_date = datetime.strptime(manual_date_str, "%Y-%m-%d")
                manual_date_aware = make_aware(manual_date)
                date_added = manual_date_aware.isoformat()
            except Exception:
                date_added = now_almaty_iso()

            # ‚úÖ –§–æ—Ç–æ –∫—É–∑–æ–≤–∞
            body_photo_urls = []
            for file in form.cleaned_data["body_photos"]:
                compressed = compress_uploaded_image(file)
                file_path = f"images/body_photos/{compressed.name}"
                os.makedirs(os.path.join(settings.MEDIA_ROOT, "images/body_photos"), exist_ok=True)
                with open(os.path.join(settings.MEDIA_ROOT, file_path), "wb+") as dest:
                    for chunk in compressed.chunks():
                        dest.write(chunk)
                body_photo_urls.append(f"{settings.MEDIA_URL}{file_path}")

            # üîÅ –î–µ—Ñ–µ–∫—Ç—ã
            inspection_data = {
                "vin_number": vin_number,
                "controller": request.user.username,
                "body_photos": body_photo_urls,
                "date_added": date_added,
                "defects": []
            }

            defect_index = 1
            while f"responsible_{defect_index}" in request.POST:
                responsible_obj = DefectResponsible.objects.filter(id=request.POST.get(f"responsible_{defect_index}")).first()
                detail_obj = BodyDetail.objects.filter(id=request.POST.get(f"detail_{defect_index}")).first()
                defect_obj = Defect.objects.filter(id=request.POST.get(f"defect_{defect_index}")).first()
                grade_obj = DefectGrade.objects.filter(id=request.POST.get(f"grade_{defect_index}")).first()

                defect_data = {
                    "responsible": responsible_obj.name if responsible_obj else None,
                    "detail": detail_obj.name if detail_obj else None,
                    "custom_detail_explanation": request.POST.get(f"custom_detail_explanation_{defect_index}"),
                    "defect": defect_obj.name if defect_obj else None,
                    "custom_defect_explanation": request.POST.get(f"custom_defect_explanation_{defect_index}"),
                    "quantity": request.POST.get(f"quantity_{defect_index}", 1),
                    "grade": grade_obj.name if grade_obj else None,
                    "repair_type": request.POST.get(f"repair_type_{defect_index}"),
                    "defect_photos": [],
                }

                for file in request.FILES.getlist(f"defect_photos_{defect_index}"):
                    compressed = compress_uploaded_image(file)
                    file_path = f"images/defects/{compressed.name}"
                    os.makedirs(os.path.join(settings.MEDIA_ROOT, "images/defects"), exist_ok=True)
                    with open(os.path.join(settings.MEDIA_ROOT, file_path), "wb+") as dest:
                        for chunk in compressed.chunks():
                            dest.write(chunk)
                    defect_data["defect_photos"].append(f"{settings.MEDIA_URL}{file_path}")

                inspection_data["defects"].append(defect_data)
                defect_index += 1

            # ‚è∫Ô∏è –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            history_entry.history.setdefault(zone, {}).setdefault(post_name, []).append(inspection_data)
            history_entry.save()

            messages.success(request, "‚úÖ –ò–Ω—Å–ø–µ–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∑–∞–¥–Ω–∏–º —á–∏—Å–ª–æ–º!")
            return redirect("final_acceptance_form")
        else:
            messages.error(request, "‚ùå –û—à–∏–±–∫–∞ –≤ —Ñ–æ—Ä–º–µ!")

    else:
        form = MainUnloadingZoneDKDForm(post_id=post.id)

    return render(request, "users/incoming/final_acceptance_form.html", {
        "form": form,
        "details": details,
        "defects": defects,
        "defect_grades": defect_grades,
        "defect_responsibles": defect_responsibles,
        "post": post,
        "vin_history": vin_history,
    })



@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def containers_acceptance_table(request):
    """
    –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –ø–æ—Å—Ç–∞ '–ü—Ä–∏–µ–º–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤' (–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏).
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∑–∞–ø–∏—Å–∏ (–ø—Ä–∏–º–µ—Ä):
    {
        "photos": [...],
        "controller": "BK-027",
        "date_added": "2025-09-09T08:48:26.557442+05:00",
        "has_defect": "no",
        "description": "",
        "container_number": "9367144"
    }
    """
    import json

    zone = "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏"
    post = "–ü—Ä–∏–µ–º–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤"

    records = []

    for history in ContainerHistory.objects.all():
        # vin = history.vin  # 1) Remove this line
        post_entries = (history.history or {}).get(zone, {}).get(post, []) or []

        for entry in post_entries:
            raw_date = entry.get("date_added") or entry.get("date")
            date = parse_datetime(raw_date) if raw_date else None

            controller = entry.get("controller", "") or entry.get("extra_data", {}).get("controller", "")
            container_number = (
                entry.get("container_number", "")
                or entry.get("extra_data", {}).get("container_number", "")
            )

            photos = entry.get("photos", []) or []
            description = entry.get("description", "") or ""

            # –ü—Ä–∏–≤–æ–¥–∏–º has_defect –∫ –±—É–ª–µ–≤—É –≤–∏–¥—É
            has_defect_val = str(entry.get("has_defect", "")).lower()
            has_defect = has_defect_val in ("yes", "true", "1")

            # 2) Change group_key assignment to use container_number
            group_key = f"{container_number}_{raw_date}"

            # 3,4) Build record dict without "vin", and with "description": description
            records.append({
                "date": date,
                "controller": controller,
                "container_number": container_number,
                "description": description,
                "photos": photos,
                "photos_json": json.dumps(photos),
                "has_defect": has_defect,
                "group_key": group_key,
            })

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ —É–±—ã–≤–∞–Ω–∏—é
    records.sort(key=lambda r: r["date"] or timezone.datetime.min, reverse=True)

    # ---- –î–æ–ø–æ–ª–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç: –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä—ã –∏ TraceData ----
    all_controllers = {r["controller"] for r in records if r.get("controller")}
    controller_users_qs = CustomUser.objects.filter(username__in=all_controllers)
    controller_users = {user.username: user for user in controller_users_qs}

    # 5) Remove vin_list, trace_data, vin_trace_map construction; instead set vin_trace_map = {}
    vin_trace_map = {}

    # 6) Keep vin_trace_map in context for template compatibility
    return render(request, "users/incoming/containers_acceptance_table.html", {
        "records": records,
        "controller_users": controller_users,
        "vin_trace_map": vin_trace_map,
    })


@login_required
@permission_required('users.access_to_pqa_data', raise_exception=True)
def containers_acceptance_export(request):
    return render(request, "users/incoming/containers_acceptance_export.html")







@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def assembly_workshop_dashboard(request):
    today_str = now().date().isoformat()
    zone = "–¶–µ—Ö —Å–±–æ—Ä–∫–∏"

    post_vin_set = defaultdict(set)
    post_defect_counts = defaultdict(int)

    for history in VINHistory.objects.all():
        vin = history.vin
        posts = history.history.get(zone, {})
        for post_name, entries in posts.items():
            for entry in entries:
                date_str = entry.get("date_added", "")[:10]
                if date_str != today_str:
                    continue
                post_vin_set[post_name].add(vin)

                defects = entry.get("defects")
                if isinstance(defects, list):
                    post_defect_counts[post_name] += len(defects)
                elif entry.get("has_defect") == "yes":
                    post_defect_counts[post_name] += 1

    # –ú–∞–ø–ø–∏–Ω–≥: –ø–æ—Å—Ç ‚Üí —É—á–∞—Å—Ç–æ–∫
    POST_AREA_MAPPING = {
        "–ü–æ—Å—Ç –º–æ–º–µ–Ω—Ç–∞ –∑–∞—Ç—è–∂–µ–∫": "–¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å",
        "Chassis": "–¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å",
        "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å": "–¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å",


        "–ó–∞–∑–æ—Ä—ã –∏ –ø–µ—Ä–µ–ø–∞–¥—ã": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–≠–∫—Å—Ç–µ—Ä—å–µ—Ä": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–ò–Ω—Ç–µ—Ä—å–µ—Ä": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–ë–∞–≥–∞–∂–Ω–∏–∫": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–ú–æ—Ç–æ—Ä": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",
        "–§—É–Ω–∫—Ü–æ–Ω–∞–ª": "–ü–µ—Ä–≤–∞—è –∏–Ω—Å–ø–µ–∫—Ü–∏—è",

        "–ì–µ–æ–º–µ—Ç—Ä–∏—è –∫–æ–ª–µ—Å": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "–†–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ —Å–≤–µ—Ç–∞ —Ñ–∞—Ä –∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ä—É–ª—è": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "–¢–æ—Ä–º–æ–∑–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "Underbody": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "ADAS": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "AVM": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",
        "–ì–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –∫—É–∑–æ–≤–∞": "–¢–µ—Å—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è",

        "–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞": "–§–∏–Ω–∞–ª + –¢–µ—Å—Ç —Ç—Ä–µ–∫",
        "–¢–µ—Å—Ç —Ç—Ä–µ–∫": "–§–∏–Ω–∞–ª + –¢–µ—Å—Ç —Ç—Ä–µ–∫",
        "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è": "–§–∏–Ω–∞–ª + –¢–µ—Å—Ç —Ç—Ä–µ–∫",
    }

    grouped_posts = defaultdict(list)

    for post_name, area in POST_AREA_MAPPING.items():
        encoded_post = urllib.parse.quote(post_name)

        # —Ç–æ–ª—å–∫–æ –¥–ª—è "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è" –≤–µ–¥—ë–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–π view –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ assembly
        if post_name == "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è":
            table_url = reverse("assembly:documentation_table")
        else:
            table_url = reverse("assembly_post_table") + f"?post={encoded_post}"

        grouped_posts[area].append({
            "title": post_name,
            "icon": "",
            "table_url": table_url,
            "report_url": reverse("assembly_post_report") + f"?post={encoded_post}",
            "export_url": reverse("assembly_post_export") + f"?post={encoded_post}",
            "manual_entry_url": reverse("assembly_post_manual_entry") + f"?post={encoded_post}",
            "today_vins": len(post_vin_set.get(post_name, set())),
            "today_entries": post_defect_counts.get(post_name, 0),
        })

    return render(request, "users/assembly/assembly_workshop_dashboard.html", {
        "grouped_posts": dict(grouped_posts),
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    })


from datetime import datetime
import pytz

@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def assembly_post_manual_entry(request):
    zone = "–¶–µ—Ö —Å–±–æ—Ä–∫–∏"
    post_name = request.GET.get("post")

    if not post_name or post_name == "–¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å":
        return HttpResponse("‚ùå –£–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–æ—Å—Ç", status=400)

    if request.method == "POST":
        form = AssemblyTemplateForm(request.POST, request.FILES)

        if form.is_valid():
            vin_number = form.cleaned_data.get("vin_number")
            defect_description = form.cleaned_data.get("defect_description", "").strip()
            defect_photos = request.FILES.getlist("defect_photos")
            has_defect = form.cleaned_data.get("has_defect", "")
            custom_date = request.POST.get("custom_date")
            custom_time = request.POST.get("custom_time")

            if not vin_number or not custom_date or not custom_time:
                messages.error(request, "‚ùå VIN, –¥–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã.")
                return redirect(request.path + f"?post={post_name}")

            # üëá –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è —Å —á–∞—Å–æ–≤—ã–º –ø–æ—è—Å–æ–º
            try:
                combined_dt = datetime.strptime(f"{custom_date} {custom_time}", "%Y-%m-%d %H:%M:%S")
                localized_dt = pytz.timezone("Asia/Almaty").localize(combined_dt)
                date_added = localized_dt.isoformat()
            except Exception:
                messages.error(request, "‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã –∏–ª–∏ –≤—Ä–µ–º–µ–Ω–∏.")
                return redirect(request.path + f"?post={post_name}")

            history_entry, _ = VINHistory.objects.get_or_create(vin=vin_number)

            defect_photo_urls = []
            if defect_photos:
                for file in defect_photos:
                    compressed = compress_uploaded_image(file)
                    path = f"images/defects/{compressed.name}"
                    full_path = os.path.join(settings.MEDIA_ROOT, path)
                    os.makedirs(os.path.dirname(full_path), exist_ok=True)
                    with open(full_path, "wb+") as destination:
                        for chunk in compressed.chunks():
                            destination.write(chunk)
                    defect_photo_urls.append(f"{settings.MEDIA_URL}{path}")

            inspection_data = {
                "vin_number": vin_number,
                "controller": request.user.username,
                "defect_description": defect_description,
                "defect_photos": defect_photo_urls,
                "has_defect": has_defect,
                "date_added": date_added,
            }

            if zone not in history_entry.history:
                history_entry.history[zone] = {}
            if post_name not in history_entry.history[zone]:
                history_entry.history[zone][post_name] = []

            history_entry.history[zone][post_name].append(inspection_data)
            history_entry.save()

            messages.success(request, "‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")
            return redirect(request.path + f"?post={post_name}")
        else:
            messages.error(request, "‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö.")
    else:
        form = AssemblyTemplateForm()

    return render(request, "users/assembly/manual_entry_form.html", {
        "form": form,
        "post_name": post_name,
    })





@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def assembly_post_report(request):
    zone = "–¶–µ—Ö —Å–±–æ—Ä–∫–∏"
    post_name = request.GET.get("post")

    if not post_name or post_name == "–¢–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å":
        return HttpResponse("‚ùå –£–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–æ—Å—Ç", status=400)

    today = now().date()

    start_date_str = request.GET.get("start_date")
    end_date_str = request.GET.get("end_date")

    selected_brands = request.GET.getlist("brand")
    selected_models = request.GET.getlist("model")

    try:
        start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date() if start_date_str else today - timedelta(days=7)
        end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date() if end_date_str else today
    except ValueError:
        start_date = today - timedelta(days=7)
        end_date = today

    all_brands = TraceData.objects.values_list("brand", flat=True).distinct()
    if selected_brands:
        all_models = TraceData.objects.filter(brand__in=selected_brands).values_list("model", flat=True).distinct()
    else:
        all_models = TraceData.objects.values_list("model", flat=True).distinct()

    filtered_vins = TraceData.objects.all()
    if selected_brands:
        filtered_vins = filtered_vins.filter(brand__in=selected_brands)
    if selected_models:
        filtered_vins = filtered_vins.filter(model__in=selected_models)

    vin_set = set(filtered_vins.values_list("vin_rk", flat=True))

    passed_vins = set()
    passed_with_defect = set()
    passed_without_defect = set()
    controller_counter = Counter()
    controller_vin_pairs = set()
    defect_counter = Counter()
    total_defects = 0

    histories = VINHistory.objects.all()
    if vin_set:
        histories = histories.filter(vin__in=vin_set)

    for history in histories:
        vin = history.vin
        post_entries = history.history.get(zone, {}).get(post_name, [])
        if not post_entries:
            continue

        entries_in_range = []
        for entry in post_entries:
            raw_date = entry.get("date_added")
            if not raw_date:
                continue
            entry_date = parse_date(raw_date[:10])
            if entry_date and start_date <= entry_date <= end_date:
                entries_in_range.append(entry)

        if not entries_in_range:
            continue

        passed_vins.add(vin)

        vin_has_defect = any(
            entry.get("has_defect") == "yes" or entry.get("defects")
            for entry in entries_in_range
        )

        if vin_has_defect:
            passed_with_defect.add(vin)
            for entry in entries_in_range:
                if entry.get("has_defect") == "yes" or entry.get("defects"):
                    controller = entry.get("controller", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                    if (controller, vin) not in controller_vin_pairs:
                        controller_counter[controller] += 1
                        controller_vin_pairs.add((controller, vin))

                    for defect in entry.get("defects", []):
                        name = defect.get("name", "?")
                        unit = defect.get("unit", "?")
                        combined = f"{name} ({unit})" if name and unit else name or unit or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                        defect_counter[combined] += 1
                        total_defects += 1
        else:
            passed_without_defect.add(vin)

    total_inspections = len(passed_vins)
    inspections_with_defects = len(passed_with_defect)
    inspections_without_defects = total_inspections - inspections_with_defects
    dpu = round(total_defects / total_inspections, 2) if total_inspections else 0
    str_percentage = round(inspections_without_defects / total_inspections * 100, 2) if total_inspections else 0

    context = {
        "post_name": post_name,
        "start_date": start_date_str or '',
        "end_date": end_date_str or '',
        "total_inspections": total_inspections,
        "inspections_with_defects": inspections_with_defects,
        "inspections_without_defects": inspections_without_defects,
        "total_defects": total_defects,
        "dpu": dpu,
        "str_percentage": str_percentage,
        "unique_vin_count": total_inspections,
        "top_controllers": controller_counter.most_common(20),
        "top_defects": defect_counter.most_common(20),
        "all_brands": all_brands,
        "selected_brands": selected_brands,
        "all_models": all_models,
        "selected_models": selected_models,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    }

    return render(request, "users/assembly/assembly_post_report.html", context)






@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def assembly_current_report(request):
    # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞
    return render(request, "assembly/assembly/torque_graph_dkd.html")


@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def assembly_current_table(request):
    zone = "–¶–µ—Ö —Å–±–æ—Ä–∫–∏"
    post = "–ü–æ—Å—Ç –º–æ–º–µ–Ω—Ç–∞ –∑–∞—Ç—è–∂–∫–∏, DKD"

    records = []

    for history in VINHistory.objects.all():
        vin = history.vin
        post_entries = history.history.get(zone, {}).get(post, [])

        for entry in post_entries:
            raw_date = entry.get("date_added")
            date = parse_datetime(raw_date) if raw_date else None

            controller = entry.get("controller", "")
            mod = entry.get("modification", "")
            part = entry.get("assembly_part", "")
            torques = entry.get("torque_values", [])
            defects = entry.get("defects", [])
            group_key = f"{vin}_{raw_date}"

            if defects:
                for defect in defects:
                    records.append({
                        "vin": vin,
                        "date": date,
                        "controller": controller,
                        "modification": mod,
                        "assembly_part": part,
                        "torque_values": torques,
                        "defect_type": defect.get("type"),
                        "photos": defect.get("photos", []),
                        "quantity": defect.get("quantity", ""),
                        "has_defect": True,
                        "group_key": group_key,
                    })
            else:
                records.append({
                    "vin": vin,
                    "date": date,
                    "controller": controller,
                    "modification": mod,
                    "assembly_part": part,
                    "torque_values": torques,
                    "defect_type": "–ë–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤",
                    "photos": [],
                    "quantity": "",
                    "has_defect": False,
                    "group_key": group_key,
                })

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –¥–∞—Ç–µ —É–±—ã–≤–∞–Ω–∏—é
    records.sort(key=lambda r: r["date"] or timezone.datetime.min, reverse=True)

    return render(request, "users/assembly/assembly_current_table.html", {"records": records})


@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def assembly_current_export(request):
    # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ Excel
    return render(request, "users/assembly/assembly_current_export.html")












@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def assembly_post_table(request):
    zone = "–¶–µ—Ö —Å–±–æ—Ä–∫–∏"
    post = request.GET.get("post")

    valid_posts = [
        "–ü–æ—Å—Ç –º–æ–º–µ–Ω—Ç–∞ –∑–∞—Ç—è–∂–µ–∫", "Chassis", "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å", "–ó–∞–∑–æ—Ä—ã –∏ –ø–µ—Ä–µ–ø–∞–¥—ã", "–≠–∫—Å—Ç–µ—Ä—å–µ—Ä", "–ò–Ω—Ç–µ—Ä—å–µ—Ä", "–ë–∞–≥–∞–∂–Ω–∏–∫",
        "–ú–æ—Ç–æ—Ä", "–§—É–Ω–∫—Ü–æ–Ω–∞–ª", "–ì–µ–æ–º–µ—Ç—Ä–∏—è –∫–æ–ª–µ—Å", "–†–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ —Å–≤–µ—Ç–∞ —Ñ–∞—Ä –∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ä—É–ª—è",
        "–¢–æ—Ä–º–æ–∑–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞", "Underbody", "ADAS", "AVM", "–ì–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –∫—É–∑–æ–≤–∞", "–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", "–¢–µ—Å—Ç —Ç—Ä–µ–∫", "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è",
    ]

    if not post or post not in valid_posts:
        return HttpResponse("‚ùå –£–∫–∞–∂–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–æ—Å—Ç", status=400)

    records_grouped = defaultdict(list)

    for history in VINHistory.objects.all():
        vin = history.vin
        post_entries = history.history.get(zone, {}).get(post, [])

        for entry in post_entries:
            raw_date = entry.get("date_added")
            date = parse_datetime(raw_date) if raw_date else None
            controller = entry.get("controller", "") or entry.get("extra_data", {}).get("controller", "")
            group_key = f"{vin}_{raw_date}"
            line = entry.get("line", "")
            duration = entry.get("inspection_duration_seconds", "")

            # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç: —Å–ø–∏—Å–æ–∫ –¥–µ—Ñ–µ–∫—Ç–æ–≤
            if "defects" in entry and entry["defects"]:
                for defect in entry["defects"]:
                    records_grouped[vin].append({
                        "date": date,
                        "controller": controller,
                        "defect_description": defect.get("name", "–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è"),
                        "photos": defect.get("photos", []),
                        "photos_json": json.dumps(defect.get("photos", [])),
                        "has_defect": True,
                        "group_key": group_key,
                        "unit": defect.get("unit", ""),
                        "grade": defect.get("grade", ""),
                        "comment": defect.get("comment", ""),
                        "responsible": defect.get("responsible", ""),
                        "line": line,
                        "duration": duration,
                    })

            # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç: –æ–¥–∏–Ω –¥–µ—Ñ–µ–∫—Ç
            elif "defect_description" in entry or "defect_photos" in entry:
                records_grouped[vin].append({
                    "date": date,
                    "controller": controller,
                    "defect_description": entry.get("defect_description", "–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è"),
                    "photos": entry.get("defect_photos", []),
                    "photos_json": json.dumps(entry.get("defect_photos", [])),
                    "has_defect": True,
                    "group_key": group_key,
                    "unit": "",
                    "grade": "",
                    "comment": "",
                    "responsible": "",
                    "line": line,
                    "duration": duration,
                })

            # –ë–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤
            else:
                records_grouped[vin].append({
                    "date": date,
                    "controller": controller,
                    "defect_description": "–ë–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤",
                    "photos": [],
                    "photos_json": "[]",
                    "has_defect": False,
                    "group_key": group_key,
                    "unit": "",
                    "grade": "",
                    "comment": "",
                    "responsible": "",
                    "line": line,
                    "duration": duration,
                })

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –≤–Ω—É—Ç—Ä–∏ VIN
    for vin in records_grouped:
        records_grouped[vin].sort(key=lambda r: r["date"] or timezone.datetime.min, reverse=True)

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ VIN –ø–æ –¥–∞—Ç–µ –ø–µ—Ä–≤–æ–≥–æ –¥–µ—Ñ–µ–∫—Ç–∞
    records_grouped_sorted = sorted(
        records_grouped.items(),
        key=lambda item: item[1][0]["date"] or timezone.datetime.min,
        reverse=True
    )

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–æ–≥–∏–Ω–æ–≤
    all_controllers = {
        entry["controller"]
        for entries in records_grouped.values()
        for entry in entries
        if entry["controller"]
    }

    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
    controller_users_qs = CustomUser.objects.filter(username__in=all_controllers)
    controller_users = {user.username: user for user in controller_users_qs}

    # –ü–æ–ª—É—á–∞–µ–º VIN'—ã
    vin_list = list(records_grouped.keys())

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ TraceData –ø–æ VIN RK
    trace_data = TraceData.objects.filter(vin_rk__in=vin_list)
    vin_trace_map = {
        td.vin_rk: {
            "brand": td.brand,
            "model": td.model,
            "config_code": td.config_code,
        }
        for td in trace_data
    }

    return render(request, "users/assembly/assembly_post_table.html", {
        "records_grouped": records_grouped_sorted,
        "post": post,
        "controller_users": controller_users,
        "vin_trace_map": vin_trace_map,
    })




from django.contrib.auth.decorators import login_required
from django.views.decorators.http import require_POST
from django.http import HttpResponse, HttpResponseBadRequest
from django.conf import settings
from django.utils import timezone as dj_tz
from django.db.models import Q

from collections import defaultdict
from datetime import datetime
from PIL import Image
import xlsxwriter
import json, io, os


def _collect_dataset(post: str, rows_from_client: list | None):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      records_grouped_sorted: list[(vin, [rows])]
      vin_meta: dict[vin] -> (brand, model, config)
      has_any_photos: bool  (–µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Ñ–æ—Ç–æ –≤ –¥–∞–Ω–Ω—ã—Ö)
    """
    zone = "–¶–µ—Ö —Å–±–æ—Ä–∫–∏"

    from collections import defaultdict
    from datetime import datetime
    from django.utils import timezone as dj_tz
    import json

    def _split_dt(dt):
        if not dt:
            return "", ""
        try:
            s = str(dt).replace("Z", "+00:00")
            d = datetime.fromisoformat(s)
            if d.tzinfo:
                d = d.astimezone(dj_tz.get_current_timezone())
            return d.strftime("%d.%m.%Y"), d.strftime("%H:%M")
        except Exception:
            try:
                if hasattr(dt, "strftime"):
                    return dt.strftime("%d.%m.%Y"), dt.strftime("%H:%M")
            except Exception:
                pass
            return "", ""

    def _norm(s: str) -> str:
        return (s or "").strip().lower()

    def _responsible_from_history(vin: str, date_s: str, time_s: str,
                                  unit_txt: str, defect_txt: str) -> str:
        """
        –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –≤ –∏—Å—Ç–æ—Ä–∏–∏ VIN –∑–∞–ø–∏—Å—å –ø–æ—Å—Ç–∞ —Å —Ç–µ–º –∂–µ –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º
        –∏ –∑–∞–±—Ä–∞—Ç—å –æ—Ç—Ç—É–¥–∞ extra.qrr_responsibles (–ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é unit/defect).
        """
        vh = VINHistory.objects.filter(vin=vin).only("history").first()
        if not vh or not vh.history:
            return ""
        h = vh.history
        if isinstance(h, str):
            try:
                h = json.loads(h)
            except Exception:
                return ""

        entries = (h.get(zone, {}) or {}).get(post, []) or []
        if not isinstance(entries, list):
            return ""

        # –∫–∞–Ω–¥–∏–¥–∞—Ç—ã –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏ (–∫–∞–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ)
        candidates = []
        for e in entries:
            ds, ts = _split_dt(e.get("date_added"))
            if ds == (date_s or "") and ts == (time_s or ""):
                candidates.append(e)

        if not candidates:
            return ""

        unit_l = _norm(unit_txt)
        defect_l = _norm(defect_txt)

        bucket = []
        for e in candidates:
            defects = e.get("defects") or []
            if not isinstance(defects, list):
                continue

            # —Å–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é unit/defect
            matched = False
            for d in defects:
                du = _norm(d.get("unit") or d.get("detail"))
                dn = _norm(d.get("name") or d.get("defect"))
                ok_u = (not unit_l) or (du == unit_l)
                ok_d = (not defect_l) or (dn == defect_l)
                if ok_u and ok_d:
                    extra = d.get("extra") or {}
                    resp = extra.get("qrr_responsibles") or []
                    if isinstance(resp, list):
                        bucket.extend([str(x) for x in resp if x is not None])
                    matched = True

            # –µ—Å–ª–∏ –ø–æ —Ç–µ–∫—Å—Ç–∞–º –Ω–µ –Ω–∞—à–ª–∏, –Ω–æ –¥–µ—Ñ–µ–∫—Ç –æ–¥–∏–Ω ‚Äî –±–µ—Ä—ë–º –µ–≥–æ –∫–∞–∫ fallback
            if not matched and len(defects) == 1:
                extra = (defects[0].get("extra") or {})
                resp = extra.get("qrr_responsibles") or []
                if isinstance(resp, list):
                    bucket.extend([str(x) for x in resp if x is not None])

        # —É–±–µ—Ä—ë–º –¥—É–±–ª–∏, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –ø–æ—Ä—è–¥–æ–∫
        bucket = list(dict.fromkeys(bucket))
        return ", ".join(bucket)

    records_grouped: dict[str, list[dict]] = defaultdict(list)
    vin_meta: dict[str, tuple[str, str, str]] = {}
    has_any_photos = False

    if isinstance(rows_from_client, list) and rows_from_client:
        # ‚úÖ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        for r in rows_from_client:
            vin = (r.get("vin") or "").strip().upper()
            if not vin:
                continue
            brand  = (r.get("brand") or "").strip()
            model  = (r.get("model") or "").strip()
            config = (r.get("config_code") or "").strip()
            if vin not in vin_meta or not any(vin_meta[vin]):
                vin_meta[vin] = (brand, model, config)

            photos = r.get("photos") or []
            has_any_photos = has_any_photos or bool(photos)

            date_s = (r.get("date") or "").strip()
            time_s = (r.get("time") or "").strip()
            line   = (r.get("line") or "").strip()
            unit   = (r.get("unit") or "").strip()
            defect = (r.get("defect") or "").strip()
            comment = (r.get("comment") or "").strip()
            grade   = (r.get("grade") or "").strip()
            controller = (r.get("controller") or "").strip()

            # –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –Ω–µ –ø—Ä–∏—Å–ª–∞–Ω ‚Äî –¥–æ—Å—Ç–∞—ë–º –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ VIN
            responsible = (r.get("responsible") or "").strip()
            if not responsible:
                responsible = _responsible_from_history(vin, date_s, time_s, unit, defect)

            records_grouped[vin].append({
                "date": date_s, "time": time_s, "line": line,
                "unit": unit, "defect": defect, "comment": comment, "grade": grade,
                "controller": controller, "responsible": responsible,
                "photos": photos,
            })

        # –¥–æ—Ç—è–Ω—É—Ç—å –º–µ—Ç—É, –µ—Å–ª–∏ –ø—É—Å—Ç–∞—è
        need_fill = [v for v, (b, m, c) in vin_meta.items() if not (b and m and c)]
        if need_fill:
            for t in TraceData.objects.filter(vin_rk__in=need_fill).only("vin_rk", "brand", "model", "config_code"):
                v = (t.vin_rk or "").upper()
                old = vin_meta.get(v, ("", "", ""))
                vin_meta[v] = (old[0] or (t.brand or ""), old[1] or (t.model or ""), old[2] or (t.config_code or ""))

    else:
        # üü® –∑–∞–ø–∞—Å–Ω–æ–π —Ä–µ–∂–∏–º ‚Äî —Å–æ–±—Ä–∞—Ç—å –≤—Å—ë –∏–∑ –ë–î (–∫–∞–∫ –±—ã–ª–æ)
        for vh in VINHistory.objects.only("vin", "history"):
            vin = (vh.vin or "").strip().upper()
            if not vin:
                continue
            h = vh.history or {}
            if isinstance(h, str):
                try:
                    h = json.loads(h)
                except Exception:
                    continue

            post_entries = (h.get(zone, {}) or {}).get(post, []) or []
            for entry in post_entries:
                raw_dt = entry.get("date_added")
                date_s, time_s = _split_dt(raw_dt)
                controller = (entry.get("controller") or entry.get("extra_data", {}).get("controller") or "").strip()
                line = entry.get("line", "") or ""

                if isinstance(entry.get("defects"), list) and entry["defects"]:
                    for d in entry["defects"]:
                        name   = (d.get("name") or d.get("defect") or "").strip() or "–ë–µ–∑ –æ–ø–∏—Å–∞–Ω–∏—è"
                        unit   = (d.get("unit") or d.get("detail") or "").strip()
                        grade  = (d.get("grade") or "").strip()
                        comment = (d.get("comment") or "").strip()
                        photos = list(dict.fromkeys([str(p) for p in (d.get("photos") or [])]))
                        has_any_photos = has_any_photos or bool(photos)
                        extra = d.get("extra") or {}
                        responsibles = extra.get("qrr_responsibles") or []
                        responsible_str = ", ".join([str(x) for x in responsibles if x is not None]) \
                                          if isinstance(responsibles, list) else ""
                        records_grouped[vin].append({
                            "date": date_s, "time": time_s, "line": line,
                            "unit": unit, "defect": name, "comment": comment, "grade": grade,
                            "controller": controller, "responsible": responsible_str,
                            "photos": photos,
                        })
                else:
                    records_grouped[vin].append({
                        "date": date_s, "time": time_s, "line": line,
                        "unit": "", "defect": "–ë–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤", "comment": "", "grade": "",
                        "controller": controller, "responsible": "", "photos": [],
                    })

        # –º–µ—Ç–∞ –ø–æ VIN
        vin_list = list(records_grouped.keys())
        for t in TraceData.objects.filter(vin_rk__in=vin_list).only("vin_rk", "brand", "model", "config_code"):
            vin_meta[(t.vin_rk or "").upper()] = (t.brand or "", t.model or "", t.config_code or "")

    # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
    def _dt_key(r: dict):
        try:
            return datetime.strptime(f'{r.get("date","")} {r.get("time","")}', "%d.%m.%Y %H:%M")
        except Exception:
            return datetime.min

    for v in records_grouped:
        records_grouped[v].sort(key=_dt_key, reverse=True)

    records_grouped_sorted = sorted(
        records_grouped.items(),
        key=lambda item: _dt_key(item[1][0]) if item[1] else datetime.min,
        reverse=True
    )

    return records_grouped_sorted, vin_meta, has_any_photos


def _build_excel(records_grouped_sorted, vin_meta, include_photos: bool, file_title: str) -> bytes:
    """–°—Ç—Ä–æ–∏—Ç xlsx –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç bytes."""
    def _media_stream(abs_or_media_path: str) -> io.BytesIO | None:
        if not abs_or_media_path:
            return None
        rel = abs_or_media_path
        if rel.startswith("/media/"):
            rel = rel[len("/media/"):]
        rel = rel.lstrip("/")
        full = os.path.join(settings.MEDIA_ROOT, rel)
        if not os.path.exists(full) or not os.path.isfile(full):
            return None
        try:
            with open(full, "rb") as f:
                return io.BytesIO(f.read())
        except Exception:
            return None

    def _image_scale_for_draw(image_stream: io.BytesIO, max_w_px: int, max_h_px: int) -> tuple[float, float]:
        try:
            pos = image_stream.tell()
            image_stream.seek(0)
            im = Image.open(image_stream)
            w, h = im.size
            image_stream.seek(pos)
            if not w or not h:
                return 1.0, 1.0
            sx = min(max_w_px / float(w), 1.0)
            sy = min(max_h_px / float(h), 1.0)
            return sx, sy
        except Exception:
            return 1.0, 1.0

    # –¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ —Ñ–æ—Ç–æ
    max_photos = 0
    if include_photos:
        for _, rows in records_grouped_sorted:
            for r in rows:
                max_photos = max(max_photos, len(r.get("photos") or []))
        max_photos = max(max_photos, 1)  # —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ ¬´–§–æ—Ç–æ 1¬ª

    bio = io.BytesIO()
    wb = xlsxwriter.Workbook(bio, {"in_memory": True, "strings_to_urls": False, "constant_memory": True})
    ws = wb.add_worksheet(file_title[:31] or "–û—Ç—á—ë—Ç")  # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ Excel –≤ 31 —Å–∏–º–≤–æ–ª

    fmt_head  = wb.add_format({"bold": True, "align": "center", "valign": "vcenter",
                               "bg_color": "#F2F2F2", "border": 1, "text_wrap": True})
    fmt_merge = wb.add_format({"align": "center", "valign": "vcenter", "border": 1})
    fmt_txt   = wb.add_format({"valign": "top", "border": 1, "text_wrap": True})
    fmt_ctr   = wb.add_format({"align": "center", "valign": "top", "border": 1})

    headers_fixed = [
        "VIN", "–ë—Ä–µ–Ω–¥", "–ú–æ–¥–µ–ª—å", "–ö–æ–¥ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏",
        "–î–∞—Ç–∞", "–í—Ä–µ–º—è", "–õ–∏–Ω–∏—è",
        "–î–µ—Ç–∞–ª—å", "–î–µ—Ñ–µ–∫—Ç", "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", "–ì—Ä–µ–π–¥", "–ö–æ–Ω—Ç—Ä–æ–ª–µ—Ä", "–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π",
    ]
    photo_headers = [f"–§–æ—Ç–æ {i}" for i in range(1, max_photos + 1)] if include_photos else []
    headers = headers_fixed + photo_headers

    widths = [20, 14, 18, 18, 12, 10, 14, 22, 24, 28, 10, 16, 20] + ([18] * len(photo_headers))
    for i, (h, w) in enumerate(zip(headers, widths)):
        ws.write(0, i, h, fmt_head)
        ws.set_column(i, i, w)

    # –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–æ—Ç–æ ‚Äî –ø–æ–≤—ã—à–µ —Å—Ç—Ä–æ–∫–∏; –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç
    if include_photos:
        ws.set_default_row(120)
    else:
        ws.set_default_row(18)

    PHOTO_MAX_W = 120
    PHOTO_MAX_H = 110

    # –∏–Ω–¥–µ–∫—Å—ã
    COL_VIN, COL_BRAND, COL_MODEL, COL_CFG = 0, 1, 2, 3
    COL_DATE, COL_TIME, COL_LINE = 4, 5, 6
    COL_UNIT, COL_DEFECT, COL_COMMENT, COL_GRADE, COL_CONTROLLER, COL_RESP = 7, 8, 9, 10, 11, 12
    COL_PHOTOS_START = len(headers_fixed)

    row_xlsx = 1
    for vin, rows in records_grouped_sorted:
        brand, model, cfg = vin_meta.get(vin, ("", "", ""))
        start_row = row_xlsx

        for r in rows:
            ws.write(row_xlsx, COL_VIN,   vin,   fmt_txt)
            ws.write(row_xlsx, COL_BRAND, brand, fmt_txt)
            ws.write(row_xlsx, COL_MODEL, model, fmt_txt)
            ws.write(row_xlsx, COL_CFG,   cfg,   fmt_txt)

            ws.write(row_xlsx, COL_DATE, (r.get("date") or ""), fmt_ctr)
            ws.write(row_xlsx, COL_TIME, (r.get("time") or ""), fmt_ctr)
            ws.write(row_xlsx, COL_LINE, (r.get("line") or ""), fmt_txt)

            ws.write(row_xlsx, COL_UNIT,      (r.get("unit") or ""),      fmt_txt)
            ws.write(row_xlsx, COL_DEFECT,    (r.get("defect") or ""),    fmt_txt)
            ws.write(row_xlsx, COL_COMMENT,   (r.get("comment") or ""),   fmt_txt)
            ws.write(row_xlsx, COL_GRADE,     (r.get("grade") or ""),     fmt_ctr)
            ws.write(row_xlsx, COL_CONTROLLER,(r.get("controller") or ""),fmt_txt)
            ws.write(row_xlsx, COL_RESP,      (r.get("responsible") or ""), fmt_txt)

            if include_photos:
                photos = r.get("photos") or []
                for j in range(max_photos):
                    col = COL_PHOTOS_START + j
                    p = photos[j] if j < len(photos) else None
                    if not p:
                        continue
                    stream = _media_stream(p)
                    if stream is None:
                        ws.write(row_xlsx, col, os.path.basename(str(p)), fmt_txt)
                        continue
                    try:
                        sx, sy = _image_scale_for_draw(stream, PHOTO_MAX_W, PHOTO_MAX_H)
                        ws.insert_image(row_xlsx, col, "photo.bin", {
                            "image_data": stream, "x_offset": 4, "y_offset": 4,
                            "x_scale": sx, "y_scale": sy
                        })
                    except Exception:
                        ws.write(row_xlsx, col, os.path.basename(str(p)), fmt_txt)

            row_xlsx += 1

        # —Å–ª–∏—Ç—å VIN/–ë—Ä–µ–Ω–¥/–ú–æ–¥–µ–ª—å/–ö–æ–¥ –Ω–∞ –≥—Ä—É–ø–ø—É
        if row_xlsx - 1 > start_row:
            ws.merge_range(start_row, COL_VIN,   row_xlsx - 1, COL_VIN,   vin,   fmt_merge)
            ws.merge_range(start_row, COL_BRAND, row_xlsx - 1, COL_BRAND, brand, fmt_merge)
            ws.merge_range(start_row, COL_MODEL, row_xlsx - 1, COL_MODEL, model, fmt_merge)
            ws.merge_range(start_row, COL_CFG,   row_xlsx - 1, COL_CFG,   cfg,   fmt_merge)

    wb.close()
    bio.seek(0)
    return bio.getvalue()


def _export_common(request, include_photos: bool, name_suffix: str):
    post = (request.GET.get("post") or "").strip()
    if not post:
        return HttpResponseBadRequest("parameter 'post' is required")

    try:
        payload = json.loads(request.body.decode("utf-8") or "{}")
    except Exception:
        payload = {}
    rows_from_client = payload.get("rows")

    records_grouped_sorted, vin_meta, _ = _collect_dataset(post, rows_from_client)
    if not records_grouped_sorted:
        return HttpResponseBadRequest("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –ø–æ —ç—Ç–æ–º—É –ø–æ—Å—Ç—É")

    data = _build_excel(
        records_grouped_sorted=records_grouped_sorted,
        vin_meta=vin_meta,
        include_photos=include_photos,
        file_title="–û—Ç—á—ë—Ç",
    )

    fname = f"post_export_{post}{name_suffix}_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.xlsx"
    resp = HttpResponse(
        data,
        content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
    resp["Content-Disposition"] = f'attachment; filename="{fname}"'
    return resp


# ===== –ø—É–±–ª–∏—á–Ω—ã–µ –≤—å—é—à–∫–∏ =====
@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
@require_POST
def assembly_post_export(request):
    """–°–∫–∞—á–∞—Ç—å –° –§–û–¢–û (–∫–∞–∫ —Å–µ–π—á–∞—Å). –£—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã —Å —Ñ—Ä–æ–Ω—Ç–∞, –µ—Å–ª–∏ –ø—Ä–∏—Å–ª–∞–Ω—ã rows."""
    return _export_common(request, include_photos=True, name_suffix="_with_photos")


@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
@require_POST
def assembly_post_export_nophotos(request):
    """–°–∫–∞—á–∞—Ç—å –ë–ï–ó –§–û–¢–û ‚Äî —Ç–µ –∂–µ –∫–æ–ª–æ–Ω–∫–∏, –Ω–æ –±–µ–∑ –±–ª–æ–∫–∞ –§–æ—Ç–æ."""
    return _export_common(request, include_photos=False, name_suffix="_no_photos")



def _build_excel_custom(records_grouped_sorted, vin_meta, columns: list[str],
                        photo_limit: int | None = None, sheet_title: str = "–û—Ç—á—ë—Ç") -> bytes:
    """
    columns ‚Äî —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–π –≤ –Ω—É–∂–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ. –î–æ–ø—É—Å—Ç–∏–º—ã–µ –∫–ª—é—á–∏:
      'vin','brand','model','config_code','date','time','line',
      'unit','defect','comment','grade','controller','responsible','photos'

    –ï—Å–ª–∏ 'photos' –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è N –∫–æ–ª–æ–Ω–æ–∫ ¬´–§–æ—Ç–æ i¬ª.
    N = max(1, min(photo_limit, max_—Ñ–æ—Ç–æ_–≤_–¥–∞–Ω–Ω—ã—Ö)) –µ—Å–ª–∏ photo_limit –∑–∞–¥–∞–Ω,
        –∏–Ω–∞—á–µ N = max(1, max_—Ñ–æ—Ç–æ_–≤_–¥–∞–Ω–Ω—ã—Ö).
    """
    allowed = {
        "vin","brand","model","config_code","date","time","line",
        "unit","defect","comment","grade","controller","responsible","photos"
    }
    bad = [c for c in columns if c not in allowed]
    if bad:
        raise ValueError(f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(bad)}")

    include_photos = "photos" in columns

    # ----- —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ñ–æ—Ç–æ -----
    def _media_stream(abs_or_media_path: str) -> io.BytesIO | None:
        if not abs_or_media_path:
            return None
        rel = abs_or_media_path
        if rel.startswith("/media/"):
            rel = rel[len("/media/"):]
        rel = rel.lstrip("/")
        full = os.path.join(settings.MEDIA_ROOT, rel)
        if not os.path.exists(full) or not os.path.isfile(full):
            return None
        try:
            with open(full, "rb") as f:
                return io.BytesIO(f.read())
        except Exception:
            return None

    def _image_scale_for_draw(image_stream: io.BytesIO, max_w_px: int, max_h_px: int) -> tuple[float, float]:
        try:
            pos = image_stream.tell()
            image_stream.seek(0)
            im = Image.open(image_stream)
            w, h = im.size
            image_stream.seek(pos)
            if not w or not h:
                return 1.0, 1.0
            sx = min(max_w_px / float(w), 1.0)
            sy = min(max_h_px / float(h), 1.0)
            return sx, sy
        except Exception:
            return 1.0, 1.0

    # –ø–æ—Å—á–∏—Ç–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ñ–æ—Ç–æ
    max_photos_in_data = 0
    if include_photos:
        for _, rows in records_grouped_sorted:
            for r in rows:
                max_photos_in_data = max(max_photos_in_data, len(r.get("photos") or []))
        max_photos_in_data = max(max_photos_in_data, 1)
    # –∏—Ç–æ–≥–æ–≤–æ–µ —á–∏—Å–ª–æ –∫–æ–ª–æ–Ω–æ–∫ –§–æ—Ç–æ
    if include_photos:
        if isinstance(photo_limit, int) and photo_limit >= 1:
            photo_count = max(1, min(photo_limit, max_photos_in_data))
        else:
            photo_count = max_photos_in_data
    else:
        photo_count = 0

    # –∑–∞–≥–æ–ª–æ–≤–∫–∏ / —à–∏—Ä–∏–Ω—ã / –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ
    title_map = {
        "vin":"VIN", "brand":"–ë—Ä–µ–Ω–¥", "model":"–ú–æ–¥–µ–ª—å", "config_code":"–ö–æ–¥ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏",
        "date":"–î–∞—Ç–∞", "time":"–í—Ä–µ–º—è", "line":"–õ–∏–Ω–∏—è",
        "unit":"–î–µ—Ç–∞–ª—å", "defect":"–î–µ—Ñ–µ–∫—Ç", "comment":"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π",
        "grade":"–ì—Ä–µ–π–¥", "controller":"–ö–æ–Ω—Ç—Ä–æ–ª–µ—Ä", "responsible":"–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π",
        "photos":"–§–æ—Ç–æ"
    }
    width_map = {
        "vin":20, "brand":14, "model":18, "config_code":18,
        "date":12, "time":10, "line":14,
        "unit":22, "defect":24, "comment":28,
        "grade":10, "controller":16, "responsible":20,
        "photos":18
    }
    centered = {"date","time","grade"}

    # ¬´–ø–ª–æ—Å–∫–∏–π¬ª —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –±–µ–∑ ¬´photos¬ª (–æ–Ω —Ä–∞—Å—à–∏—Ä—è–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ)
    base_cols = [c for c in columns if c != "photos"]

    # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–Ω–∏–≥–∏
    bio = io.BytesIO()
    wb = xlsxwriter.Workbook(bio, {"in_memory": True, "strings_to_urls": False, "constant_memory": True})
    ws = wb.add_worksheet((sheet_title or "–û—Ç—á—ë—Ç")[:31])

    fmt_head  = wb.add_format({"bold": True, "align": "center", "valign": "vcenter",
                               "bg_color": "#F2F2F2", "border": 1, "text_wrap": True})
    fmt_merge = wb.add_format({"align": "center", "valign": "vcenter", "border": 1})
    fmt_txt   = wb.add_format({"valign": "top", "border": 1, "text_wrap": True})
    fmt_ctr   = wb.add_format({"align": "center", "valign": "top", "border": 1})

    # —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —à–∏—Ä–∏–Ω—ã
    headers: list[str] = []
    widths:  list[int] = []
    for k in base_cols:
        headers.append(title_map[k])
        widths.append(width_map.get(k, 16))
    if include_photos:
        for i in range(1, photo_count+1):
            headers.append(f"–§–æ—Ç–æ {i}")
            widths.append(width_map["photos"])

    # –≤—ã—Å—Ç–∞–≤–∏—Ç—å —à–∞–ø–∫—É –∏ —à–∏—Ä–∏–Ω—ã
    for col, (h, w) in enumerate(zip(headers, widths)):
        ws.write(0, col, h, fmt_head)
        ws.set_column(col, col, w)

    ws.set_default_row(120 if include_photos else 18)
    PHOTO_MAX_W = 120
    PHOTO_MAX_H = 110

    # –ø–æ–∑–∏—Ü–∏–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ (–µ—Å–ª–∏ –æ–Ω–∏ –≤–∫–ª—é—á–µ–Ω—ã)
    idx_map = {k: i for i, k in enumerate(base_cols)}
    photos_col_start = len(base_cols)  # —Å—Ç–∞—Ä—Ç —Ñ–æ—Ç–æ-–±–ª–æ–∫–∞ (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å)

    # –∑–∞–ø–∏—Å—å —Å—Ç—Ä–æ–∫
    row_xlsx = 1
    for vin, rows in records_grouped_sorted:
        brand, model, cfg = vin_meta.get(vin, ("", "", ""))
        start_row = row_xlsx

        for r in rows:
            # –ø–∏—à–µ–º ¬´–±–∞–∑–æ–≤—ã–µ¬ª –∫–æ–ª–æ–Ω–∫–∏ –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
            for k, col in idx_map.items():
                if k == "vin":
                    val = vin
                elif k == "brand":
                    val = brand
                elif k == "model":
                    val = model
                elif k == "config_code":
                    val = cfg
                else:
                    val = (r.get(k) or "")
                ws.write(row_xlsx, col, val, fmt_ctr if k in centered else fmt_txt)

            # –±–ª–æ–∫ —Ñ–æ—Ç–æ
            if include_photos:
                photos = r.get("photos") or []
                for j in range(photo_count):
                    col = photos_col_start + j
                    p = photos[j] if j < len(photos) else None
                    if not p:
                        continue
                    stream = _media_stream(p)
                    if stream is None:
                        ws.write(row_xlsx, col, os.path.basename(str(p)), fmt_txt)
                        continue
                    try:
                        sx, sy = _image_scale_for_draw(stream, PHOTO_MAX_W, PHOTO_MAX_H)
                        ws.insert_image(row_xlsx, col, "photo.bin", {
                            "image_data": stream, "x_offset": 4, "y_offset": 4,
                            "x_scale": sx, "y_scale": sy
                        })
                    except Exception:
                        ws.write(row_xlsx, col, os.path.basename(str(p)), fmt_txt)

            row_xlsx += 1

        # —Å–ª–∏—è–Ω–∏—è –ø–æ VIN/–ë—Ä–µ–Ω–¥/–ú–æ–¥–µ–ª—å/–ö–æ–¥ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏ –≤–∫–ª—é—á–µ–Ω—ã)
        if row_xlsx - 1 > start_row:
            for k, v in (("vin", vin), ("brand", brand), ("model", model), ("config_code", cfg)):
                if k in idx_map:
                    c = idx_map[k]
                    ws.merge_range(start_row, c, row_xlsx - 1, c, v, fmt_merge)

    wb.close()
    bio.seek(0)
    return bio.getvalue()


@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
@require_POST
def assembly_post_export_custom(request):
    """
    –ö–∞—Å—Ç–æ–º-—ç–∫—Å–ø–æ—Ä—Ç –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫–æ–ª–æ–Ω–∫–∞–º.
    –û–∂–∏–¥–∞–µ—Ç JSON –≤ —Ç–µ–ª–µ –∑–∞–ø—Ä–æ—Å–∞:
      {
        "rows": [...],              # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        "columns": ["vin","date",...,"photos"],   # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û, –ø–æ—Ä—è–¥–æ–∫ = –ø–æ—Ä—è–¥–æ–∫ –≤ —Ñ–∞–π–ª–µ
        "photo_limit": 3            # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –µ—Å—Ç—å "photos" (>=1)
      }
    –ü–∞—Ä–∞–º–µ—Ç—Ä GET ?post= –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω (–∫–∞–∫ –∏ –≤ –¥—Ä—É–≥–∏—Ö —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞—Ö).
    """
    post = (request.GET.get("post") or "").strip()
    if not post:
        return HttpResponseBadRequest("parameter 'post' is required")

    try:
        payload = json.loads(request.body.decode("utf-8") or "{}")
    except Exception:
        payload = {}

    columns = payload.get("columns")
    if not isinstance(columns, list) or not columns:
        return HttpResponseBadRequest("–í —Ç–µ–ª–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–ø–∏—Å–æ–∫ 'columns'.")

    rows_from_client = payload.get("rows")
    photo_limit = payload.get("photo_limit")

    # —Å–æ–±—Ä–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç (–µ—Å–ª–∏ rows –ø—Ä–∏—Å–ª–∞–Ω—ã ‚Äî —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
    records_grouped_sorted, vin_meta, _ = _collect_dataset(post, rows_from_client)
    if not records_grouped_sorted:
        return HttpResponseBadRequest("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –ø–æ —ç—Ç–æ–º—É –ø–æ—Å—Ç—É")

    try:
        data = _build_excel_custom(
            records_grouped_sorted=records_grouped_sorted,
            vin_meta=vin_meta,
            columns=columns,
            photo_limit=photo_limit if isinstance(photo_limit, int) else None,
            sheet_title="–û—Ç—á—ë—Ç",
        )
    except ValueError as e:
        return HttpResponseBadRequest(str(e))

    fname = f"post_export_{post}_custom_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.xlsx"
    resp = HttpResponse(
        data,
        content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
    resp["Content-Disposition"] = f'attachment; filename=\"{fname}\"'
    return resp










@login_required
@permission_required('users.access_to_the_shift_management', raise_exception=True)
def master_controller_panel(request):
    User = get_user_model()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞
    if request.method == 'POST' and 'user_id' in request.POST:
        user_id = request.POST.get('user_id')
        user = get_object_or_404(User, id=user_id, role='controller')

        form_edit = ControllerEditForm(request.POST, request.FILES, instance=user)
        if form_edit.is_valid():
            form_edit.save()
            messages.success(request, f"‚úÖ –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä {user.username} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª—ë–Ω.")
            return redirect('master_controller_panel')
        else:
            messages.error(request, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞ {user.username}.")
            # –¢—É—Ç –º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å form_edit –≤ context –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞
    elif request.method == 'POST':
        form = ControllerCreationForm(request.POST)
        if form.is_valid():
            form.save()
            messages.success(request, "‚úÖ –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.")
            return redirect('master_controller_panel')
        else:
            for error in form.errors.get('__all__', []):
                if "–ü–∞—Ä–æ–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç" in error:
                    messages.error(request, "‚ùå –ü–∞—Ä–æ–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –≤–≤–æ–¥.")
                elif "This password is too short" in error:
                    messages.error(request, "‚ùå –ü–∞—Ä–æ–ª—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –ú–∏–Ω–∏–º—É–º 8 —Å–∏–º–≤–æ–ª–æ–≤.")
                elif "This password is too common" in error:
                    messages.error(request, "‚ùå –ü–∞—Ä–æ–ª—å —Å–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç–æ–π. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω—ã–π.")
                elif "This password is entirely numeric" in error:
                    messages.error(request, "‚ùå –ü–∞—Ä–æ–ª—å –Ω–µ –¥–æ–ª–∂–µ–Ω —Å–æ—Å—Ç–æ—è—Ç—å —Ç–æ–ª—å–∫–æ –∏–∑ —Ü–∏—Ñ—Ä.")
                else:
                    messages.error(request, f"‚ùå {error}")
        form_edit = None  # –Ω–µ –Ω—É–∂–µ–Ω
    else:
        form = ControllerCreationForm()
        form_edit = None

    controllers = User.objects.filter(role='controller', is_superuser=False).order_by('username')

    context = {
        'form': form,
        'controllers': controllers,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    }
    return render(request, 'users/controller_panel/master_controller_panel.html', context)


@login_required
@permission_required('users.access_to_the_shift_management', raise_exception=True)
def delete_controller(request, user_id):
    user = get_object_or_404(get_user_model(), id=user_id, role='controller', is_superuser=False)

    username = user.username
    user.delete()
    messages.success(request, f"üóëÔ∏è –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä '{username}' —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª—ë–Ω.")
    return redirect('master_controller_panel')


@login_required
@permission_required('users.access_to_the_shift_management', raise_exception=True)
def change_controller_password(request, user_id):
    user = get_object_or_404(get_user_model(), id=user_id, role='controller', is_superuser=False)

    if request.method == 'POST':
        form = ControllerPasswordChangeForm(request.POST)
        if form.is_valid():
            user.set_password(form.cleaned_data['new_password'])
            user.save()
            messages.success(request, f"‚úÖ –ü–∞—Ä–æ–ª—å –¥–ª—è {user.username} —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω—ë–Ω.")
            return redirect('master_controller_panel')
        else:
            for error in form.errors.get('__all__', []):
                if "–ü–∞—Ä–æ–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç" in error:
                    messages.error(request, "‚ùå –ü–∞—Ä–æ–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç.")
                elif "This password is too short" in error:
                    messages.error(request, "‚ùå –ü–∞—Ä–æ–ª—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π. –ú–∏–Ω–∏–º—É–º 8 —Å–∏–º–≤–æ–ª–æ–≤.")
                elif "This password is too common" in error:
                    messages.error(request, "‚ùå –ü–∞—Ä–æ–ª—å —Å–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç–æ–π. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω—ã–π.")
                elif "This password is entirely numeric" in error:
                    messages.error(request, "‚ùå –ü–∞—Ä–æ–ª—å –Ω–µ –¥–æ–ª–∂–µ–Ω —Å–æ—Å—Ç–æ—è—Ç—å —Ç–æ–ª—å–∫–æ –∏–∑ —Ü–∏—Ñ—Ä.")
                else:
                    messages.error(request, f"‚ùå {error}")
    else:
        form = ControllerPasswordChangeForm()

    return render(request, 'users/controller_panel/change_controller_password.html', {
        'form': form,
        'controller': user,
    })


@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def assembly_post_edit(request, vin, post_name, timestamp):
    zone = "–¶–µ—Ö —Å–±–æ—Ä–∫–∏"

    try:
        timestamp_dt = datetime.fromisoformat(timestamp)
    except ValueError:
        return HttpResponse("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ä–µ–º–µ–Ω–∏", status=400)

    history_entry = get_object_or_404(VINHistory, vin=vin)
    post_entries = history_entry.history.get(zone, {}).get(post_name, [])

    entry_to_edit = None
    for entry in post_entries:
        raw_date = entry.get("date_added")
        try:
            entry_dt = datetime.fromisoformat(raw_date)
        except Exception:
            continue

        if abs(entry_dt - timestamp_dt) <= timedelta(seconds=1):
            entry_to_edit = entry
            break

    if not entry_to_edit:
        return HttpResponse("‚ùå –ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", status=404)

    if request.method == "POST":
        VINHistoryBackup.objects.create(
            vin=vin,
            post=post_name,
            zone=zone,
            entry=entry_to_edit.copy(),
            action="edit"
        )

        new_vin = request.POST.get("vin_number", "").strip()
        has_defect = request.POST.get("has_defect", "")
        defect_description = request.POST.get("defect_description", "").strip()

        if not new_vin:
            messages.error(request, "‚ùå VIN –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω.")
            return redirect(request.path)

        if new_vin == vin:
            # VIN –Ω–µ –º–µ–Ω—è–ª—Å—è
            entry_to_edit["has_defect"] = has_defect
            entry_to_edit["defect_description"] = defect_description
            history_entry.save()
            messages.success(request, f"‚úÖ –ò–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")
        else:
            # VIN –º–µ–Ω—è–ª—Å—è
            post_entries.remove(entry_to_edit)

            if post_entries:
                history_entry.history[zone][post_name] = post_entries
            else:
                del history_entry.history[zone][post_name]
                if not history_entry.history[zone]:
                    del history_entry.history[zone]

            entry_to_edit["vin_number"] = new_vin
            entry_to_edit["has_defect"] = has_defect
            entry_to_edit["defect_description"] = defect_description

            new_history_entry, _ = VINHistory.objects.get_or_create(vin=new_vin)
            new_history_entry.history.setdefault(zone, {}).setdefault(post_name, []).append(entry_to_edit)

            history_entry.save()
            new_history_entry.save()
            messages.success(request, f"‚úÖ –ò–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã. –ó–∞–ø–∏—Å—å –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –≤ VIN {new_vin}.")

        return redirect(reverse("assembly_post_table") + f"?post={post_name}")

    # –ø–µ—Ä–µ–¥ return render(...)
    try:
        entry_dt = datetime.fromisoformat(entry_to_edit["date_added"])
        entry_to_edit["date_display"] = entry_dt.strftime("%Y-%m-%d %H:%M")
    except Exception:
        entry_to_edit["date_display"] = entry_to_edit["date_added"]

    return render(request, "users/assembly/assembly_post_edit.html", {
        "post_name": post_name,
        "entry": entry_to_edit,
        "vin": vin,
        "timestamp": timestamp,
    })



@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def delete_entry_view(request, vin, post, timestamp):
    zone = "–¶–µ—Ö —Å–±–æ—Ä–∫–∏"

    try:
        timestamp_dt = datetime.fromisoformat(timestamp)
    except ValueError:
        return HttpResponse("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—Ä–µ–º–µ–Ω–∏", status=400)

    history_entry = get_object_or_404(VINHistory, vin=vin)
    post_entries = history_entry.history.get(zone, {}).get(post, [])

    updated_entries = []
    deleted_entry = None  # ‚Üê —Å–æ—Ö—Ä–∞–Ω–∏–º —É–¥–∞–ª—ë–Ω–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç –¥–ª—è –±—ç–∫–∞–ø–∞

    for entry in post_entries:
        try:
            entry_dt = datetime.fromisoformat(entry.get("date_added", ""))
            if abs(entry_dt - timestamp_dt) <= timedelta(seconds=1):
                deleted_entry = entry
                continue  # –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
        except Exception:
            pass
        updated_entries.append(entry)

    if deleted_entry:
        # ‚úÖ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —É–¥–∞–ª—ë–Ω–Ω—É—é –∑–∞–ø–∏—Å—å –≤ VINHistoryBackup
        VINHistoryBackup.objects.create(
            vin=vin,
            post=post,
            zone=zone,
            entry=deleted_entry,
            action="delete"
        )

        # ‚úÖ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∑–∞–ø–∏—Å–∏ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ
        history_entry.history[zone][post] = updated_entries
        history_entry.save()

        messages.success(request, "‚úÖ –ó–∞–ø–∏—Å—å —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ –∞—Ä—Ö–∏–≤.")
    else:
        messages.error(request, "‚ùå –ó–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")

    return redirect(reverse("assembly_post_table") + f"?post={post}")










@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def assembly_general_report(request):
    brands_selected = request.GET.getlist("brand")
    BRAND_MAP = {
        "gwm": ["haval", "tank"],
        "chery": ["chery"],
        "changan": ["changan"]
    }
    models_selected = request.GET.getlist("model")
    download_brand = request.GET.get("download_brand")  # üëà –¥–æ–±–∞–≤–ª–µ–Ω–æ

    mapped_brands = list(chain.from_iterable(BRAND_MAP.get(b, [b]) for b in brands_selected))

    trace_qs = TraceData.objects.all()

    if mapped_brands:
        trace_qs = trace_qs.filter(brand__in=mapped_brands)

    if models_selected:
        trace_qs = trace_qs.filter(model__in=models_selected)

    filtered_vins = set(trace_qs.values_list("vin_rk", flat=True))

    if mapped_brands:
        models_available = TraceData.objects.filter(brand__in=mapped_brands).values_list("model", flat=True).distinct()
    else:
        models_available = TraceData.objects.values_list("model", flat=True).distinct()

    brands_all = TraceData.objects.values_list("brand", flat=True).distinct()

    posts_info = {
        "torque_control": {"post": "–ü–æ—Å—Ç –º–æ–º–µ–Ω—Ç–∞ –∑–∞—Ç—è–∂–µ–∫", "title": "–ü–æ—Å—Ç –º–æ–º–µ–Ω—Ç–∞ –∑–∞—Ç—è–∂–µ–∫"},
        "chassis": {"post": "Chassis", "title": "Chassis"},
        "final_current": {"post": "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å", "title": "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å"},
        "gaps_and_drops": {"post": "–ó–∞–∑–æ—Ä—ã –∏ –ø–µ—Ä–µ–ø–∞–¥—ã", "title": "–ó–∞–∑–æ—Ä—ã –∏ –ø–µ—Ä–µ–ø–∞–¥—ã"},
        "exterior": {"post": "–≠–∫—Å—Ç–µ—Ä—å–µ—Ä", "title": "–≠–∫—Å—Ç–µ—Ä—å–µ—Ä"},
        "interior": {"post": "–ò–Ω—Ç–µ—Ä—å–µ—Ä", "title": "–ò–Ω—Ç–µ—Ä—å–µ—Ä"},
        "trunk": {"post": "–ë–∞–≥–∞–∂–Ω–∏–∫", "title": "–ë–∞–≥–∞–∂–Ω–∏–∫"},
        "motor": {"post": "–ú–æ—Ç–æ—Ä", "title": "–ú–æ—Ç–æ—Ä"},
        "functionality": {"post": "–§—É–Ω–∫—Ü–æ–Ω–∞–ª", "title": "–§—É–Ω–∫—Ü–æ–Ω–∞–ª"},
        "wheel_geometry": {"post": "–ì–µ–æ–º–µ—Ç—Ä–∏—è –∫–æ–ª–µ—Å", "title": "–ì–µ–æ–º–µ—Ç—Ä–∏—è –∫–æ–ª–µ—Å"},
        "light_and_steering": {"post": "–†–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ —Å–≤–µ—Ç–∞ —Ñ–∞—Ä –∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ä—É–ª—è", "title": "–†–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ —Å–≤–µ—Ç–∞ —Ñ–∞—Ä –∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ä—É–ª—è"},
        "brake_system": {"post": "–¢–æ—Ä–º–æ–∑–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞", "title": "–¢–æ—Ä–º–æ–∑–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞"},
        "underbody": {"post": "Underbody", "title": "Underbody"},
        "adas": {"post": "ADAS", "title": "ADAS"},
        "avm": {"post": "AVM", "title": "AVM"},
        "body_tightness": {"post": "–ì–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –∫—É–∑–æ–≤–∞", "title": "–ì–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –∫—É–∑–æ–≤–∞"},
        "diagnostics": {"post": "–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", "title": "–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞"},
        "test_track": {"post": "–¢–µ—Å—Ç —Ç—Ä–µ–∫", "title": "–¢–µ—Å—Ç —Ç—Ä–µ–∫"},
        "documentation": {"post": "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", "title": "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"},
    }

    zone = "–¶–µ—Ö —Å–±–æ—Ä–∫–∏"
    today = now().date()

    start_date_str = request.GET.get("start_date")
    end_date_str = request.GET.get("end_date")

    try:
        start_date = datetime.strptime(start_date_str, "%Y-%m-%d").date() if start_date_str else today - timedelta(days=7)
        end_date = datetime.strptime(end_date_str, "%Y-%m-%d").date() if end_date_str else today
    except ValueError:
        start_date = today - timedelta(days=7)
        end_date = today

    vin_with_final = set()
    vin_with_defect_on_final = set()
    total_defects_on_final = 0
    overall_total_inspections = 0
    overall_inspections_with_defects = 0
    overall_total_defects = 0
    overall_without_defects = 0
    unique_vins = set()
    posts_data = {}

    for key, info in posts_info.items():
        post = info["post"]

        passed_vins = set()
        passed_with_defect = set()
        passed_without_defect = set()
        defect_counter = Counter()
        controller_counter = Counter()
        controller_vin_pairs = set()
        total_defects = 0

        histories = VINHistory.objects.all()
        if filtered_vins:
            histories = histories.filter(vin__in=filtered_vins)

        for history in histories:
            vin = history.vin
            post_entries = history.history.get(zone, {}).get(post, [])
            if not post_entries:
                continue

            entries_in_range = []
            for entry in post_entries:
                raw_date = entry.get("date_added")
                if not raw_date:
                    continue
                entry_date = parse_date(raw_date[:10])
                if entry_date and start_date <= entry_date <= end_date:
                    entries_in_range.append(entry)

            if not entries_in_range:
                continue

            passed_vins.add(vin)
            unique_vins.add(vin)

            vin_has_defect = any(
                entry.get("has_defect") == "yes" or entry.get("defects")
                for entry in entries_in_range
            )

            if vin_has_defect:
                passed_with_defect.add(vin)
                for entry in entries_in_range:
                    if entry.get("has_defect") == "yes" or entry.get("defects"):
                        controller = entry.get("controller", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                        if (controller, vin) not in controller_vin_pairs:
                            controller_counter[controller] += 1
                            controller_vin_pairs.add((controller, vin))

                        for defect in entry.get("defects", []):
                            name = defect.get("name")
                            unit = defect.get("unit")
                            combined = f"{name} ({unit})" if name and unit else name or unit or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                            defect_counter[combined] += 1
                            total_defects += 1
            else:
                passed_without_defect.add(vin)

        total_inspections = len(passed_vins)
        inspections_with_defects = len(passed_with_defect)
        inspections_without_defects = len(passed_without_defect)
        dpu = round(total_defects / total_inspections, 2) if total_inspections else 0
        str_percentage = round(inspections_without_defects / total_inspections * 100, 2) if total_inspections else 0

        encoded_post = urllib.parse.quote(info["post"])
        report_url = reverse("assembly_post_report") + f"?post={encoded_post}"
        table_url = reverse("assembly_post_table") + f"?post={encoded_post}"
        export_url = reverse("assembly_post_export") + f"?post={encoded_post}"

        posts_data[key] = {
            "title": info["title"],
            "total_inspections": total_inspections,
            "inspections_with_defects": inspections_with_defects,
            "without_defects": inspections_without_defects,
            "total_defects": total_defects,
            "dpu": dpu,
            "str_percentage": str_percentage,
            "top_defects": defect_counter.most_common(5),
            "top_controllers": controller_counter.most_common(5),
            "report_url": report_url,
            "table_url": table_url,
            "export_url": export_url,
        }

    # üìå –ê–Ω–∞–ª–∏–∑ —Ç–æ–ª—å–∫–æ –ø–æ –ø–æ—Å—Ç—É "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å"
    # üìå VIN—ã, –ø—Ä–æ—à–µ–¥—à–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
    # üìå VIN—ã, –ø—Ä–æ—à–µ–¥—à–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è" –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
    histories = VINHistory.objects.all()
    if filtered_vins:
        histories = histories.filter(vin__in=filtered_vins)

    vin_with_final = set()
    vin_with_defect_on_any_post = set()
    total_defects_for_final_vins = 0
    # --- begin: date map ---
    vin_final_date_map: dict[str, str] = {}
    final_post_name = "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
    # --- end: date map ---

    for history in histories:
        vin = history.vin
        zone_data = history.history.get(zone, {})

        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –∑–∞–ø–∏—Å—å –Ω–∞ "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è" –≤ –Ω—É–∂–Ω—ã–π –ø–µ—Ä–∏–æ–¥
        final_entries = zone_data.get(final_post_name, [])
        passed_final = False

        for entry in final_entries:
            raw_date = entry.get("date_added")
            if not raw_date:
                continue
            entry_date = parse_date(raw_date[:10])
            if entry_date and start_date <= entry_date <= end_date:
                # --- begin: set date in map if not already set ---
                if vin not in vin_final_date_map:
                    vin_final_date_map[vin] = (raw_date[:10] if isinstance(raw_date, str) else entry_date.strftime("%Y-%m-%d"))
                # --- end: set date in map ---
                passed_final = True
                break

        if not passed_final:
            continue  # VIN –Ω–µ –ø—Ä–æ—à—ë–ª "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è" –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥

        vin_with_final.add(vin)

        # ‚úÖ –¢–µ–ø–µ—Ä—å —Å—á–∏—Ç–∞–µ–º –≤—Å–µ –¥–µ—Ñ–µ–∫—Ç—ã –Ω–∞ –≤—Å–µ—Ö –ø–æ—Å—Ç–∞—Ö —É —ç—Ç–æ–≥–æ VIN
        for post_entries in zone_data.values():
            for entry in post_entries:
                # üî∏ –ù–µ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ ‚Äî —Å—á–∏—Ç–∞–µ–º –í–°–ï –¥–µ—Ñ–µ–∫—Ç—ã –∑–∞ –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é VIN
                defects = entry.get("defects", [])
                if entry.get("has_defect") == "yes" or defects:
                    vin_with_defect_on_any_post.add(vin)
                    total_defects_for_final_vins += len(defects)

    overall_total_inspections = len(vin_with_final)
    overall_inspections_with_defects = len(vin_with_defect_on_any_post)
    overall_without_defects = overall_total_inspections - overall_inspections_with_defects
    overall_total_defects = total_defects_for_final_vins
    overall_dpu = round(overall_total_defects / overall_total_inspections, 2) if overall_total_inspections else 0

    # üìå VIN-–¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–ø–ª—ã–≤–∞—é—â–µ–≥–æ –æ–∫–Ω–∞
    vins_with_defects = list(vin_with_defect_on_any_post)
    vins_without_defects = list(vin_with_final - vin_with_defect_on_any_post)
    vins_all = list(vin_with_final)

    request.session["vin_with_final"] = vins_all
    request.session["vin_with_defect_on_any_post"] = vins_with_defects
    request.session["vin_final_date_map"] = vin_final_date_map

    # –°–æ–ø–æ—Å—Ç–∞–≤–∏–º VIN ‚Üí –±—Ä–µ–Ω–¥ –∏ –º–æ–¥–µ–ª—å
    trace_data_map = {
        obj.vin_rk: {
            "brand": obj.brand,
            "model": obj.model
        }
        for obj in TraceData.objects.filter(vin_rk__in=vin_with_final)
    }

    User = get_user_model()
    all_controllers = set()
    for pdata in posts_data.values():
        for username, _ in pdata["top_controllers"]:
            all_controllers.add(username)

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    controller_users = {
        user.username: user for user in User.objects.filter(username__in=all_controllers)
    }

    context = {
        "start_date": start_date_str or start_date.strftime("%Y-%m-%d"),
        "end_date": end_date_str or end_date.strftime("%Y-%m-%d"),
        "overall_total_inspections": overall_total_inspections,
        "overall_inspections_with_defects": overall_inspections_with_defects,
        "overall_without_defects": overall_without_defects,
        "overall_total_defects": overall_total_defects,
        "overall_dpu": overall_dpu,
        "vins_with_defects": vins_with_defects,
        "vins_without_defects": vins_without_defects,
        "vins_all": vins_all,
        "vin_brand_model_map": trace_data_map,
        # "overall_str_percentage": overall_str_percentage,
        "posts_data": posts_data,
        "controller_users": controller_users,
        "unique_vin_count": overall_total_inspections,
        "models_available": models_available,
        "brands_selected": brands_selected,
        "models_selected": models_selected,
        "brands_all": brands_all,
        "fixed_brands_excel": ['gwm', 'chery', 'changan'],
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    }

    return render(request, "users/assembly/assembly_general_report.html", context)


@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def vin_list_view(request, vin_type):
    # —Ä–∞–Ω—å—à–µ –±—ã–ª–æ: pop(...)
    vins_all = request.session.get("vin_with_final")
    vins_with_defects = request.session.get("vin_with_defect_on_any_post")
    vin_final_date_map = request.session.get("vin_final_date_map", {}) or {}

    if not vins_all or vins_with_defects is None:
        messages.error(request, "‚ùå –°–Ω–∞—á–∞–ª–∞ —Å—Ñ–æ—Ä–º–∏—Ä—É–π—Ç–µ –æ—Ç—á—ë—Ç.")
        return redirect("assembly_general_report")

    vins_without_defects = list(set(vins_all) - set(vins_with_defects))

    vins_map = {
        "with_defects": vins_with_defects,
        "without_defects": vins_without_defects,
        "all": vins_all,
    }

    titles = {
        "with_defects": "VIN —Å –¥–µ—Ñ–µ–∫—Ç–∞–º–∏",
        "without_defects": "VIN –±–µ–∑ –¥–µ—Ñ–µ–∫—Ç–æ–≤",
        "all": "–í—Å–µ VIN",
    }

    vins = vins_map.get(vin_type, [])
    title = titles.get(vin_type, "VIN –Ω–æ–º–µ—Ä–∞")

    trace_data_map = {
        obj.vin_rk: {"brand": obj.brand, "model": obj.model}
        for obj in TraceData.objects.filter(vin_rk__in=vins)
    }

    return render(request, "users/vin_lists_modal.html", {
        "vins": vins,
        "title": title,
        "trace_data_map": trace_data_map,
        "vin_type": vin_type,   # üëà –¥–æ–±–∞–≤–∏–ª–∏ –¥–ª—è –∫–Ω–æ–ø–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞
        "vin_final_date_map": vin_final_date_map,
    })


@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def export_vin_list_excel(request, vin_type):
    """
    –≠–∫—Å–ø–æ—Ä—Ç —Ç–µ–∫—É—â–µ–≥–æ —Å–ø–∏—Å–∫–∞ VIN'–æ–≤ (–∫–∞–∫ –≤ –º–æ–¥–∞–ª–∫–µ) –≤ Excel.
    –ö–æ–ª–æ–Ω–∫–∏: ‚Ññ, VIN, –ë—Ä–µ–Ω–¥, –ú–æ–¥–µ–ª—å, –î–∞—Ç–∞ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è.
    vin_type: with_defects | without_defects | all
    """
    vins_all = request.session.get("vin_with_final")
    vins_with_defects = request.session.get("vin_with_defect_on_any_post")
    vin_final_date_map = request.session.get("vin_final_date_map", {}) or {}

    if not vins_all or vins_with_defects is None:
        return HttpResponse("‚ùå –°–Ω–∞—á–∞–ª–∞ —Å—Ñ–æ—Ä–º–∏—Ä—É–π—Ç–µ –æ—Ç—á—ë—Ç.", status=400)

    vins_without_defects = list(set(vins_all) - set(vins_with_defects))

    vins_map = {
        "with_defects": list(vins_with_defects),
        "without_defects": vins_without_defects,
        "all": list(vins_all),
    }
    vins = vins_map.get(vin_type, [])
    if not isinstance(vins, list):
        vins = list(vins)

    # –±—Ä–µ–Ω–¥/–º–æ–¥–µ–ª—å
    trace_map = {
        t.vin_rk: {"brand": t.brand or "", "model": t.model or ""}
        for t in TraceData.objects.filter(vin_rk__in=vins)
    }

    # Excel
    wb = Workbook()
    ws = wb.active
    ws.title = "VIN-—Å–ø–∏—Å–æ–∫"
    ws.append(["‚Ññ", "VIN", "–ë—Ä–µ–Ω–¥", "–ú–æ–¥–µ–ª—å", "–î–∞—Ç–∞ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è"])

    for idx, v in enumerate(vins, start=1):
        meta = trace_map.get(v, {"brand": "", "model": ""})
        ws.append([idx, v, meta.get("brand", ""), meta.get("model", ""), (vin_final_date_map.get(v, "") or "")])

    for col in ws.columns:
        for cell in col:
            cell.alignment = Alignment(vertical="center")

    filename = f"vin_list_{vin_type}_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx"
    response = HttpResponse(
        content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    response["Content-Disposition"] = f'attachment; filename="{filename}"'
    wb.save(response)
    return response


@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def download_summary_report(request):
    brand = request.GET.get("download_brand")
    start_date = request.GET.get("start_date")
    end_date = request.GET.get("end_date")

    start_date = datetime.strptime(start_date, "%Y-%m-%d").date()
    end_date = datetime.strptime(end_date, "%Y-%m-%d").date()

    path = generate_summary_report(brand, start_date, end_date)

    with open(path, "rb") as f:
        response = HttpResponse(f.read(), content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        response["Content-Disposition"] = f"attachment; filename={os.path.basename(path)}"
        return response





from django.utils.timezone import make_aware, is_naive
from django.utils.dateparse import parse_datetime
from openpyxl import Workbook
from openpyxl.styles import Alignment

@login_required
@permission_required('users.access_to_vqa_data', raise_exception=True)
def export_all_defects_excel(request):
    start_date_str = request.GET.get("start_date")
    end_date_str   = request.GET.get("end_date")
    brand_filter   = request.GET.get("download_brand") or ""  # –º–æ–∂–µ—Ç –ø—Ä–∏–π—Ç–∏ –ø—É—Å—Ç–æ–π

    # --- –≥—Ä–∞–Ω–∏—Ü—ã –ø–µ—Ä–∏–æ–¥–∞ ---
    try:
        start_date = make_aware(datetime.combine(datetime.strptime(start_date_str, "%Y-%m-%d").date(), time.min)) if start_date_str else None
        end_date   = make_aware(datetime.combine(datetime.strptime(end_date_str,   "%Y-%m-%d").date(), time.max)) if end_date_str   else None
    except ValueError:
        return HttpResponse("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã", status=400)

    def _iter_entries(history_data):
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏:
        - –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç: {zone: {post: [entries]}}
        - –ü–æ–ª—É-–Ω–æ–≤—ã–π:   {zone: [entries]}
        - –°—Ç–∞—Ä—ã–π:       [entries]
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂–∏ (zone, post, entry)
        """
        if isinstance(history_data, dict):
            for zone_name, posts in history_data.items():
                if isinstance(posts, dict):
                    for post_name, entries in posts.items():
                        if isinstance(entries, list):
                            for e in entries:
                                yield zone_name or "", post_name or "", e or {}
                elif isinstance(posts, list):
                    for e in posts:
                        yield zone_name or "", "", e or {}
        elif isinstance(history_data, list):
            for e in history_data:
                yield "", "", e or {}

    vin_histories = VINHistory.objects.all()
    data_rows = []

    for history in vin_histories:
        vin = getattr(history, 'vin', '')
        trace = TraceData.objects.filter(vin_rk=vin).first()
        if not trace:
            continue

        if brand_filter and (getattr(trace, 'brand', '') != brand_filter):
            continue

        brand       = getattr(trace, 'brand',       '') or ''
        model       = getattr(trace, 'model',       '') or ''
        config_code = getattr(trace, 'config_code', '') or ''

        history_data = getattr(history, 'history', {}) or {}

        for zone_name, post_name, entry in _iter_entries(history_data):
            try:
                # --- –¥–∞—Ç–∞ ---
                date_raw = (entry.get("date_added")
                            or entry.get("date")
                            or entry.get("extra_data", {}).get("date_added"))
                if not date_raw:
                    continue
                dt = parse_datetime(str(date_raw))
                if dt is None:
                    continue
                if is_naive(dt):
                    dt = make_aware(dt)

                if start_date and dt < start_date:
                    continue
                if end_date and dt > end_date:
                    continue

                # --- –æ—Å—Ç–∞–ª—å–Ω–æ–µ ---
                controller = (entry.get("controller")
                              or entry.get("extra_data", {}).get("controller")
                              or "")
                line       = entry.get("line", "") or entry.get("extra_data", {}).get("line", "") or ""
                duration   = entry.get("inspection_duration_seconds", "") or entry.get("extra_data", {}).get("inspection_duration_seconds", "")

                defects = entry.get("defects")
                if isinstance(defects, list) and defects:
                    for d in defects:
                        data_rows.append({
                            "zone": zone_name, "post": post_name, "vin": vin,
                            "brand": brand, "model": model, "config_code": config_code,
                            "date": dt, "line": line,
                            "unit": d.get("unit", ""),
                            "defect": d.get("name", "") or d.get("defect", ""),
                            "comment": d.get("comment", ""),
                            "quantity": d.get("quantity", ""),
                            "grade": d.get("grade", ""),
                            "responsible": d.get("responsible", ""),
                            "controller": controller, "duration": duration,
                        })
                else:
                    # –∑–∞–ø–∏—Å—å –±–µ–∑ —Å–ø–∏—Å–∫–∞ defects (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
                    data_rows.append({
                        "zone": zone_name, "post": post_name, "vin": vin,
                        "brand": brand, "model": model, "config_code": config_code,
                        "date": dt, "line": line,
                        "unit": entry.get("unit", ""),
                        "defect": entry.get("name", "") or entry.get("defect_description", "") or entry.get("defect", ""),
                        "comment": entry.get("comment", ""),
                        "quantity": entry.get("quantity", ""),
                        "grade": entry.get("grade", ""),
                        "responsible": entry.get("responsible", ""),
                        "controller": controller, "duration": duration,
                    })
            except Exception:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∏—Ç—ã–µ –∑–∞–ø–∏—Å–∏, —á—Ç–æ–±—ã —ç–∫—Å–ø–æ—Ä—Ç –Ω–µ –ø–∞–¥–∞–ª
                continue

    # --- Excel ---
    wb = Workbook()
    ws = wb.active
    ws.title = "–í—Å–µ –¥–µ—Ñ–µ–∫—Ç—ã"

    headers = [
        "–£—á–∞—Å—Ç–æ–∫", "–ü–æ—Å—Ç", "VIN", "–ë—Ä–µ–Ω–¥", "–ú–æ–¥–µ–ª—å", "–ö–æ–¥ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏", "–î–∞—Ç–∞", "–õ–∏–Ω–∏—è",
        "–î–µ—Ç–∞–ª—å", "–î–µ—Ñ–µ–∫—Ç", "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–ì—Ä–µ–π–¥", "–ö—Ç–æ –≤–∏–Ω–æ–≤–∞—Ç",
        "–ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä", "–í—Ä–µ–º—è –æ—Å–º–æ—Ç—Ä–∞ (—Å–µ–∫)"
    ]
    ws.append(headers)

    for row in data_rows:
        try:
            ws.append([
                row.get("zone", ""),
                row.get("post", ""),
                row.get("vin", ""),
                row.get("brand", ""),
                row.get("model", ""),
                row.get("config_code", ""),
                row.get("date").strftime("%d.%m.%Y %H:%M") if row.get("date") else "",
                row.get("line", ""),
                row.get("unit", ""),
                row.get("defect", ""),
                row.get("comment", ""),
                row.get("quantity", ""),
                row.get("grade", ""),
                row.get("responsible", ""),
                row.get("controller", ""),
                row.get("duration", ""),
            ])
        except Exception:
            continue

    # –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ
    for col in ws.columns:
        for cell in col:
            cell.alignment = Alignment(wrap_text=True, vertical='top')

    response = HttpResponse(content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    filename = f"defects_summary_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx"
    response['Content-Disposition'] = f'attachment; filename="{filename}"'
    wb.save(response)
    return response






from django.db.models import Case, When, Value, IntegerField

@login_required
@permission_required('users.access_to_the_vqa_data_management', raise_exception=True)
def manage_post_visibility(request):
    zone_form = AssemblyZoneForm()
    unit_form = AssemblyUnitForm()
    defect_form = AssemblyDefectForm()

    if request.method == "POST":
        if request.headers.get("x-requested-with") == "XMLHttpRequest":
            action = request.POST.get("action")

            if action == "bulk_units_from_zone":
                post_id = request.POST.get("post_id")
                zone_id = request.POST.get("zone_id")

                post = PostAssembly.objects.filter(id=post_id).first()
                if not post:
                    return JsonResponse({"ok": False, "message": "–ü–æ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"}, status=404)

                zone = AssemblyZone.objects.filter(id=zone_id).first()
                if not zone:
                    return JsonResponse({"ok": False, "message": "–ü–æ–¥—Å–∏—Å—Ç–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}, status=404)

                unit_ids_all = list(
                    AssemblyUnit.objects.filter(zone_id=zone_id).values_list("id", flat=True)
                )
                existing = set(post.assembly_units.values_list("id", flat=True))
                to_add_ids = [uid for uid in unit_ids_all if uid not in existing]

                if to_add_ids:
                    post.assembly_units.add(*AssemblyUnit.objects.filter(id__in=to_add_ids))

                return JsonResponse({
                    "ok": True,
                    "added_unit_ids": to_add_ids,
                    "total_in_zone": len(unit_ids_all),
                })

            if action == "bulk_remove_units_of_zone":
                post_id = request.POST.get("post_id")
                zone_id = request.POST.get("zone_id")

                post = PostAssembly.objects.filter(id=post_id).first()
                if not post:
                    return JsonResponse({"ok": False, "message": "–ü–æ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"}, status=404)

                zone = AssemblyZone.objects.filter(id=zone_id).first()
                if not zone:
                    return JsonResponse({"ok": False, "message": "–ü–æ–¥—Å–∏—Å—Ç–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}, status=404)

                unit_ids_zone = list(
                    AssemblyUnit.objects.filter(zone_id=zone_id).values_list("id", flat=True)
                )
                to_remove_qs = post.assembly_units.filter(id__in=unit_ids_zone)
                removed_ids = list(to_remove_qs.values_list("id", flat=True))

                if removed_ids:
                    post.assembly_units.remove(*to_remove_qs)

                return JsonResponse({
                    "ok": True,
                    "removed_unit_ids": removed_ids,
                    "total_in_zone": len(unit_ids_zone),
                })

            # —Ç—É–º–±–ª–µ—Ä zone/unit/defect
            post_id = request.POST.get("post_id")
            item_id = request.POST.get("item_id")
            item_type = request.POST.get("item_type")

            post = PostAssembly.objects.filter(id=post_id).first()
            if not post:
                return JsonResponse({"status": "error", "message": "–ü–æ—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"}, status=404)

            model_map = {
                "zone": (post.assembly_zones, AssemblyZone),
                "unit": (post.assembly_units, AssemblyUnit),
                "defect": (post.assembly_defects, AssemblyDefect),
            }

            if item_type not in model_map:
                return JsonResponse({"status": "error", "message": "–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø"}, status=400)

            m2m_field, model = model_map[item_type]
            item = model.objects.filter(id=item_id).first()
            if not item:
                return JsonResponse({"status": "error", "message": "–û–±—ä–µ–∫—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω"}, status=404)

            if m2m_field.filter(id=item_id).exists():
                m2m_field.remove(item)
                return JsonResponse({"status": "removed"})
            else:
                m2m_field.add(item)
                return JsonResponse({"status": "added"})

        # –æ–±—ã—á–Ω—ã–µ —Ñ–æ—Ä–º—ã
        form_type = request.POST.get("form_type")
        if form_type == "zone":
            zone_form = AssemblyZoneForm(request.POST)
            if zone_form.is_valid():
                zone_form.save()
                messages.success(request, "–ü–æ–¥—Å–∏—Å—Ç–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞.")
            else:
                messages.error(request, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∑–æ–Ω—ã: {zone_form.errors}")
        elif form_type == "unit":
            unit_form = AssemblyUnitForm(request.POST)
            if unit_form.is_valid():
                name = unit_form.cleaned_data['name']
                zone = unit_form.cleaned_data['zone']
                if not AssemblyUnit.objects.filter(name=name, zone=zone).exists():
                    unit_form.save()
                    messages.success(request, "–î–µ—Ç–∞–ª—å —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–∞.")
                else:
                    messages.warning(request, "–¢–∞–∫–∞—è –¥–µ—Ç–∞–ª—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∑–æ–Ω–µ.")
            else:
                messages.error(request, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–µ—Ç–∞–ª–∏: {unit_form.errors}")
        elif form_type == "defect":
            defect_form = AssemblyDefectForm(request.POST)
            if defect_form.is_valid():
                defect_form.save()
                messages.success(request, "–î–µ—Ñ–µ–∫—Ç —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω.")
            else:
                messages.error(request, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–µ—Ñ–µ–∫—Ç–∞: {defect_form.errors}")

        return redirect(request.get_full_path())

    # –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    zones = AssemblyZone.objects.all().order_by("name")
    units = AssemblyUnit.objects.all().order_by("name")
    defects = AssemblyDefect.objects.all().order_by("name")

    order = [
        "–ü–æ—Å—Ç –º–æ–º–µ–Ω—Ç–∞ –∑–∞—Ç—è–∂–µ–∫",
        "Chassis",
        "–§–∏–Ω–∞–ª —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å",
        "–ó–∞–∑–æ—Ä—ã –∏ –ø–µ—Ä–µ–ø–∞–¥—ã",
        "–≠–∫—Å—Ç–µ—Ä—å–µ—Ä",
        "–ò–Ω—Ç–µ—Ä—å–µ—Ä",
        "–ë–∞–≥–∞–∂–Ω–∏–∫",
        "–ú–æ—Ç–æ—Ä",
        "–§—É–Ω–∫—Ü–æ–Ω–∞–ª",  # ‚Üê –ø—Ä–æ–≤–µ—Ä—å —Ç–æ—á–Ω–æ–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∫ –≤ –ë–î
        "–ì–µ–æ–º–µ—Ç—Ä–∏—è –∫–æ–ª–µ—Å",
        "–†–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ —Å–≤–µ—Ç–∞ —Ñ–∞—Ä –∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ä—É–ª—è",
        "–¢–æ—Ä–º–æ–∑–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞",
        "Underbody",
        "ADAS",
        "AVM",
        "–ì–µ—Ä–º–µ—Ç–∏—á–Ω–æ—Å—Ç—å –∫—É–∑–æ–≤–∞",
        "–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞",
        "–¢–µ—Å—Ç —Ç—Ä–µ–∫",
        "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è",
    ]

    order_case = Case(
        *[When(name=n, then=Value(i)) for i, n in enumerate(order)],
        default=Value(999),
        output_field=IntegerField(),
    )

    posts_qs = (
        PostAssembly.objects
        .filter(name__in=order)
        .annotate(order_idx=order_case)
        .order_by("order_idx")
    )
    posts = list(posts_qs)  # —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

    post_visibility = {
        post.id: {
            "zones": list(post.assembly_zones.values_list("id", flat=True)),
            "units": list(post.assembly_units.values_list("id", flat=True)),
            "defects": list(post.assembly_defects.values_list("id", flat=True)),
        }
        for post in posts
    }

    return render(request, "users/assembly/manage_post_visibility.html", {
        "posts": posts,
        "zones": zones,
        "units": units,
        "defects": defects,
        "zone_form": zone_form,
        "unit_form": unit_form,
        "defect_form": defect_form,
        "post_visibility_json": json.dumps(post_visibility, cls=DjangoJSONEncoder),
    })



def _is_ajax(request):
    return request.headers.get("x-requested-with") == "XMLHttpRequest"


# ===== ZONES =====
@login_required
@require_POST
def assembly_zone_update(request):
    pk = request.POST.get("id")
    name = (request.POST.get("name") or "").strip()
    zone = get_object_or_404(AssemblyZone, pk=pk)

    if not name:
        if _is_ajax(request):
            return JsonResponse({"ok": False, "message": "–ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–¥—Å–∏—Å—Ç–µ–º—ã –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º."})
        messages.error(request, "–ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–¥—Å–∏—Å—Ç–µ–º—ã –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º.")
        return redirect("manage_post_visibility")

    if AssemblyZone.objects.filter(name__iexact=name).exclude(pk=pk).exists():
        if _is_ajax(request):
            return JsonResponse({"ok": False, "message": f"–ü–æ–¥—Å–∏—Å—Ç–µ–º–∞ ¬´{name}¬ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."})
        messages.warning(request, f"–ü–æ–¥—Å–∏—Å—Ç–µ–º–∞ ¬´{name}¬ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
        return redirect("manage_post_visibility")

    zone.name = name
    zone.save(update_fields=["name"])
    if _is_ajax(request):
        return JsonResponse({"ok": True, "message": f"–ü–æ–¥—Å–∏—Å—Ç–µ–º–∞ ¬´{name}¬ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞."})
    messages.success(request, f"–ü–æ–¥—Å–∏—Å—Ç–µ–º–∞ ¬´{name}¬ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
    return redirect("manage_post_visibility")


@login_required
@require_POST
def assembly_zone_delete(request):
    pk = request.POST.get("id")
    zone = get_object_or_404(AssemblyZone, pk=pk)
    name = zone.name
    zone.delete()
    if _is_ajax(request):
        return JsonResponse({"ok": True, "removed": True, "message": f"–ü–æ–¥—Å–∏—Å—Ç–µ–º–∞ ¬´{name}¬ª —É–¥–∞–ª–µ–Ω–∞."})
    messages.success(request, f"–ü–æ–¥—Å–∏—Å—Ç–µ–º–∞ ¬´{name}¬ª —É–¥–∞–ª–µ–Ω–∞.")
    return redirect("manage_post_visibility")


# ===== UNITS =====
@login_required
@require_POST
def assembly_unit_update(request):
    pk = request.POST.get("id")
    name = (request.POST.get("name") or "").strip()
    zone_id = request.POST.get("zone")
    unit = get_object_or_404(AssemblyUnit, pk=pk)

    if not name:
        if _is_ajax(request):
            return JsonResponse({"ok": False, "message": "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª–∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º."})
        messages.error(request, "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª–∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º.")
        return redirect("manage_post_visibility")

    zone = get_object_or_404(AssemblyZone, pk=zone_id) if zone_id else None

    if AssemblyUnit.objects.filter(zone=zone, name__iexact=name).exclude(pk=pk).exists():
        if _is_ajax(request):
            return JsonResponse({"ok": False, "message": f"–î–µ—Ç–∞–ª—å ¬´{name}¬ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø–æ–¥—Å–∏—Å—Ç–µ–º–µ."})
        messages.warning(request, f"–î–µ—Ç–∞–ª—å ¬´{name}¬ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø–æ–¥—Å–∏—Å—Ç–µ–º–µ.")
        return redirect("manage_post_visibility")

    unit.name = name
    unit.zone = zone
    unit.save(update_fields=["name", "zone"])
    if _is_ajax(request):
        return JsonResponse({"ok": True, "message": f"–î–µ—Ç–∞–ª—å ¬´{name}¬ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞."})
    messages.success(request, f"–î–µ—Ç–∞–ª—å ¬´{name}¬ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
    return redirect("manage_post_visibility")


@login_required
@require_POST
def assembly_unit_delete(request):
    pk = request.POST.get("id")
    unit = get_object_or_404(AssemblyUnit, pk=pk)
    name = unit.name
    unit.delete()
    if _is_ajax(request):
        return JsonResponse({"ok": True, "removed": True, "message": f"–î–µ—Ç–∞–ª—å ¬´{name}¬ª —É–¥–∞–ª–µ–Ω–∞."})
    messages.success(request, f"–î–µ—Ç–∞–ª—å ¬´{name}¬ª —É–¥–∞–ª–µ–Ω–∞.")
    return redirect("manage_post_visibility")


# ===== DEFECTS =====
@login_required
@require_POST
def assembly_defect_update(request):
    pk = request.POST.get("id")
    name = (request.POST.get("name") or "").strip()
    defect = get_object_or_404(AssemblyDefect, pk=pk)

    if not name:
        if _is_ajax(request):
            return JsonResponse({"ok": False, "message": "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ—Ñ–µ–∫—Ç–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º."})
        messages.error(request, "–ù–∞–∑–≤–∞–Ω–∏–µ –¥–µ—Ñ–µ–∫—Ç–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º.")
        return redirect("manage_post_visibility")

    if AssemblyDefect.objects.filter(name__iexact=name).exclude(pk=pk).exists():
        if _is_ajax(request):
            return JsonResponse({"ok": False, "message": f"–î–µ—Ñ–µ–∫—Ç ¬´{name}¬ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."})
        messages.warning(request, f"–î–µ—Ñ–µ–∫—Ç ¬´{name}¬ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
        return redirect("manage_post_visibility")

    defect.name = name
    defect.save(update_fields=["name"])
    if _is_ajax(request):
        return JsonResponse({"ok": True, "message": f"–î–µ—Ñ–µ–∫—Ç ¬´{name}¬ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω."})
    messages.success(request, f"–î–µ—Ñ–µ–∫—Ç ¬´{name}¬ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
    return redirect("manage_post_visibility")


@login_required
@require_POST
def assembly_defect_delete(request):
    pk = request.POST.get("id")
    defect = get_object_or_404(AssemblyDefect, pk=pk)
    name = defect.name
    defect.delete()
    if _is_ajax(request):
        return JsonResponse({"ok": True, "removed": True, "message": f"–î–µ—Ñ–µ–∫—Ç ¬´{name}¬ª —É–¥–∞–ª—ë–Ω."})
    messages.success(request, f"–î–µ—Ñ–µ–∫—Ç ¬´{name}¬ª —É–¥–∞–ª—ë–Ω.")
    return redirect("manage_post_visibility")





# QRQC
# QRQC –æ—Ç—á–µ—Ç –æ—Ç–¥–µ–ª–∞ VQA

# assembly/views_qrqc_demo.py
from datetime import date
from typing import Any, Dict, List

from django.contrib.auth.decorators import login_required
from django.shortcuts import render
from django.utils.dateparse import parse_date
from django.db.models import Q

from assembly.services import utils_qrqc as uq

from qrr.models import QRRResponsible


# --- Counters (VIN stats) ---
from assembly.services.utils_counter import (
    counter_vins,
    counter_vins_from_vehicle_history,
    counter_vins_documentation,
    POST_AREA_MAPPING,
)

def _fmt_prev5_for_chart(rows: List[dict]) -> Dict[str, Any]:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç 5 –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –Ω–µ–¥–µ–ª—å –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç totals (unique_vins/dpu/str) –∏ averages (avg_unique_vins/avg_dpu/avg_str).
    –¢–∞–∫–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–µ–ª—å –¥–ª—è –∫–ª–∏–∫–æ–≤: iso_year, iso_week, start (–ü–Ω ISO) –≤ ISO —Ñ–æ—Ä–º–∞—Ç–µ.
    """
    labels, dpu, str_, uniq = [], [], [], []
    weeks_meta: List[Dict[str, Any]] = []
    for r in rows:
        # –º–µ—Ç–∫–∏
        labels.append(f"–ù–µ–¥. {r['iso_week']:02d}")
        # –∑–Ω–∞—á–µ–Ω–∏—è (ÂÖºÂÆπ totals/avg)
        dpu.append(r.get("dpu", r.get("avg_dpu", 0)))
        str_.append(r.get("str", r.get("avg_str", 0)))
        uniq.append(r.get("unique_vins", r.get("avg_unique_vins", 0)))
        # –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–µ–ª–∏
        weeks_meta.append({
            "iso_year": r.get("iso_year"),
            "iso_week": r.get("iso_week"),
            "start": (r.get("start").isoformat() if hasattr(r.get("start"), "isoformat") else r.get("start")),
        })
    return {
        "labels": labels,
        "series": {"dpu": dpu, "str": str_, "unique_vins": uniq},
        "weeks": weeks_meta,
    }


def _fmt_current_week_for_chart(rows: List[dict]) -> Dict[str, Any]:
    """
    qrqc_current_week_daily -> {labels, series:{dpu,str,unique_vins}}
    """
    labels, dpu, str_, uniq = [], [], [], []
    for r in rows:
        d: date = r["date"]  # type: ignore[assignment]
        labels.append(d.strftime("%d.%m"))
        dpu.append(r["dpu"])
        str_.append(r["str"])
        uniq.append(r["unique_vins"])
    return {"labels": labels, "series": {"dpu": dpu, "str": str_, "unique_vins": uniq}}


@login_required
@permission_required('users.access_to_the_qrqc_report_vqa', raise_exception=True)
def qrqc_dashboard_view(request):
    """
    6 –≥—Ä–∞—Ñ–∏–∫–æ–≤: Chery/GWM/Changan √ó (5 –ø—Ä–æ—à–ª—ã—Ö –Ω–µ–¥–µ–ª—å totals / —Ç–µ–∫—É—â–∞—è –Ω–µ–¥–µ–ª—è daily)
    GET:
      ?date=YYYY-MM-DD
      ?grade=V1|V2|V3
      ?post=–≠–∫—Å—Ç–µ—Ä—å–µ—Ä|–ò–Ω—Ç–µ—Ä—å–µ—Ä|...
      ?models=Tiggo%202%20PRO,Tiggo%207  (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, —Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    """
    # –±–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
    raw_date = request.GET.get("date")
    target = parse_date(raw_date) if raw_date else date.today()

    grade = request.GET.get("grade") or None
    post = request.GET.get("post") or None
    models_raw = request.GET.get("models") or ""
    models = [m.strip() for m in models_raw.split(",") if m.strip()] or None

    # weekly mode (sum/avg) from query param
    weekly_mode = request.GET.get("weekly")
    if weekly_mode not in {"sum", "avg"}:
        weekly_mode = "sum"

    brands = ["chery", "gwm", "changan"]
    charts: Dict[str, Dict[str, Any]] = {}

    for b in brands:
        prev5_totals = uq.qrqc_prev5_weeks_totals(target, brand=b, models=models, grade=grade, post=post)
        prev5_avg = uq.qrqc_prev5_weeks_avg(target, brand=b, models=models, grade=grade, post=post)
        current_week = uq.qrqc_current_week_daily(target, brand=b, models=models, grade=grade, post=post)

        charts[b] = {
            "prev5_sum": _fmt_prev5_for_chart(prev5_totals),  # —Å—É–º–º—ã –∑–∞ 5 –Ω–µ–¥–µ–ª—å
            "prev5_avg": _fmt_prev5_for_chart(prev5_avg),  # —Å—Ä–µ–¥–Ω–∏–µ –ø–æ –∞–∫—Ç–∏–≤–Ω—ã–º –¥–Ω—è–º
            "current": _fmt_current_week_for_chart(current_week),
        }

    ctx = {
        "target_date": target.isoformat(),
        "active_filters": {"grade": grade, "post": post, "models": models or []},
        "charts": charts,
        "weekly_mode_default": weekly_mode,  # 'sum' | 'avg'
        "series_meta": {          # –ø–æ–¥—Å–∫–∞–∑–∫–∞ —Ñ—Ä–æ–Ω—Ç—É –ø–æ —Ç–∏–ø–∞–º —Ä—è–¥–æ–≤ –∏ –æ—Å—è–º
            "dpu": {"type": "line", "yAxis": "left"},
            "str": {"type": "line", "yAxis": "right"},
            "unique_vins": {"type": "bar", "yAxis": "bar"},
        },
        "titles": {
            "chery":   {"prev5": "Chery ‚Äî –ø—Ä–æ—à–ª—ã–µ 5 –Ω–µ–¥–µ–ª—å",   "current": "Chery ‚Äî —Ç–µ–∫—É—â–∞—è –Ω–µ–¥–µ–ª—è"},
            "gwm":     {"prev5": "GWM ‚Äî –ø—Ä–æ—à–ª—ã–µ 5 –Ω–µ–¥–µ–ª—å",     "current": "GWM ‚Äî —Ç–µ–∫—É—â–∞—è –Ω–µ–¥–µ–ª—è"},
            "changan": {"prev5": "Changan ‚Äî –ø—Ä–æ—à–ª—ã–µ 5 –Ω–µ–¥–µ–ª—å", "current": "Changan ‚Äî —Ç–µ–∫—É—â–∞—è –Ω–µ–¥–µ–ª—è"},
        },
        "brands": brands,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    }
    return render(request, "users/qrqc/qrqc_dashboard.html", ctx)

# ===== Brand-focused QRQC page (charts + tables) =====
from typing import Optional, Sequence

# --- Period helpers for QRQC brand page ---
from datetime import timedelta as _timedelta
from dateutil.relativedelta import relativedelta as _relativedelta

def _norm_list_param(raw: Optional[str]) -> Optional[list[str]]:
    """
    Accepts comma-separated string or None; returns list[str] or None.
    """
    if not raw:
        return None
    items = [x.strip() for x in raw.split(",") if x.strip()]
    return items or None


def _fmt_posts_for_chart(rows: List[dict]) -> Dict[str, Any]:
    """
    uq.qrqc_by_posts(...) -> chart payload
    rows item: {"post","inspected","defects","offline_defects","dpu","str",...}
    """
    labels = [r["post"] for r in rows]
    series = {
        "unique_vins": [r.get("inspected", 0) for r in rows],
        "dpu": [r.get("dpu", 0.0) for r in rows],
        "str": [r.get("str", 0.0) for r in rows],
    }
    return {"labels": labels, "series": series}


def _fmt_grades_for_chart(rows: List[dict]) -> Dict[str, Any]:
    """
    uq.qrqc_defects_by_grade(...) -> chart payload
    rows item: {"grade","defects", "vins":[...]}
    """
    labels = [r["grade"] for r in rows]
    series = {
        "defects": [r.get("defects", 0) for r in rows],
        "unique_vins": [len(r.get("vins", [])) for r in rows],
    }
    return {"labels": labels, "series": series}



def _fmt_models_for_chart(rows: List[dict]) -> Dict[str, Any]:
    """
    uq.qrqc_by_models(...) -> chart payload
    rows item: {"model","inspected","defects","offline_defects","dpu","str",...}
    """
    labels = [r["model"] or "‚Äî" for r in rows]
    series = {
        "unique_vins": [r.get("inspected", 0) for r in rows],
        "dpu": [r.get("dpu", 0.0) for r in rows],
        "str": [r.get("str", 0.0) for r in rows],
    }
    return {"labels": labels, "series": series}


# --- DPU –ø–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–º (for charts) ---
def _fmt_dpu_responsibles_for_chart(rows: List[dict], all_names: List[str] | None = None) -> Dict[str, Any]:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç payload –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ DPU –ø–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–º.
    rows: —Ä–µ–∑—É–ª—å—Ç–∞—Ç uq.qrqc_dpu_by_responsible() -> [{"responsible","defects_weight","inspected","dpu"}, ...]
    all_names: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö, –¥–æ–±–∞–≤–ª—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Å dpu=0 –≤ –∫–æ–Ω–µ—Ü (–ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç {labels:[...], series:{dpu:[...]}, meta:{active_count:int, all_count:int}}
    """
    # –∞–∫—Ç–∏–≤–Ω—ã–µ (–∏–º–µ—é—Ç –¥–∞–Ω–Ω—ã–µ)
    active_map = { (r.get("responsible") or "").strip(): float(r.get("dpu", 0.0) or 0.0) for r in (rows or []) }
    active_names = [name for name in active_map.keys() if name]
    # –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –±–∞–∑–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    labels: List[str] = []
    dpu_vals: List[float] = []
    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –æ—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –≤ –∞–ª—Ñ–∞–≤–∏—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    for name in sorted(active_names, key=lambda x: x.lower()):
        labels.append(name)
        dpu_vals.append(round(active_map.get(name, 0.0), 6))
    active_count = len(labels)

    # –ï—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–±–∏—Ç—å –¥–æ ¬´–≤—Å–µ—Ö¬ª ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Å –Ω—É–ª—è–º–∏
    if all_names is not None:
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –∏–º–µ–Ω–∞
        all_norm = sorted({ (n or "").strip() for n in all_names if (n or "").strip() }, key=lambda x: x.lower())
        # –î–æ–±–∞–≤–∏–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã –∏–∑ —Ä–∞—Å—á—ë—Ç–∞ (–µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è)
        if "(–í –æ–∂–∏–¥–∞–Ω–∏–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è)" in active_map and "(–í –æ–∂–∏–¥–∞–Ω–∏–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è)" not in all_norm:
            all_norm.append("(–í –æ–∂–∏–¥–∞–Ω–∏–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è)")
        if "ALL" in active_map and "ALL" not in all_norm:
            all_norm.append("ALL")
        # –ü—Ä–æ–π–¥—ë–º—Å—è –ø–æ –≤—Å–µ–º—É —Å–ø–∏—Å–∫—É –∏ —Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ —Ä—è–¥—ã
        labels_all: List[str] = []
        dpu_all: List[float] = []
        for name in all_norm:
            labels_all.append(name)
            dpu_all.append(round(active_map.get(name, 0.0), 6))
        return {
            "labels": labels_all,
            "series": {"dpu": dpu_all},
            "meta": {"active_count": active_count, "all_count": len(labels_all)},
        }

    return {"labels": labels, "series": {"dpu": dpu_vals}, "meta": {"active_count": active_count, "all_count": active_count}}


# ==== Extra helpers for ranged daily series ‚Üí chart payloads ====
from collections import defaultdict as _dd
from datetime import date as _date


def _fmt_daily_for_chart(rows: List[dict]) -> Dict[str, Any]:
    """
    rows items: {"date": date, "unique_vins": int, "defects": int, "dpu": float, "str": float}
    ‚Üí {labels:["dd.mm",...], series:{unique_vins:[], dpu:[], str:[]}}
    """
    labels, uniq, dpu, str_ = [], [], [], []
    for r in rows or []:
        d: _date = r.get("date")  # type: ignore[assignment]
        if hasattr(d, "strftime"):
            labels.append(d.strftime("%d.%m"))
        else:
            labels.append(str(d))
        uniq.append(r.get("unique_vins", 0) or 0)
        dpu.append(r.get("dpu", 0.0) or 0.0)
        str_.append(r.get("str", 0.0) or 0.0)
    return {"labels": labels, "series": {"unique_vins": uniq, "dpu": dpu, "str": str_}}


def _aggregate_days_to_weeks(rows: List[dict]) -> Dict[str, Any]:
    """
    –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –¥–Ω–µ–≤–Ω–æ–π —Ä—è–¥ –ø–æ ISO-–Ω–µ–¥–µ–ª—è–º. –î–ª—è –∫–∞–∂–¥–æ–π –Ω–µ–¥–µ–ª–∏:
      unique_vins = Œ£ unique_vins
      defects = Œ£ defects
      dpu = defects / unique_vins (0 –µ—Å–ª–∏ unique_vins==0)
      str = 100 - ( (Œ£ offline_vins_count) / (Œ£ unique_vins) * 100 )
    offline_vins_count –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–∑ –¥–Ω–µ–≤–Ω—ã—Ö STR: uniq * (100 - str) / 100.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç chart payload {labels, series:{unique_vins,dpu,str}} —Å –º–µ—Ç–∫–∞–º–∏ "–ù–µ–¥. WW".
    """
    buckets = _dd(lambda: {"uniq": 0, "defects": 0, "offline_vins": 0.0, "iso_year": None, "iso_week": None})
    for r in rows or []:
        d: _date = r.get("date")  # type: ignore[assignment]
        if not hasattr(d, "isocalendar"):
            continue
        y, w, _ = d.isocalendar()
        key = (y, w)
        uniq = int(r.get("unique_vins", 0) or 0)
        defects = int(r.get("defects", 0) or 0)
        str_val = float(r.get("str", 0.0) or 0.0)
        offline = (uniq * max(0.0, min(100.0, 100.0 - str_val)))/100.0
        b = buckets[key]
        b["iso_year"], b["iso_week"] = y, w
        b["uniq"] += uniq
        b["defects"] += defects
        b["offline_vins"] += offline

    # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –Ω–µ–¥–µ–ª—è–º (–≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏–µ)
    ordered = sorted(buckets.values(), key=lambda x: (x["iso_year"], x["iso_week"]))
    labels, uniq_s, dpu_s, str_s = [], [], [], []
    for b in ordered:
        labels.append(f"–ù–µ–¥. {int(b['iso_week']):02d}")
        uniq = int(b["uniq"]) or 0
        defects = int(b["defects"]) or 0
        dpu = round(defects/uniq, 2) if uniq else 0.0
        str_val = 0.0 if uniq == 0 else max(0.0, min(100.0, round(100.0 - ((b["offline_vins"]/uniq)*100.0), 2)))
        uniq_s.append(uniq)
        dpu_s.append(dpu)
        str_s.append(str_val)
    return {"labels": labels, "series": {"unique_vins": uniq_s, "dpu": dpu_s, "str": str_s}}


essential_month_names = ["01","02","03","04","05","06","07","08","09","10","11","12"]

def _aggregate_days_to_months(rows: List[dict]) -> Dict[str, Any]:
    """
    –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –¥–Ω–µ–≤–Ω–æ–π —Ä—è–¥ –ø–æ –º–µ—Å—è—Ü–∞–º (YYYY-MM). –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∫–∞–∫ –≤ –Ω–µ–¥–µ–ª—è—Ö.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç payload {labels:['YYYY-MM',...], series:{unique_vins,dpu,str}}.
    """
    buckets = _dd(lambda: {"uniq": 0, "defects": 0, "offline_vins": 0.0})
    for r in rows or []:
        d: _date = r.get("date")  # type: ignore[assignment]
        if not hasattr(d, "strftime"):
            continue
        ym = d.strftime("%Y-%m")
        uniq = int(r.get("unique_vins", 0) or 0)
        defects = int(r.get("defects", 0) or 0)
        str_val = float(r.get("str", 0.0) or 0.0)
        offline = (uniq * max(0.0, min(100.0, 100.0 - str_val)))/100.0
        b = buckets[ym]
        b["uniq"] += uniq
        b["defects"] += defects
        b["offline_vins"] += offline

    ordered_keys = sorted(buckets.keys())
    labels, uniq_s, dpu_s, str_s = [], [], [], []
    for k in ordered_keys:
        b = buckets[k]
        uniq = int(b["uniq"]) or 0
        defects = int(b["defects"]) or 0
        dpu = round(defects/uniq, 2) if uniq else 0.0
        str_val = 0.0 if uniq == 0 else max(0.0, min(100.0, round(100.0 - ((b["offline_vins"]/uniq)*100.0), 2)))
        labels.append(k)
        uniq_s.append(uniq)
        dpu_s.append(dpu)
        str_s.append(str_val)
    return {"labels": labels, "series": {"unique_vins": uniq_s, "dpu": dpu_s, "str": str_s}}



def _iso_week_bounds(_d: _date) -> tuple[_date, _date]:
    """
    Returns Monday..Sunday (inclusive) of the ISO week containing _d.
    """
    # Monday=0 .. Sunday=6
    wd = _d.weekday()
    start = _d - _timedelta(days=wd)
    end = start + _timedelta(days=6)
    return start, end

# --- New helpers for explicit ISO week selection ---
import re as _re

def _iso_week_bounds_yw(iso_year: int, iso_week: int) -> tuple[_date, _date]:
    """Return Monday..Sunday for a given ISO year/week."""
    # Find Monday of week 1
    jan4 = _date(iso_year, 1, 4)
    # Monday of the first ISO week
    week1_monday = jan4 - _timedelta(days=jan4.weekday())
    start = week1_monday + _timedelta(weeks=iso_week - 1)
    end = start + _timedelta(days=6)
    return start, end

def _parse_iso_week_param(request) -> tuple[int | None, int | None]:
    """Accepts ?iso=YYYY-Www or ?iso=YYYYWww or ?iso_year=&iso_week=; returns (year, week) or (None, None)."""
    raw = (request.GET.get("iso") or "").strip()
    if raw:
        m = _re.match(r"^(\d{4})-?[Ww](\d{1,2})$", raw)
        if m:
            try:
                y = int(m.group(1)); w = int(m.group(2))
                return y, w
            except Exception:
                pass
    y_raw = (request.GET.get("iso_year") or "").strip()
    w_raw = (request.GET.get("iso_week") or "").strip()
    if y_raw and w_raw and y_raw.isdigit() and w_raw.isdigit():
        try:
            return int(y_raw), int(w_raw)
        except Exception:
            return None, None
    return None, None


def _normalize_top_rows(rows: List[dict]) -> List[dict]:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç —Å—Ç—Ä–æ–∫–∏ TOP‚Äë—Ç–∞–±–ª–∏—Ü –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É:
      1) detail: str
      2) defect: str
      3) count: int
      4) grade: str
      5) responsibles: dict[str,float]
      6) defect_ids: list[str]
      7) vins: list[str]
    """
    normalized: List[dict] = []
    for r in (rows or []):
        try:
            normalized.append({
                "detail": r.get("detail") or "",
                "defect": r.get("defect") or "",
                "count": int(r.get("count", 0) or 0),
                "grade": r.get("grade") or "",
                "responsibles": r.get("responsibles") or {},
                "defect_ids": list(r.get("defect_ids") or []),
                "vins": list(r.get("vins") or []),
            })
        except Exception:
            # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –±–∏—Ç—É—é —Å—Ç—Ä–æ–∫—É
            continue
    return normalized

@login_required
@permission_required('users.access_to_the_qrqc_report_vqa', raise_exception=True)
def qrqc_brand_view(request, brand=None):
    """
    –ë—Ä–µ–Ω–¥–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ QRQC —Å –Ω–∞–±–æ—Ä–∞–º–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∏ –¥–≤—É–º—è —Ç–∞–±–ª–∏—Ü–∞–º–∏:
      - –≥—Ä–∞—Ñ–∏–∫ –ø–æ –Ω–µ–¥–µ–ª—è–º (—Å—É–º–º–∞—Ä–Ω–æ) –¥–ª—è –±—Ä–µ–Ω–¥–∞
      - –≥—Ä–∞—Ñ–∏–∫ –ø–æ –¥–Ω—è–º (—Ç–µ–∫—É—â–∞—è ISO‚Äë–Ω–µ–¥–µ–ª—è target_date)
      - –≥—Ä–∞—Ñ–∏–∫ –ø–æ –ø–æ—Å—Ç–∞–º (DPU/STR/–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ)
      - –≥—Ä–∞—Ñ–∏–∫ –ø–æ –≥—Ä–µ–π–¥–∞–º (–∫–æ–ª-–≤–æ –¥–µ—Ñ–µ–∫—Ç–æ–≤, —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ VIN)
      - –≥—Ä–∞—Ñ–∏–∫ –ø–æ –º–æ–¥–µ–ª—è–º (DPU/STR/–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ)
      - —Ç–∞–±–ª–∏—Ü–∞ ¬´–¢–û–ü –¥–µ—Ñ–µ–∫—Ç–æ–≤ –ø–æ –≥—Ä–µ–π–¥–∞–º¬ª
      - —Ç–∞–±–ª–∏—Ü–∞ ¬´–¢–û–ü –¥–µ—Ñ–µ–∫—Ç–æ–≤ –ø–æ –º–∞—Å—Å–æ–≤–æ—Å—Ç–∏¬ª
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ GET‚Äë–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–≤—Å–µ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):
      ?brand=gwm|chery|changan
      ?date=YYYY-MM-DD    (–µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ start/end)
      ?start=YYYY-MM-DD&amp;end=YYYY-MM-DD
      ?models=A,B,C
      ?posts=P1,P2
      ?grades=V1,V2,V3
      ?weekly=sum|avg     (—Ä–µ–∂–∏–º –¥–ª—è ¬´–ø—Ä–µ–¥. 5 –Ω–µ–¥–µ–ª—å¬ª: totals/averages)
    –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –Ω–µ–¥–µ–ª—å–Ω—ã–µ/–¥–Ω–µ–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –ø—Ä–∏–Ω–∏–º–∞—é—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω–æ—á–Ω—ã–µ post/grade.
    –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ ‚Äî –≤ —ç—Ç–∏ –≥—Ä–∞—Ñ–∏–∫–∏ –ø–æ—Å—Ç/–≥—Ä–µ–π–¥ –Ω–µ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è (–±–µ—Ä—É—Ç—Å—è –≤—Å–µ).
    """
    # ---- Parse filters
    brand = ((request.GET.get("brand") or brand or "").strip().lower() or None)
    raw_date = request.GET.get("date")
    raw_start = request.GET.get("start")
    raw_end = request.GET.get("end")

    target = parse_date(raw_date) if raw_date else date.today()
    start_d = parse_date(raw_start) if raw_start else None
    end_d = parse_date(raw_end) if raw_end else None
    if raw_date:  # –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –¥–Ω—è
        start_d = end_d = None

    # --- Parse ISO week explicit params ---
    iso_y, iso_w = _parse_iso_week_param(request)

    # Range & aggregation (affects ALL breakdown charts/tables when start/end are not provided)
    range_param = (request.GET.get("range") or "").strip().lower()
    agg_param   = (request.GET.get("agg") or "").strip().lower()  # reserved for UI, not used in backend math here

    # If an explicit ISO week is passed ‚Äì use its Monday..Sunday as the working period
    if iso_y and iso_w:
        start_d, end_d = _iso_week_bounds_yw(iso_y, iso_w)
        # anchor target inside selected week to keep daily chart labels stable
        target = start_d
    elif start_d is None and end_d is None:
        # No explicit period ‚Äì use range presets
        if range_param == "day":
            # current ISO week for the target date
            wn_start, wn_end = _iso_week_bounds(target)
            start_d, end_d = wn_start, wn_end
        elif range_param == "week":
            # last 5 ISO weeks including week of target
            wn_start, wn_end = _iso_week_bounds(target)
            start_d = wn_start - _timedelta(weeks=4)
            end_d = wn_end
        elif range_param == "month":
            start_d = target - _timedelta(days=29)
            end_d = target
        elif range_param == "halfyear":
            start_d = target - _relativedelta(months=6)
            end_d = target
        elif range_param == "year":
            start_d = target - _relativedelta(years=1)
            end_d = target
        else:
            # keep None ‚Äì single-day mode (target_date only)
            pass

    models = _norm_list_param(request.GET.get("models"))
    posts = _norm_list_param(request.GET.get("posts"))
    grades = _norm_list_param(request.GET.get("grades"))

    weekly_mode = request.GET.get("weekly")
    if weekly_mode not in {"sum", "avg"}:
        weekly_mode = "sum"

    # –î–ª—è –Ω–µ–¥–µ–ª—å–Ω—ã—Ö/–¥–Ω–µ–≤–Ω—ã—Ö API ‚Äî –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    post_single = posts[0] if posts and len(posts) == 1 else None
    grade_single = grades[0] if grades and len(grades) == 1 else None

    # ---- Data assembly
    charts: Dict[str, Any] = {}

    # weekly totals / averages for brand
    prev5_totals = uq.qrqc_prev5_weeks_totals(target, brand=brand, models=models, grade=grade_single, post=post_single)
    prev5_avg = uq.qrqc_prev5_weeks_avg(target, brand=brand, models=models, grade=grade_single, post=post_single)
    # daily current-week chart: use selected ISO week if provided
    if iso_y and iso_w:
        try:
            current_week = uq.qrqc_week_daily(iso_y, iso_w, brand=brand, models=models, grade=grade_single, post=post_single)
        except Exception:
            current_week = uq.qrqc_current_week_daily(target, brand=brand, models=models, grade=grade_single, post=post_single)
    else:
        current_week = uq.qrqc_current_week_daily(target, brand=brand, models=models, grade=grade_single, post=post_single)

    charts["prev5_sum"] = _fmt_prev5_for_chart(prev5_totals)
    charts["prev5_avg"] = _fmt_prev5_for_chart(prev5_avg)
    charts["current"] = _fmt_current_week_for_chart(current_week)

    # posts breakdown (respects multi posts/grades)
    posts_rows = uq.qrqc_by_posts(
        target_date=target if (not start_d and not end_d) else None,
        start_d=start_d, end_d=end_d,
        brand=brand, models=models, grades=grades, posts=posts,
    )
    charts["by_posts"] = _fmt_posts_for_chart(posts_rows)

    # grades breakdown
    grades_rows = uq.qrqc_defects_by_grade(
        target_date=target if (not start_d and not end_d) else None,
        start_d=start_d, end_d=end_d,
        brand=brand, models=models, posts=posts, grades=grades,
    )
    charts["by_grades"] = _fmt_grades_for_chart(grades_rows)

    # models breakdown
    models_rows = uq.qrqc_by_models(
        target_date=target if (not start_d and not end_d) else None,
        start_d=start_d, end_d=end_d,
        brand=brand, models=models, grades=grades, posts=posts,
    )
    charts["by_models"] = _fmt_models_for_chart(models_rows)

    # ===== RANGED DAILY SERIES (month / halfyear / year) =====
    try:
        month_daily = uq.qrqc_last_month_daily(target, brand=brand, models=models, grade=grade_single, post=post_single)
    except Exception:
        month_daily = []
    try:
        halfyear_daily = uq.qrqc_last_halfyear_daily(target, brand=brand, models=models, grade=grade_single, post=post_single)
    except Exception:
        halfyear_daily = []
    try:
        year_daily = uq.qrqc_last_year_daily(target, brand=brand, models=models, grade=grade_single, post=post_single)
    except Exception:
        year_daily = []

    # For the UI: provide all aggregations explicitly so toggle (–î–Ω—è–º–∏/–ù–µ–¥–µ–ª—è–º–∏/–ú–µ—Å—è—Ü–∞–º–∏) works
    charts["month_by_days"]    = _fmt_daily_for_chart(month_daily)
    charts["month_by_weeks"]   = _aggregate_days_to_weeks(month_daily)
    charts["month_by_months"]  = _aggregate_days_to_months(month_daily)

    charts["halfyear_by_days"]   = _fmt_daily_for_chart(halfyear_daily)
    charts["halfyear_by_weeks"]  = _aggregate_days_to_weeks(halfyear_daily)
    charts["halfyear_by_months"] = _aggregate_days_to_months(halfyear_daily)

    charts["year_by_days"]   = _fmt_daily_for_chart(year_daily)
    charts["year_by_weeks"]  = _aggregate_days_to_weeks(year_daily)
    charts["year_by_months"] = _aggregate_days_to_months(year_daily)

    # tables
    top_by_grades = uq.qrqc_top_defects_by_grades(
        target_date=target if (not start_d and not end_d) else None,
        start_d=start_d, end_d=end_d,
        brand=brand, models=models, posts=posts, grades=grades,
    )
    top_by_mass = uq.qrqc_top_defects_by_mass(
        target_date=target if (not start_d and not end_d) else None,
        start_d=start_d, end_d=end_d,
        brand=brand, models=models, posts=posts, grades=grades,
    )
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤ —Ç—Ä–µ–±—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç (7 –ø–æ–ª–µ–π)
    top_by_grades = _normalize_top_rows(top_by_grades)
    top_by_mass = _normalize_top_rows(top_by_mass)

    # --- DPU –ø–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–º ---
    dpu_resp_rows = uq.qrqc_dpu_by_responsible(
        target_date=target if (not start_d and not end_d) else None,
        start_d=start_d, end_d=end_d,
        brand=brand, models=models, posts=posts, grades=grades,
    )
    # –≤—Å–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ QRR
    try:
        all_resp_names = list(QRRResponsible.objects.order_by("name").values_list("name", flat=True))
    except Exception:
        all_resp_names = []
    # –≥—Ä–∞—Ñ–∏–∫ —Ç–æ–ª—å–∫–æ –ø–æ –∞–∫—Ç–∏–≤–Ω—ã–º (–µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ)
    chart_resp_active = _fmt_dpu_responsibles_for_chart(dpu_resp_rows)
    # –≥—Ä–∞—Ñ–∏–∫ –ø–æ –≤—Å–µ–º –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ = 0)
    chart_resp_all = _fmt_dpu_responsibles_for_chart(dpu_resp_rows, all_names=all_resp_names)

    # –∞–≥—Ä–µ–≥–∞—Ç ALL (–≤—Å–µ –¥–µ—Ñ–µ–∫—Ç—ã / –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ VIN –∑–∞ –ø–µ—Ä–∏–æ–¥)
    agg_all = next((r for r in dpu_resp_rows if (r.get("responsible") or "").upper() == "ALL"), None)
    dpu_all_value = float(agg_all.get("dpu", 0.0)) if agg_all else 0.0
    inspected_total = int(agg_all.get("inspected", 0) or 0) if agg_all else 0
    defects_weight_total = float(agg_all.get("defects_weight", 0.0) or 0.0) if agg_all else 0.0

    # ===== KTV (–û—Ç–ª–æ–∂–µ–Ω–Ω—ã–µ –¥–µ—Ñ–µ–∫—Ç—ã) ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —à–∞–±–ª–æ–Ω —Ç–æ–ª—å–∫–æ –≤–∏–¥–∏–º—ã–µ –∑–∞–ø–∏—Å–∏ =====
    # –ü—Ä–∞–≤–∏–ª–æ –≤–∏–¥–∏–º–æ—Å—Ç–∏: visible_from <= —Å–µ–≥–æ–¥–Ω—è. –ï—Å–ª–∏ –≤—ã–±—Ä–∞–Ω—ã –≥—Ä–µ–π–¥—ã, –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –Ω–∏–º.
    today_ktv = timezone.localdate()
    ktv_qs = KTVDefect.objects.filter(visible_from__lte=today_ktv)

    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä –ø–æ –≥—Ä–µ–π–¥–∞–º ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —ç—Ç–∏ –≥—Ä–µ–π–¥—ã (–∏ –ø—É—Å—Ç—ã–µ)
    if grades:
        ktv_qs = ktv_qs.filter(Q(grade__in=grades) | Q(grade__isnull=True) | Q(grade=""))

    ktv_by_grades_list = ktv_qs.filter(table_type="by_grades").order_by("-visible_from", "-created_at")
    ktv_by_mass_list   = ktv_qs.filter(table_type="by_mass").order_by("-visible_from", "-created_at")

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –¥–∏–∫—Ç–∞–º –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —Ä–µ–Ω–¥–µ—Ä–∞ –≤ —à–∞–±–ª–æ–Ω–µ
    ktv_by_grades_ctx = [_ktv_to_dict(o) for o in ktv_by_grades_list]
    ktv_by_mass_ctx   = [_ktv_to_dict(o) for o in ktv_by_mass_list]

    ctx = {
        "brand": brand,
        "target_date": target.isoformat(),
        "start": (start_d.isoformat() if start_d else ""),
        "end": (end_d.isoformat() if end_d else ""),
        "iso_year": (iso_y or ""),
        "iso_week": (iso_w or ""),
        "range": range_param or "",
        "agg": agg_param or "",
        "filters": {
            "models": models or [],
            "posts": posts or [],
            "grades": grades or [],
            "weekly_mode": weekly_mode,
        },

        # –≥—Ä–∞—Ñ–∏–∫–∏
        "charts": charts,

        # —Ç–∞–±–ª–∏—Ü—ã
        "table_top_by_grades": top_by_grades,
        "table_top_by_mass": top_by_mass,

        # KTV: –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±—Ä–µ–Ω–¥–æ–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        "ktv_by_grades": ktv_by_grades_ctx,
        "ktv_by_mass": ktv_by_mass_ctx,

        # –≥—Ä–∞—Ñ–∏–∫ DPU –ø–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–º
        "dpu_responsibles_active": chart_resp_active,
        "dpu_responsibles_all": chart_resp_all,
        "responsibles_active_count": chart_resp_active.get("meta", {}).get("active_count", 0),
        "responsibles_all_count": chart_resp_all.get("meta", {}).get("all_count", 0),
        # –∞–≥—Ä–µ–≥–∞—Ç ALL –∏ –∑–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å
        "dpu_all": dpu_all_value,
        "dpu_all_inspected": inspected_total,
        "dpu_all_defects_weight": defects_weight_total,

        # –ø–æ–¥—Å–∫–∞–∑–∫–∞ —Ñ—Ä–æ–Ω—Ç—É –ø–æ —Ç–∏–ø–∞–º —Ä—è–¥–æ–≤ –∏ –æ—Å—è–º
        "series_meta": {
            # —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –∫–æ–º–±–æ: –∫–æ–ª–æ–Ω–∫–∞ (unique_vins) + –ª–∏–Ω–∏–∏ (dpu/str)
            "dpu": {"type": "line", "yAxis": "left"},
            "str": {"type": "line", "yAxis": "right"},
            "unique_vins": {"type": "bar", "yAxis": "bar"},
            "defects": {"type": "bar", "yAxis": "bar"},
        },

        # –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è —à–∞–±–ª–æ–Ω–∞ (–º–æ–∂–µ—Ç–µ –ø–æ–º–µ–Ω—è—Ç—å –Ω–∞ —Å–≤–æ–∏)
        "titles": {
            "prev5": "–ü—Ä–æ—à–ª—ã–µ 5 –Ω–µ–¥–µ–ª—å",
            "current": "–¢–µ–∫—É—â–∞—è –Ω–µ–¥–µ–ª—è (–ø–æ –¥–Ω—è–º)",
            "by_posts": "–ü–æ –ø–æ—Å—Ç–∞–º (DPU / STR / –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ)",
            "by_grades": "–ü–æ –≥—Ä–µ–π–¥–∞–º",
            "by_models": "–ü–æ –º–æ–¥–µ–ª—è–º (DPU / STR / –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ)",
            "table_top_by_grades": "–¢–û–ü –¥–µ—Ñ–µ–∫—Ç–æ–≤ –ø–æ –≥—Ä–µ–π–¥–∞–º",
            "table_top_by_mass": "–¢–û–ü –¥–µ—Ñ–µ–∫—Ç–æ–≤ –ø–æ –º–∞—Å—Å–æ–≤–æ—Å—Ç–∏",
        },

        # –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—è totals/avg –Ω–∞ —à–∞–±–ª–æ–Ω–µ
        "weekly_mode_default": weekly_mode,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    }

    return render(request, "users/qrqc/qrqc_brand_dashboard.html", ctx)


@login_required
@permission_required('users.access_to_the_qrqc_report_vqa', raise_exception=True)
def defect_details_view(request):
    """
    –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–µ—Ñ–µ–∫—Ç–æ–≤ VIN.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–µ—Ñ–µ–∫—Ç–æ–≤.
    Query params:
      - vin=VIN –∏–ª–∏ VIN1,VIN2 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ; –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω, VIN –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è –∏–∑ defect_id)
      - defect_id=ID  (–º–æ–∂–Ω–æ –ø–µ—Ä–µ—á–∏—Å–ª–∏—Ç—å —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –∏–ª–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑)
      - defect_ids=ID1,ID2,... (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ)
    –®–∞–±–ª–æ–Ω –æ–∂–∏–¥–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç {"items": list[dict]} –≤ —Ñ–æ—Ä–º–∞—Ç–µ –∫–∞—Ä—Ç–æ—á–µ–∫ QRR.
    """
    from collections import defaultdict
    import re
    from django.http import HttpResponseBadRequest, HttpResponseNotFound
    from django.utils.dateparse import parse_datetime
    from django.utils import timezone

    # --- VIN param: –¥–æ–ø—É—Å–∫–∞–µ–º CSV, –ø—Ä–æ–±–µ–ª—ã
    raw_vin = (request.GET.get("vin") or "").strip()
    vin_list = [v.strip() for v in raw_vin.split(",") if v.strip()] if raw_vin else []

    # --- –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–µ—Ä–µ–¥–∞—á–∏ id-—à–µ–∫
    ids: list[str] = []
    # 1) –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è defect_id
    ids += [x.strip() for x in request.GET.getlist("defect_id") if (x or "").strip()]
    # 2) –æ–¥–∏–Ω–æ—á–Ω—ã–π defect_id, –Ω–æ –≤ –Ω—ë–º –º–æ–∂–µ—Ç –±—ã—Ç—å CSV
    single = (request.GET.get("defect_id") or "").strip()
    if single and "," in single:
        ids += [x.strip() for x in single.split(",") if x.strip()]
    # 3) –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä defect_ids=csv
    csv_ids = (request.GET.get("defect_ids") or "").strip()
    if csv_ids:
        ids += [x.strip() for x in csv_ids.split(",") if x.strip()]

    # –£–Ω–∏–∫–∞–ª–∏–∑—É–µ–º, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –ø–æ—Ä—è–¥–æ–∫
    seen = set()
    ids = [x for x in ids if not (x in seen or seen.add(x))]

    if not ids:
        return HttpResponseBadRequest("defect_id(—ã) –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã")

    # --- –†–∞–∑–±–∏–≤–∫–∞ id –ø–æ VIN ---
    def _vin_from_defect_id(did: str) -> str | None:
        # –æ–∂–∏–¥–∞–µ–º —à–∞–±–ª–æ–Ω: VIN-—Ü–µ—Ö-—Å–±–æ—Ä–∫–∏-...
        m = re.match(r"^([A-Z0-9]+)-—Ü–µ—Ö-—Å–±–æ—Ä–∫–∏-", str(did), re.IGNORECASE)
        return m.group(1) if m else None

    vin_to_ids: dict[str, list[str]] = defaultdict(list)

    if len(vin_list) == 1:
        # –ï—Å–ª–∏ –∑–∞–¥–∞–Ω –æ–¥–∏–Ω VIN ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –Ω–æ –µ—Å–ª–∏ –∏–∑ id –∏–∑–≤–ª–µ–∫–ª–∏ –¥—Ä—É–≥–æ–π VIN, —Å–≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∏–∑–≤–ª–µ—á—ë–Ω–Ω–æ–º—É
        single_vin = vin_list[0]
        for did in ids:
            v = _vin_from_defect_id(did) or single_vin
            vin_to_ids[v].append(did)
    else:
        # VIN –Ω–µ –∑–∞–¥–∞–Ω –∏–ª–∏ –∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–æ ‚Äî –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–∑ –∫–∞–∂–¥–æ–≥–æ id
        for did in ids:
            v = _vin_from_defect_id(did)
            if v:
                vin_to_ids[v].append(did)
        # –µ—Å–ª–∏ –Ω–∏ —É –æ–¥–Ω–æ–≥–æ id VIN –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω, –∞ vin_list –∑–∞–¥–∞–Ω (–º–Ω–æ–≥–æ VIN) ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏–º –ø–µ—Ä–≤—ã–π VIN
        if not vin_to_ids and vin_list:
            for did in ids:
                vin_to_ids[vin_list[0]].append(did)

    if not vin_to_ids:
        return HttpResponseBadRequest("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å VIN –ø–æ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–º defect_id")

    # --- –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º VIN
    details_list: list[dict] = []
    try:
        if hasattr(uq, "get_defect_details_many"):
            for v, id_list in vin_to_ids.items():
                chunk = uq.get_defect_details_many(v, id_list) or []
                if chunk:
                    details_list.extend(chunk)
        else:
            # –§–æ–ª–ª–±—ç–∫: –ø–æ –æ–¥–Ω–æ–º—É id
            for v, id_list in vin_to_ids.items():
                for did in id_list:
                    item = uq.get_defect_details(v, did)
                    if item:
                        details_list.append(item)
    except Exception:
        details_list = []

    if not details_list:
        return HttpResponseNotFound("–î–µ—Ñ–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –ø–æ VIN, –∑–∞—Ç–µ–º –ø–æ –¥–∞—Ç–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    def _key(d: dict):
        vinv = d.get("vin") or ""
        dt = d.get("date")
        if not dt:
            raw = d.get("date_added") or d.get("date_str") or ""
            dt = parse_datetime(raw) if raw else None
        if dt is None:
            # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –≤–æ–∑–º–æ–∂–Ω–∞—è aware-–¥–∞—Ç–∞, —á—Ç–æ–±—ã —Ç–∞–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã —à–ª–∏ –ø–µ—Ä–≤—ã–º–∏
            try:
                return (vinv, timezone.make_aware(timezone.datetime.min))
            except Exception:
                return (vinv, timezone.now())
        return (vinv, timezone.localtime(dt) if timezone.is_aware(dt) else timezone.make_aware(dt, timezone.get_current_timezone()))

    details_list.sort(key=_key)

    # –ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ —è–≤–Ω–æ –±—ã–ª –æ–¥–∏–Ω VIN ‚Äî –ø—Ä–æ–±—Ä–æ—Å–∏–º –µ–≥–æ, –∏–Ω–∞—á–µ –æ—Å—Ç–∞–≤–∏–º –ø—É—Å—Ç—ã–º (—à–∞–±–ª–æ–Ω—É –æ–Ω –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω)
    vin_ctx = vin_list[0] if len(vin_list) == 1 else ""

    return render(request, "users/qrqc/defect_details.html", {"vin": vin_ctx, "items": details_list})


def _ktv_to_dict(o: KTVDefect):
    return {
        "id": o.id,
        "table_type": o.table_type,         # 'by_grades' | 'by_mass'
        "detail": o.detail,
        "defect": o.defect,
        "grade": o.grade,
        "count": o.count,
        "visible_from": o.visible_from.isoformat(),
        "created_at": o.created_at.isoformat(),
        "created_by": (o.created_by.get_full_name() or o.created_by.username) if o.created_by else None,
        "comment": o.comment or "",
    }


@login_required
def ktvdefect_list(request):
    """
    GET /api/ktvdefect/list
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤–∏–¥–∏–º—ã–µ –∑–∞–ø–∏—Å–∏ (visible_from <= —Å–µ–≥–æ–¥–Ω—è), —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–æ –ø–æ —Ç–∏–ø—É.
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):
      ?from=YYYY-MM-DD  ‚Äî –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –≤–∏–¥–∏–º–æ—Å—Ç–∏
      ?limit=10         ‚Äî –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ
    """
    if request.method != "GET":
        return HttpResponseNotAllowed(["GET"])

    today = timezone.localdate()
    from_date = request.GET.get("from")
    try:
        from_date = parse_date(from_date) if from_date else None
    except Exception:
        from_date = None

    base_qs = KTVDefect.objects.filter(visible_from__lte=today)
    if from_date:
        base_qs = base_qs.filter(visible_from__gte=from_date)

    limit = request.GET.get("limit")
    try:
        limit = int(limit) if limit else None
    except Exception:
        limit = None

    by_grades = base_qs.filter(table_type="by_grades").order_by("-visible_from", "-created_at")
    by_mass   = base_qs.filter(table_type="by_mass").order_by("-visible_from", "-created_at")

    if limit:
        by_grades = by_grades[:limit]
        by_mass   = by_mass[:limit]

    data = {
        "by_grades": [_ktv_to_dict(o) for o in by_grades],
        "by_mass":   [_ktv_to_dict(o) for o in by_mass],
    }
    return JsonResponse(data, json_dumps_params={"ensure_ascii": False})


@login_required
@require_POST
def ktvdefect_upsert(request):
    """
    POST /api/ktvdefect/upsert  (JSON)
    –¢–µ–ª–æ:
      {
        "table_type": "by_grades" | "by_mass",
        "detail": "string",
        "defect": "string",
        "grade": "string|null",
        "count": 123,                # –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0)
        "visible_from": "YYYY-MM-DD",
        "comment": "—Å—Ç—Ä–æ–∫–∞ (–æ–ø—Ü.)"
      }
    –õ–æ–≥–∏–∫–∞:
      - –∫–ª—é—á —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏: (table_type, detail, defect, grade)
      - –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å –µ—Å—Ç—å ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º count, visible_from –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω—è–µ–º comment.
      - –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞—ë–º.
    """
    import json

    try:
        payload = json.loads(request.body.decode("utf-8"))
    except Exception:
        return HttpResponseBadRequest("Invalid JSON")

    table_type = payload.get("table_type")
    detail     = (payload.get("detail") or "").strip()
    defect     = (payload.get("defect") or "").strip()
    grade      = (payload.get("grade") or None)
    count      = payload.get("count", 0)
    visible_s  = payload.get("visible_from")
    comment    = (payload.get("comment") or "").strip()

    if table_type not in ("by_grades", "by_mass"):
        return HttpResponseBadRequest("table_type must be 'by_grades' or 'by_mass'")
    if not detail or not defect:
        return HttpResponseBadRequest("detail and defect are required")

    vis_date = parse_date(visible_s) if visible_s else None
    if not vis_date:
        vis_date = timezone.localdate()  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —Å–µ–≥–æ–¥–Ω—è

    obj, created = KTVDefect.objects.get_or_create(
        table_type=table_type,
        detail=detail,
        defect=defect,
        grade=grade if grade else None,
        defaults={
            "count": int(count) if isinstance(count, int) else 0,
            "visible_from": vis_date,
            "comment": comment,
            "created_by": request.user,
        }
    )

    # –ï—Å–ª–∏ –Ω–µ –Ω–æ–≤–∞—è ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º
    if not created:
        # –ø–æ–ª–∏—Ç–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º count –∏ –≤–∏–¥–∏–º–æ—Å—Ç—å; –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–æ–ø–∏—Å—ã–≤–∞–µ–º —Å –ø–æ–¥–ø–∏—Å—å—é –∞–≤—Ç–æ—Ä–∞
        obj.count = int(count) if isinstance(count, int) else obj.count
        obj.visible_from = vis_date
        if comment:
            stamp = timezone.now().strftime("%Y-%m-%d %H:%M")
            who = (request.user.get_full_name() or request.user.username)
            prev = (obj.comment or "").strip()
            addition = f"[{stamp} ¬∑ {who}] {comment}"
            obj.comment = (prev + "\n" + addition).strip() if prev else addition
        if not obj.created_by:
            obj.created_by = request.user
        obj.save(update_fields=["count", "visible_from", "comment", "created_by"])

    return JsonResponse({"ok": True, "created": created, "item": _ktv_to_dict(obj)}, json_dumps_params={"ensure_ascii": False})


@login_required
@require_http_methods(["POST", "DELETE"])
def ktvdefect_delete(request, pk: int | None = None):
    """
    –£–¥–∞–ª—è–µ—Ç –∑–∞–ø–∏—Å—å KTV.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–∑–æ–≤–∞:
      - POST /api/ktvdefect/delete/           —Å —Ç–µ–ª–æ–º JSON {"id": 123} –∏–ª–∏ —Ñ–æ—Ä–º–æ–π id=123
      - DELETE /api/ktvdefect/delete/?id=123
      - DELETE /api/ktvdefect/<id>/delete/  (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –º–∞—Ä—à—Ä—É—Ç —Å pk)
    –¢—Ä–µ–±—É–µ—Ç –ø—Ä–∞–≤–∞ staff.
    """
    # –†–∞–∑—Ä–µ—à–∞–µ–º —É–¥–∞–ª–µ–Ω–∏–µ —Ç–µ–º, —É –∫–æ–≥–æ –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø:
    # - superuser / staff
    # - —è–≤–Ω–æ–µ –ø—Ä–∞–≤–æ users.delete_ktvdefect
    # - —Ä–æ–ª–∏ –∏–∑ –Ω–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞: head_area, master
    user_role = getattr(request.user, "role", None)
    if not (
        request.user.is_superuser
        or request.user.is_staff
        or request.user.has_perm("users.delete_ktvdefect")
        or user_role in ("head_area", "master")
    ):
        return JsonResponse({"ok": False, "error": "forbidden"}, status=403)

    # –ò–∑–≤–ª–µ—á—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–∑ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç
    item_id = pk
    if item_id is None:
        # –ü—Ä–æ–±—É–µ–º JSON —Ç–µ–ª–æ
        try:
            import json
            if request.body:
                data = json.loads(request.body.decode("utf-8"))
                item_id = data.get("id") or data.get("pk")
        except Exception:
            item_id = None

    if item_id is None:
        # –ü—Ä–æ–±—É–µ–º form-data
        item_id = request.POST.get("id") or request.POST.get("pk")

    if item_id is None:
        # –ü—Ä–æ–±—É–µ–º querystring (–¥–ª—è DELETE)
        item_id = request.GET.get("id") or request.GET.get("pk")

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ int
    try:
        item_id = int(item_id) if item_id is not None else None
    except (TypeError, ValueError):
        item_id = None

    if item_id is None:
        return JsonResponse({"ok": False, "error": "id required"}, status=400)

    # –£–¥–∞–ª–µ–Ω–∏–µ
    try:
        obj = KTVDefect.objects.get(pk=item_id)
    except KTVDefect.DoesNotExist:
        return JsonResponse({"ok": False, "error": "not found"}, status=404)

    obj.delete()
    return JsonResponse({"ok": True, "deleted_id": item_id})







# @login_required
# @role_required(["master", "head_area"])
# def export_all_defects_excel(request):
#     start_date_str = request.GET.get("start_date")
#     end_date_str = request.GET.get("end_date")
#     brand_filter = request.GET.get("download_brand")
#
#     try:
#         if start_date_str:
#             start_date = make_aware(datetime.combine(datetime.strptime(start_date_str, "%Y-%m-%d").date(), time.min))
#         else:
#             start_date = None
#
#         if end_date_str:
#             end_date = make_aware(datetime.combine(datetime.strptime(end_date_str, "%Y-%m-%d").date(), time.max))
#         else:
#             end_date = None
#     except ValueError:
#         return HttpResponse("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã", status=400)
#
#     vin_histories = VINHistory.objects.all()
#     data_rows = []
#     max_photos = 0
#
#     for history in vin_histories:
#         vin = getattr(history, 'vin', '')
#         trace = TraceData.objects.filter(vin_rk=vin).first()
#         if not trace:
#             continue
#         if brand_filter and getattr(trace, 'brand', '') != brand_filter:
#             continue
#
#         brand = getattr(trace, 'brand', '')
#         model = getattr(trace, 'model', '')
#         config_code = getattr(trace, 'config_code', '')
#
#         history_data = getattr(history, 'history', {})
#
#         for zone_name, posts in history_data.items():
#             for post_name, entries in posts.items():
#                 for entry in entries:
#                     try:
#                         date_raw = entry.get("date_added")
#                         if not date_raw:
#                             continue
#                         date = parse_datetime(date_raw)
#                         if start_date and date < start_date:
#                             continue
#                         if end_date and date > end_date:
#                             continue
#
#                         controller = entry.get("controller", "") or entry.get("extra_data", {}).get("controller", "")
#                         line = entry.get("line", "")
#                         duration = entry.get("inspection_duration_seconds", "")
#
#                         if "defects" in entry and isinstance(entry["defects"], list) and entry["defects"]:
#                             for defect in entry["defects"]:
#                                 photos = defect.get("photos", [])
#                                 max_photos = max(max_photos, len(photos))
#                                 data_rows.append({
#                                     "zone": zone_name or "",
#                                     "post": post_name or "",
#                                     "vin": vin or "",
#                                     "brand": brand or "",
#                                     "model": model or "",
#                                     "config_code": config_code or "",
#                                     "date": date or "",
#                                     "line": line or "",
#                                     "unit": defect.get("unit", ""),
#                                     "defect": defect.get("name", ""),
#                                     "comment": defect.get("comment", ""),
#                                     "quantity": defect.get("quantity", ""),
#                                     "grade": defect.get("grade", ""),
#                                     "responsible": defect.get("responsible", ""),
#                                     "controller": controller or "",
#                                     "duration": duration or "",
#                                     "photos": photos,
#                                 })
#                         else:
#                             photos = entry.get("defect_photos", [])
#                             max_photos = max(max_photos, len(photos))
#                             data_rows.append({
#                                 "zone": zone_name or "",
#                                 "post": post_name or "",
#                                 "vin": vin or "",
#                                 "brand": brand or "",
#                                 "model": model or "",
#                                 "config_code": config_code or "",
#                                 "date": date or "",
#                                 "line": line or "",
#                                 "unit": "",
#                                 "defect": entry.get("defect_description", ""),
#                                 "comment": "",
#                                 "quantity": "",
#                                 "grade": "",
#                                 "responsible": "",
#                                 "controller": controller or "",
#                                 "duration": duration or "",
#                                 "photos": photos,
#                             })
#                     except Exception:
#                         continue
#
#     wb = Workbook()
#     ws = wb.active
#     ws.title = "–í—Å–µ –¥–µ—Ñ–µ–∫—Ç—ã"
#
#     headers = [
#         "–£—á–∞—Å—Ç–æ–∫", "–ü–æ—Å—Ç", "VIN", "–ë—Ä–µ–Ω–¥", "–ú–æ–¥–µ–ª—å", "–ö–æ–¥ –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏", "–î–∞—Ç–∞", "–õ–∏–Ω–∏—è",
#         "–î–µ—Ç–∞–ª—å", "–î–µ—Ñ–µ–∫—Ç", "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–ì—Ä–µ–π–¥", "–ö—Ç–æ –≤–∏–Ω–æ–≤–∞—Ç",
#         "–ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä", "–í—Ä–µ–º—è –æ—Å–º–æ—Ç—Ä–∞ (—Å–µ–∫)"
#     ] + [f"–§–æ—Ç–æ {i+1}" for i in range(max_photos)]
#
#     ws.append(headers)
#
#     for row in data_rows:
#         try:
#             excel_row = [
#                 row.get("zone", ""),
#                 row.get("post", ""),
#                 row.get("vin", ""),
#                 row.get("brand", ""),
#                 row.get("model", ""),
#                 row.get("config_code", ""),
#                 row.get("date", "").strftime("%d.%m.%Y %H:%M") if row.get("date") else "",
#                 row.get("line", ""),
#                 row.get("unit", ""),
#                 row.get("defect", ""),
#                 row.get("comment", ""),
#                 row.get("quantity", ""),
#                 row.get("grade", ""),
#                 row.get("responsible", ""),
#                 row.get("controller", ""),
#                 row.get("duration", ""),
#             ]
#             excel_row += ["" for _ in range(max_photos)]
#             ws.append(excel_row)
#
#             row_idx = ws.max_row
#             for i, img_path in enumerate(row.get("photos", [])):
#                 insert_single_image(ws, row_idx, 17 + i, img_path)
#             ws.row_dimensions[row_idx].height = 75
#         except Exception:
#             continue
#
#     for col in ws.columns:
#         for cell in col:
#             cell.alignment = Alignment(wrap_text=True, vertical='top')
#
#     response = HttpResponse(content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
#     filename = f"defects_summary_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx"
#     response['Content-Disposition'] = f'attachment; filename="{filename}"'
#     wb.save(response)
#     return response






# @login_required
# @role_required(["head_area"])
# def assembly_general_report_export(request):
#     start_date = request.GET.get("start_date")
#     end_date = request.GET.get("end_date")
#     brands = request.GET.getlist("brand")
#     models = request.GET.getlist("model")
#
#     # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ —Ä–∞—Å—á—ë—Ç, —á—Ç–æ –≤ assembly_general_report (–º–æ–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é)
#     report_data = generate_report_data(start_date, end_date, brands, models)
#
#     # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel
#     file_path = generate_excel_from_report(report_data, start_date, end_date, brands)
#
#     # –û—Ç–¥–∞–µ–º —Ñ–∞–π–ª
#     with open(file_path, 'rb') as f:
#         response = HttpResponse(f.read(),
#                                 content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
#         response['Content-Disposition'] = f'attachment; filename="report_{start_date}_{end_date}.xlsx"'
#         return response

@login_required
@permission_required('users.access_to_indicators', raise_exception=True)
def assembly_counter_dashboard(request):
    """
    –°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å —Ç—Ä–µ–º—è –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Å–ø–∏—Å–∫–∞–º–∏ VIN:
      1) –ü–æ—Å—Ç-—Å—á—ë—Ç—á–∏–∫ (AssemblyPassLog)
      2) –í—Å–µ –ø–æ—Å—Ç—ã –æ—Ç –ü–µ—Ä–≤–æ–π –∏–Ω—Å–ø–µ–∫—Ü–∏–∏ –¥–æ –§–∏–Ω–∞–ª–∞ (—Å–º. POST_AREA_MAPPING)
      3) –ü–æ—Å—Ç ¬´–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è¬ª
    –§–∏–ª—å—Ç—Ä—ã –±–µ—Ä—ë–º –∏–∑ TraceData: brand (–º—É–ª—å—Ç–∏, —á–µ—Ä–µ–∑ –º–∞–ø–ø–∏–Ω–≥), model (–º—É–ª—å—Ç–∏), start_date, end_date (YYYY-MM-DD)
    """
    # --- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤ (–∫–∞–∫ –≤ assembly_general_report) ---
    brands_selected = request.GET.getlist("brand")  # ['gwm','chery',...]
    models_selected = request.GET.getlist("model")

    BRAND_MAP = {
        "gwm": ["haval", "tank"],
        "chery": ["chery"],
        "changan": ["changan"],
    }
    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤ –ë–î
    brands_selected = [b.strip().lower() for b in brands_selected if b.strip()]
    mapped_brands = list(chain.from_iterable(BRAND_MAP.get(b, [b]) for b in brands_selected))

    # –î–∞—Ç—ã: –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã ‚Äî ¬´—Å–µ–≥–æ–¥–Ω—è..—Å–µ–≥–æ–¥–Ω—è¬ª
    start_date = (request.GET.get("start_date") or "").strip() or None
    end_date = (request.GET.get("end_date") or "").strip() or None
    if not start_date and not end_date:
        today = timezone.localdate()
        start_date = today.isoformat()
        end_date = today.isoformat()

    # --- –ë–∞–∑–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Ç—Ä–µ–π—Å–∏–Ω–≥—É ---
    trace_qs = TraceData.objects.all()
    if mapped_brands:
        trace_qs = trace_qs.filter(brand__in=mapped_brands)
    if models_selected:
        trace_qs = trace_qs.filter(model__in=models_selected)
    # VIN'—ã, —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
    allowed_vins = set(trace_qs.values_list("vin_rk", flat=True))

    # –û–ø—Ü–∏–∏ –¥–ª—è —á–µ–∫–±–æ–∫—Å–æ–≤:
    #   –±—Ä–µ–Ω–¥—ã –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è (–∫–ª—é—á–∏ BRAND_MAP),
    #   –º–æ–¥–µ–ª–∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –∏–∑ —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç—Ä–µ–π—Å–∏–Ω–≥–∞
    brands_options = ["gwm", "chery", "changan"]
    models_options = list(
        trace_qs.exclude(model__isnull=True)
                .exclude(model="")
                .values_list("model", flat=True)
                .distinct()
                .order_by("model")
    )

    # --- –ü–æ–¥—Å—á—ë—Ç—ã –ø–æ –ø–µ—Ä–∏–æ–¥–∞–º (–≤—Å–µ–≥–¥–∞ —Å—á–∏—Ç–∞–µ–º –ø–æ –¥–∞—Ç–µ), –∑–∞—Ç–µ–º –ø–µ—Ä–µ—Å–µ–∫–∞–µ–º —Å allowed_vins ---
    res_counter = counter_vins(
        brand=None, model=None,
        start_date=start_date, end_date=end_date,
        distinct=True,
    )
    res_vh_all = counter_vins_from_vehicle_history(
        posts=list(POST_AREA_MAPPING.keys()),
        brand=None, model=None,
        start_date=start_date, end_date=end_date,
    )
    res_docs = counter_vins_documentation(
        brand=None, model=None,
        start_date=start_date, end_date=end_date,
    )

    def _apply_trace_filter(payload: dict) -> dict:
        vins = payload.get("vins", []) or []
        if allowed_vins:
            vins = [v for v in vins if v in allowed_vins]
        return {"count": len(vins), "vins": vins}

    # –ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ç—Ä–µ–π—Å–∏–Ω–≥—É ‚Äî –ø—Ä–∏–º–µ–Ω–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ.
    if brands_selected or models_selected:
        res_counter = _apply_trace_filter(res_counter)
        res_vh_all = _apply_trace_filter(res_vh_all)
        res_docs = _apply_trace_filter(res_docs)

    ctx = {
        "filters": {
            "brand": "", "model": "",
            "start_date": start_date or "",
            "end_date": end_date or "",
        },
        "counter": {"count": res_counter.get("count", 0), "vins": res_counter.get("vins", [])},
        "vehicle_history_all": {"count": res_vh_all.get("count", 0), "vins": res_vh_all.get("vins", [])},
        "documentation": {"count": res_docs.get("count", 0), "vins": res_docs.get("vins", [])},
        "brands_options": brands_options,
        "models_options": models_options,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    }
    return render(request, "users/counter/counter_dashboard.html", ctx)


from django.http import JsonResponse

from django.http import JsonResponse
from django.utils import timezone
from django.views.decorators.cache import never_cache
from django.contrib.auth.decorators import login_required
from itertools import chain

# –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π —Å–≤–æ–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –º—ç–ø–ø–∏–Ω–≥–∏:
# from supplies.utils_qrqc import counter_vins, counter_vins_from_vehicle_history, counter_vins_documentation
# from supplies.constants import POST_AREA_MAPPING
# from users.decorators import role_required
from datetime import date

def _parse_date_or_none(s: str):
    if not s:
        return None
    try:
        return date.fromisoformat(s)
    except Exception:
        return None

def _ensure_shape(payload):
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ª—é–±—ã–µ –æ—Ç–≤–µ—Ç—ã —Ö–µ–ª–ø–µ—Ä–æ–≤ –∫ —Ñ–æ—Ä–º–∞—Ç—É:
    {"count": int, "vins": [..]}.
    """
    if payload is None:
        return {"count": 0, "vins": []}

    if isinstance(payload, dict):
        vins = list(payload.get("vins", []) or [])
        cnt = payload.get("count")
        if cnt is None:
            cnt = len(vins)
        return {"count": int(cnt), "vins": vins}

    # –ï—Å–ª–∏ –≤–¥—Ä—É–≥ –ø—Ä–∏—à–ª–æ —á–∏—Å–ª–æ/–∏—Ç–µ—Ä–∏—Ä—É–µ–º–æ–µ
    try:
        # iterable VINs
        vins = list(payload)
        return {"count": len(vins), "vins": vins}
    except TypeError:
        # scalar count
        try:
            return {"count": int(payload), "vins": []}
        except Exception:
            return {"count": 0, "vins": []}

@never_cache  # <- –≤–∞–∂–Ω–æ: –æ—Ç–∫–ª—é—á–∞–µ–º –∫–µ—à –±—Ä–∞—É–∑–µ—Ä–∞/–ø—Ä–æ–∫—Å–∏/NGINX
@login_required
@permission_required('users.access_to_indicators', raise_exception=True)
def assembly_counter_api(request):
    """
    JSON API –¥–ª—è —Ç—Ä—ë—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö:
      - "counter" (–≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Å–±–æ—Ä–∫–∏)
      - "vehicle_history_all" (–Ω–∞ –ª–∏–Ω–∏–∏ —Ç–µ—Å—Ç–æ–≤)
      - "documentation" (–ø–µ—Ä–µ–¥–∞–Ω–æ –≤ –°–ì–ü)

    –§–∏–ª—å—Ç—Ä—ã (GET/POST):
      - brand: gwm / chery / changan (–º—É–ª—å—Ç–∏)
      - model: —Ä–µ–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ TraceData (–º—É–ª—å—Ç–∏)
      - start_date, end_date: YYYY-MM-DD; –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–æ–¥–Ω—è.
    """
    data = request.POST if request.method == "POST" else request.GET

    BRAND_MAP = {
        "gwm": ["haval", "tank"],
        "chery": ["chery"],
        "changan": ["changan"],
    }

    brands_selected = [b.strip().lower() for b in data.getlist("brand") if b.strip()]
    models_selected = [m.strip() for m in data.getlist("model") if m.strip()]
    mapped_brands = list(chain.from_iterable(BRAND_MAP.get(b, [b]) for b in brands_selected))

    # –î–∞—Ç—ã
    start_date_raw = (data.get("start_date") or "").strip()
    end_date_raw = (data.get("end_date") or "").strip()

    if not start_date_raw and not end_date_raw:
        today = timezone.localdate()
        start_date_dt = end_date_dt = today
    else:
        start_date_dt = _parse_date_or_none(start_date_raw) or timezone.localdate()
        end_date_dt = _parse_date_or_none(end_date_raw) or start_date_dt

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–∞–º ISO –¥–ª—è –≤–∞—à–∏—Ö —Ö–µ–ª–ø–µ—Ä–æ–≤, –µ—Å–ª–∏ –∏–º —Ç–∞–∫ —É–¥–æ–±–Ω–µ–µ
    start_date = start_date_dt.isoformat()
    end_date = end_date_dt.isoformat()

    # ----- TraceData -> allowed VINs -----
    trace_qs = TraceData.objects.all()
    if mapped_brands:
        trace_qs = trace_qs.filter(brand__in=mapped_brands)
    if models_selected:
        trace_qs = trace_qs.filter(model__in=models_selected)
    allowed_vins = set(trace_qs.values_list("vin_rk", flat=True))

    # ----- –ë–∞–∑–æ–≤—ã–µ —Ä–∞—Å—á—ë—Ç—ã –±–µ–∑ —É—á—ë—Ç–∞ Trace-—Ñ–∏–ª—å—Ç—Ä–∞ -----
    res_counter = _ensure_shape(
        counter_vins(
            brand=None, model=None,
            start_date=start_date, end_date=end_date,
            distinct=True
        )
    )

    res_vh_all = _ensure_shape(
        counter_vins_from_vehicle_history(
            posts=list(POST_AREA_MAPPING.keys()),
            brand=None, model=None,
            start_date=start_date, end_date=end_date
        )
    )

    res_docs = _ensure_shape(
        counter_vins_documentation(
            brand=None, model=None,
            start_date=start_date, end_date=end_date
        )
    )

    # ----- –ü—Ä–∏–º–µ–Ω—è–µ–º Trace-—Ñ–∏–ª—å—Ç—Ä, –µ—Å–ª–∏ –æ–Ω –∑–∞–¥–∞–Ω -----
    def _apply_trace_filter(payload):
        if not (brands_selected or models_selected):
            return payload  # —Ñ–∏–ª—å—Ç—Ä–æ–≤ –Ω–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not allowed_vins:
            return {"count": 0, "vins": []}
        vins = [v for v in payload.get("vins", []) if v in allowed_vins]
        return {"count": len(vins), "vins": vins}

    res_counter = _apply_trace_filter(res_counter)
    res_vh_all = _apply_trace_filter(res_vh_all)
    res_docs = _apply_trace_filter(res_docs)

    # ----- –û—Ç–≤–µ—Ç -----
    resp = JsonResponse(
        {
            "filters": {
                "brands": brands_selected,
                "models": models_selected,
                "start_date": start_date,
                "end_date": end_date,
            },
            "counter": res_counter,
            "vehicle_history_all": res_vh_all,
            "documentation": res_docs,
        },
        json_dumps_params={"ensure_ascii": False}
    )

    # –î–æ–ø. –∑–∞—â–∏—Ç–∞ –æ—Ç –∫–µ—à–∞ (–¥–µ–∫–æ—Ä–∞—Ç–æ—Ä —É–∂–µ –¥–µ–ª–∞–µ—Ç no-cache, –Ω–æ —É—Å–∏–ª–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏)
    resp["Cache-Control"] = "no-store, no-cache, must-revalidate, max-age=0"
    resp["Pragma"] = "no-cache"
    resp["Expires"] = "0"
    return resp







from itertools import chain
from django.views.decorators.http import require_GET
from django.http import JsonResponse, HttpResponse
from django.utils.dateparse import parse_date, parse_datetime
from openpyxl import Workbook
from openpyxl.styles import Alignment

# MES dashboard template views and helpers
from django.urls import reverse

# –Ω–∞—à–∏ MES-–∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä—ã
from assembly.services.utils_line_indicators import (
    get_trim_mes,
    get_bqa_mes,
    get_qa_mes,
    get_ves_mes,
    get_uud_mes,
)

# ==== MES: shared filters/parser for line counters ====
from django.utils import timezone as _tz
from datetime import datetime as _dt, time as _t


def _parse_mes_filters(request, *, allow_line: bool = True) -> dict:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–ª—è MES-–∞–ø–∏—à–µ–∫.
    - –î–∞—Ç—ã: start_date/end_date –ø—Ä–∏–Ω–∏–º–∞—é—Ç –∫–∞–∫ YYYY-MM-DD, —Ç–∞–∫ –∏ ISO datetime (YYYY-MM-DDTHH:MM).
      –ï—Å–ª–∏ –æ–±–µ –ø—É—Å—Ç—ã–µ ‚Äî –±–µ—Ä—ë–º ¬´—Å–µ–≥–æ–¥–Ω—è¬ª.
    - –§–∏–ª—å—Ç—Ä—ã: brand (multi), model (multi), vin (—Ç–æ—á–Ω—ã–π), line (gwm|chery|changan).
    - –ü–∞–≥–∏–Ω–∞—Ü–∏—è: page, per_page (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 2000).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å:
      start/end (aware datetimes), start_date/end_date (iso-—Å—Ç—Ä–æ–∫–∏), brands, models, vin, line, page, per_page.
    """
    data = request.GET if request.method == "GET" else request.POST

    # --- —Å—Ç—Ä–æ–∫–∏ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ ---
    start_s = (data.get("start_date") or "").strip()
    end_s   = (data.get("end_date")   or "").strip()

    # --- —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∫–∞–∫ datetime ---
    start_dt = parse_datetime(start_s) if start_s else None
    end_dt   = parse_datetime(end_s)   if end_s   else None

    # --- –µ—Å–ª–∏ –Ω–µ datetime, –ø—Ä–æ–±—É–µ–º –∫–∞–∫ date ---
    start_d = None
    end_d   = None
    if not start_dt and start_s:
        try:
            start_d = parse_date(start_s.split("T")[0])
        except Exception:
            pass
    if not end_dt and end_s:
        try:
            end_d = parse_date(end_s.split("T")[0])
        except Exception:
            pass

    # --- –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ, –±–µ—Ä—ë–º —Å–µ–≥–æ–¥–Ω—è ---
    if not start_dt and not end_dt and not start_d and not end_d:
        today = _tz.localdate()
        start = _tz.make_aware(_dt.combine(today, _t.min))
        end   = _tz.make_aware(_dt.combine(today, _t.max))
        start_out = today.isoformat()
        end_out   = today.isoformat()
    else:
        # —Å—Ç—Ä–æ–∏–º start
        if start_dt:
            start = _tz.make_aware(start_dt) if not _tz.is_aware(start_dt) else start_dt
            start_out = start.isoformat()
        elif start_d:
            start = _tz.make_aware(_dt.combine(start_d, _t.min))
            start_out = start_d.isoformat()
        else:
            start = None
            start_out = ""

        # —Å—Ç—Ä–æ–∏–º end
        if end_dt:
            end = _tz.make_aware(end_dt) if not _tz.is_aware(end_dt) else end_dt
            end_out = end.isoformat()
        elif end_d:
            end = _tz.make_aware(_dt.combine(end_d, _t.max))
            end_out = end_d.isoformat()
        else:
            end = None
            end_out = ""

    # --- —Ñ–∏–ª—å—Ç—Ä—ã ---
    brands = [b.strip().lower() for b in data.getlist("brand") if b.strip()]
    models = [m.strip() for m in data.getlist("model") if m.strip()]
    vin = (data.get("vin") or "").strip().upper() or None
    line = (data.get("line") or "").strip().lower() if allow_line else None
    if line and line not in ("gwm", "chery", "changan"):
        line = None

    # --- –ø–∞–≥–∏–Ω–∞—Ü–∏—è ---
    try:
        page = int(data.get("page", 1))
    except Exception:
        page = 1
    try:
        per_page = int(data.get("per_page", 100))
    except Exception:
        per_page = 100
    per_page = max(1, min(per_page, 2000))

    return {
        "start": start,
        "end": end,
        "start_date": start_out,
        "end_date": end_out,
        "brands": brands,
        "models": models,
        "vin": vin,
        "line": line,
        "page": page,
        "per_page": per_page,
    }


# ==== helpers: time-based filtering for items ====
from typing import Optional

def _make_aware(dt):
    try:
        return _tz.make_aware(dt) if not _tz.is_aware(dt) else dt
    except Exception:
        return dt

ITEM_DT_PAIRS = [
    ("date", "time"),
    ("trim_out_date", "trim_out_time"),
    ("in_date", "in_time"),
    ("out_date", "out_time"),
    ("step1_date", "step1_time"),
    ("step3_date", "step3_time"),
]

def _extract_item_dt(it: dict) -> Optional[object]:
    """Try to build a timezone-aware datetime for a row item using common keys.
    Returns aware datetime or None.
    """
    # direct keys first
    for k in ("datetime", "dt", "timestamp"):
        v = it.get(k)
        if not v:
            continue
        try:
            d = parse_datetime(str(v))
            if d: return _make_aware(d)
        except Exception:
            pass
    # try pairs date+time
    for dkey, tkey in ITEM_DT_PAIRS:
        d = it.get(dkey)
        t = it.get(tkey)
        if not d or not t:
            continue
        try:
            iso = f"{d}T{t}"
            dt = parse_datetime(iso)
            if dt: return _make_aware(dt)
        except Exception:
            continue
    # last resort: just date
    for dkey, _ in ITEM_DT_PAIRS:
        d = it.get(dkey)
        if not d:
            continue
        try:
            dd = parse_date(str(d))
            if dd:
                return _make_aware(_dt.combine(dd, _t.min))
        except Exception:
            continue
    return None

def _filter_items_by_time(items: list[dict], start, end) -> list[dict]:
    if not (start and end):
        return items
    out = []
    for it in (items or []):
        dt = _extract_item_dt(it)
        if dt is None:
            # keep if we cannot determine ‚Äî do not drop silently
            out.append(it)
        elif start <= dt <= end:
            out.append(it)
    return out


# ==== MES: reference lists & suggestions (brands/models/VIN) ====

from django.views.decorators.http import require_GET
from django.http import JsonResponse

@login_required
@require_GET
def mes_tracing_brands_api(request):
    """
    GET /api/mes/tracing/brands
    Optional: ?q=substr (case-insensitive)
    Returns distinct brand names from TraceData (as stored), sorted.
    """
    q = (request.GET.get("q") or "").strip().lower()
    try:
        qs = (TraceData.objects
                .exclude(brand__isnull=True)
                .exclude(brand="")
                .values_list("brand", flat=True)
                .distinct())
        brands = sorted({(b or "").strip() for b in qs if (b or "").strip()})
        if q:
            brands = [b for b in brands if q in b.lower()]
    except Exception:
        brands = []
    return JsonResponse({"brands": brands}, json_dumps_params={"ensure_ascii": False})


@login_required
@require_GET
def mes_tracing_models_api(request):
    """
    GET /api/mes/tracing/models
    Optional: ?brand=... (multi, accepts top-level gwm/chery/changan or raw brands like haval/tank)
              ?q=substr (case-insensitive)
    Returns distinct models from TraceData, optionally filtered by brand(s).
    """
    q = (request.GET.get("q") or "").strip()
    brands_selected = [b.strip().lower() for b in request.GET.getlist("brand") if b.strip()]
    BRAND_MAP = {"gwm": ["haval", "tank"], "chery": ["chery"], "changan": ["changan"]}
    mapped: set[str] = set()
    for b in brands_selected:
        mapped.update(BRAND_MAP.get(b, [b]))

    try:
        qs = TraceData.objects.all()
        if mapped:
            qs = qs.filter(brand__in=list(mapped))
        if q:
            qs = qs.filter(model__icontains=q)
        qs = (qs.exclude(model__isnull=True)
                .exclude(model="")
                .values_list("model", flat=True)
                .distinct()
                .order_by("model"))
        models = [m for m in qs if (m or "").strip()]
    except Exception:
        models = []
    return JsonResponse({"models": models}, json_dumps_params={"ensure_ascii": False})


@login_required
@require_GET
def mes_vin_suggest_api(request):
    """
    GET /api/mes/history/vins?q=MXM&limit=20
    VIN suggestions from history; falls back to TraceData if VINHistory is unavailable.
    """
    q = (request.GET.get("q") or "").strip().upper()
    try:
        limit = int(request.GET.get("limit", 20))
    except Exception:
        limit = 20
    if len(q) < 2:  # –Ω–µ–±–æ–ª—å—à–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        return JsonResponse({"vins": []}, json_dumps_params={"ensure_ascii": False})

    vins: list[str] = []
    try:
        # prefer VINHistory if present
        from vehicle_history.models import VINHistory  # adjust import path if different
        qs = (VINHistory.objects.filter(vin__icontains=q)
                               .values_list("vin", flat=True)
                               .order_by("vin")[: max(1, limit)])
        vins = [v for v in qs if v]
    except Exception:
        try:
            qs = (TraceData.objects.filter(vin_rk__icontains=q)
                                   .values_list("vin_rk", flat=True)
                                   .order_by("vin_rk")[: max(1, limit)])
            vins = [v for v in qs if v]
        except Exception:
            vins = []

    # —É–Ω–∏–∫–∞–ª–∏–∑—É–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –æ—Ç —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    vins = sorted(dict.fromkeys(vins))[: max(1, limit)]
    return JsonResponse({"vins": vins}, json_dumps_params={"ensure_ascii": False})


# ==== MES: BQA (Buffer QA) APIs ====

@login_required
@require_GET
def bqa_overview_api(request):
    """
    GET /api/mes/bqa/overview
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: start_date, end_date, brand (multi), model (multi), line, vin.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç summary –ø–æ BQA: bqa_in, bqa_wip_today, bqa_wip_all.
    """
    f = _parse_mes_filters(request, allow_line=True)
    res = get_bqa_mes(
        start=f["start"],
        end=f["end"],
        brands=f["brands"] or None,
        models=f["models"] or None,
        line=f["line"],
        vin=f["vin"],
    ) or {}

    payload = {
        "filters": {
            "start_date": f["start_date"],
            "end_date": f["end_date"],
            "brands": f["brands"],
            "models": f["models"],
            "vin": f["vin"] or "",
            "line": f["line"] or "",
        },
        "overall": res.get("overall", {}),
    }
    # –µ—Å–ª–∏ —Ä–∞—Å—á—ë—Ç –≤–µ—Ä–Ω—ë—Ç —Ä–∞–∑–±–∏–≤–∫—É –ø–æ –ª–∏–Ω–∏—è–º ‚Äî –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º
    if "by_line" in res:
        payload["by_line"] = res["by_line"]

    return JsonResponse(payload, json_dumps_params={"ensure_ascii": False})


@login_required
@require_GET
def bqa_list_api(request):
    """
    GET /api/mes/bqa/list?metric=bqa_in|bqa_wip_today|bqa_wip_all
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞–≥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ VIN–æ–≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏.
    """
    f = _parse_mes_filters(request, allow_line=True)
    metric = (request.GET.get("metric") or "bqa_in").strip().lower()

    res = get_bqa_mes(
        start=f["start"],
        end=f["end"],
        brands=f["brands"] or None,
        models=f["models"] or None,
        line=f["line"],
        vin=f["vin"],
    ) or {}
    overall = res.get("overall", {})
    bucket = overall.get(metric, {"items": []})
    items = list(bucket.get("items", []) or [])
    items = _filter_items_by_time(items, f["start"], f["end"])

    total = len(items)
    lo = (f["page"] - 1) * f["per_page"]
    hi = lo + f["per_page"]

    return JsonResponse({
        "filters": {
            "start_date": f["start_date"],
            "end_date": f["end_date"],
            "brands": f["brands"],
            "models": f["models"],
            "vin": f["vin"] or "",
            "line": f["line"] or "",
            "metric": metric,
        },
        "pagination": {"page": f["page"], "per_page": f["per_page"], "total": total},
        "items": items[lo:hi],
    }, json_dumps_params={"ensure_ascii": False})


# ==== MES: QA (First Inspection ‚Üí Sign Off) APIs ====

@login_required
@require_GET
def qa_overview_api(request):
    """
    GET /api/mes/qa/overview
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: start_date, end_date, brand (multi), model (multi), vin, include_items=0|1
    –í QA –æ–¥–Ω–∞ –æ–±—â–∞—è –ª–∏–Ω–∏—è, –ø–æ—ç—Ç–æ–º—É –ø–∞—Ä–∞–º–µ—Ç—Ä line –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç summary: qa_in, wip_qa, sign_off (+ str, dpu).
    - qa_in/wip_qa/sign_off: –≤—Å–µ–≥–¥–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø–æ–ª–µ count; –ø—Ä–∏ include_items=1 —Ç–∞–∫–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç items.
    - str: {percent, numerator, denominator}
    - dpu: {value, defects, unique_cars_today}
    """
    f = _parse_mes_filters(request, allow_line=False)
    res = get_qa_mes(
        start=f["start"],
        end=f["end"],
        brands=f["brands"] or None,
        models=f["models"] or None,
        vin=f["vin"],
    ) or {}

    # include_items flag like in TRIM overview
    include_items = (request.GET.get("include_items") or "").strip().lower() in {"1","true","yes","on"}

    overall_raw = res.get("overall", {}) or {}

    # Normalize the three core buckets (always return counts; items optionally)
    metrics = ("qa_in", "wip_qa", "sign_off")
    overall_norm: dict = {}
    for m in metrics:
        node = overall_raw.get(m, {}) or {}
        if isinstance(node, dict):
            cnt = int(node.get("count", 0) or 0)
            overall_norm[m] = {"count": cnt}
            if include_items:
                overall_norm[m]["items"] = list(node.get("items", []) or [])
        else:
            cnt = int(node or 0)
            overall_norm[m] = {"count": cnt}
            if include_items:
                overall_norm[m]["items"] = []

    # Pass-through STR and DPU aggregates if present
    if "str" in overall_raw:
        overall_norm["str"] = overall_raw["str"]
    if "dpu" in overall_raw:
        overall_norm["dpu"] = overall_raw["dpu"]

    payload = {
        "filters": {
            "start_date": f["start_date"],
            "end_date": f["end_date"],
            "brands": f["brands"],
            "models": f["models"],
            "vin": f["vin"] or "",
            "include_items": include_items,
        },
        "overall": overall_norm,
    }
    return JsonResponse(payload, json_dumps_params={"ensure_ascii": False})



@login_required
@require_GET
def qa_list_api(request):
    """
    GET /api/mes/qa/list?metric=qa_in|wip_qa|sign_off
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞–≥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ VIN–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏ QA.
    """
    f = _parse_mes_filters(request, allow_line=False)
    metric = (request.GET.get("metric") or "qa_in").strip().lower()

    res = get_qa_mes(
        start=f["start"],
        end=f["end"],
        brands=f["brands"] or None,
        models=f["models"] or None,
        vin=f["vin"],
    ) or {}
    overall = res.get("overall", {})
    bucket = overall.get(metric, {"items": []})
    items = list(bucket.get("items", []) or [])
    items = _filter_items_by_time(items, f["start"], f["end"])

    total = len(items)
    lo = (f["page"] - 1) * f["per_page"]
    hi = lo + f["per_page"]

    return JsonResponse({
        "filters": {
            "start_date": f["start_date"],
            "end_date": f["end_date"],
            "brands": f["brands"],
            "models": f["models"],
            "vin": f["vin"] or "",
            "metric": metric,
        },
        "pagination": {"page": f["page"], "per_page": f["per_page"], "total": total},
        "items": items[lo:hi],
    }, json_dumps_params={"ensure_ascii": False})


# ==== MES: UUD (–£—á–∞—Å—Ç–æ–∫ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤) APIs ====

@login_required
@require_GET
def uud_overview_api(request):
    """
    GET /api/mes/uud/overview
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: start_date, end_date, brand (multi), model (multi), vin.
    –í –£–£–î –Ω–µ—Ç —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –ª–∏–Ω–∏–∏ (–µ–¥–∏–Ω–∞—è –ª–∏–Ω–∏—è), –ø–æ—ç—Ç–æ–º—É –ø–∞—Ä–∞–º–µ—Ç—Ä line –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç summary:
      - uud_in                ‚Äî –ø–æ—Å—Ç—É–ø–∏–≤—à–∏–µ –Ω–∞ –£–£–î –∑–∞ –ø–µ—Ä–∏–æ–¥ (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ VIN)
      - uud_in_wip_today      ‚Äî –∏–∑ –ø–æ—Å—Ç—É–ø–∏–≤—à–∏—Ö —Å–µ–≥–æ–¥–Ω—è —Å—Ç–æ—è—Ç –≤ –±—É—Ñ–µ—Ä–µ (–µ—â—ë –Ω–µ –ø—Ä–∏–Ω—è—Ç—ã –£–£–î)
      - uud_in_wip_all        ‚Äî –≤—Å–µ, –∫—Ç–æ –≤ –±—É—Ñ–µ—Ä–µ –£–£–î –∏–∑ –ª—é–±—ã—Ö –¥–Ω–µ–π (–Ω–∞ —à–∞–≥–µ 1)
      - wip_uud               ‚Äî —Å–µ–π—á–∞—Å –≤ —Ä–∞–±–æ—Ç–µ –Ω–∞ –£–£–î (—à–∞–≥ 2)
      - uud_out               ‚Äî –æ—Ç—Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã –∑–∞ –ø–µ—Ä–∏–æ–¥ (–ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã –Ω–∞ —à–∞–≥ 3)
      - uud_out_wip_today     ‚Äî —Å–µ–≥–æ–¥–Ω—è –æ—Ç—Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã, –Ω–æ –µ—â—ë –Ω–µ –ø—Ä–∏–Ω—è—Ç—ã QA (—à–∞–≥ 3, –∑–∞ —Å–µ–≥–æ–¥–Ω—è)
      - uud_out_wip_all       ‚Äî –≤—Å–µ –æ–∂–∏–¥–∞—é—â–∏–µ –ø—Ä–∏—ë–º–∞ QA –ø–æ—Å–ª–µ —Ä–µ–º–æ–Ω—Ç–∞ (—à–∞–≥ 3, –≤—Å–µ –¥–Ω–∏)
    –ó–∞–º–µ—á–∞–Ω–∏–µ: —Ç–æ—á–Ω—ã–µ –∫–ª—é—á–∏ –±–µ—Ä—É—Ç—Å—è –∏–∑ —Ä–∞—Å—á—ë—Ç–∞ get_uud_mes(); –µ—Å–ª–∏ –æ–Ω–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è, —Ñ—Ä–æ–Ω—Ç –ø–æ–ª—É—á–∏—Ç —Ç–æ, —á—Ç–æ –≤–µ—Ä–Ω—É–ª —Ä–∞—Å—á—ë—Ç.
    """
    f = _parse_mes_filters(request, allow_line=False)
    res = get_uud_mes(
        start=f["start"],
        end=f["end"],
        brands=f["brands"] or None,
        models=f["models"] or None,
        vin=f["vin"],
    ) or {}

    payload = {
        "filters": {
            "start_date": f["start_date"],
            "end_date": f["end_date"],
            "brands": f["brands"],
            "models": f["models"],
            "vin": f["vin"] or "",
        },
        # –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å; —Ñ—Ä–æ–Ω—Ç—É –¥–æ—Å—Ç—É–ø–Ω—ã –≤—Å–µ –ø–æ–ª—è, —á—Ç–æ –≤–µ—Ä–Ω—É–ª —Ä–∞—Å—á—ë—Ç
        "overall": res.get("overall", {}),
    }
    return JsonResponse(payload, json_dumps_params={"ensure_ascii": False})


@login_required
@require_GET
def uud_list_api(request):
    """
    GET /api/mes/uud/list?metric=
      uud_in | uud_in_wip_today | uud_in_wip_all |
      wip_uud |
      uud_out | uud_out_wip_today | uud_out_wip_all

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞–≥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ VIN-—ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏ –£–£–î.
    –ï—Å–ª–∏ –∫–ª—é—á –º–µ—Ç—Ä–∏–∫–∏ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ —Ä–∞—Å—á—ë—Ç–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–Ω–æ–π –∞–ª–∏–∞—Å),
    –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–∞—Ä—Ç–∞ –ø—Å–µ–≤–¥–æ–Ω–∏–º–æ–≤ –Ω–∏–∂–µ.
    """
    f = _parse_mes_filters(request, allow_line=False)
    metric = (request.GET.get("metric") or "uud_in").strip().lower()

    # –í–æ–∑–º–æ–∂–Ω—ã–µ –∞–ª–∏–∞—Å—ã –Ω–∞ —Å–ª—É—á–∞–π —Å–º–µ–Ω—ã –Ω–µ–π–º–∏–Ω–≥–∞ –≤–Ω—É—Ç—Ä–∏ —Ä–∞—Å—á—ë—Ç–∞
    aliases = {
        "uud_wip": "wip_uud",
        "wip": "wip_uud",
        "in_wip_today": "uud_in_wip_today",
        "in_wip_all": "uud_in_wip_all",
        "out_wip_today": "uud_out_wip_today",
        "out_wip_all": "uud_out_wip_all",
    }

    res = get_uud_mes(
        start=f["start"],
        end=f["end"],
        brands=f["brands"] or None,
        models=f["models"] or None,
        vin=f["vin"],
    ) or {}
    overall = res.get("overall", {}) or {}

    key = metric if metric in overall else aliases.get(metric, metric)
    if key not in overall:
        # –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–ª—é—á–µ–π, —á—Ç–æ–±—ã —Ñ—Ä–æ–Ω—Ç—É –±—ã–ª–æ –ø—Ä–æ—â–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å
        return JsonResponse({
            "ok": False,
            "error": "unknown metric",
            "metric": metric,
            "available": sorted(list(overall.keys())),
        }, status=400)

    bucket = overall.get(key, {}) or {}
    items = list(bucket.get("items", []) or [])
    items = _filter_items_by_time(items, f["start"], f["end"])

    total = len(items)
    lo = (f["page"] - 1) * f["per_page"]
    hi = lo + f["per_page"]

    return JsonResponse({
        "filters": {
            "start_date": f["start_date"],
            "end_date": f["end_date"],
            "brands": f["brands"],
            "models": f["models"],
            "vin": f["vin"] or "",
            "metric": key,
        },
        "pagination": {"page": f["page"], "per_page": f["per_page"], "total": total},
        "items": items[lo:hi],
    }, json_dumps_params={"ensure_ascii": False})



# ==== MES: VES (Vehicle Evaluation Station) APIs ====

@login_required
@require_GET
def ves_overview_api(request):
    """
    GET /api/mes/ves/overview
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: start_date, end_date, brand (multi), model (multi), vin.
    –í VES –Ω–µ—Ç —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –ª–∏–Ω–∏–∏, –ø–æ—ç—Ç–æ–º—É –ø–∞—Ä–∞–º–µ—Ç—Ä line –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç summary –ø–æ VES (–∫–∞–∫ –µ–≥–æ –æ—Ç–¥–∞—ë—Ç —Ä–∞—Å—á—ë—Ç get_ves_mes):
      - ves_in    ‚Äî –ø–µ—Ä–µ–¥–∞–Ω—ã –Ω–∞ VES –∑–∞ –ø–µ—Ä–∏–æ–¥ (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ VIN)
      - wip_ves   ‚Äî —Å–µ–π—á–∞—Å –Ω–∞—Ö–æ–¥—è—Ç—Å—è –Ω–∞ VES (–æ—Ç–¥–∞–Ω—ã, –Ω–æ –µ—â—ë –Ω–µ –ø—Ä–∏–Ω—è—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ)
      - ves_out   ‚Äî –ø—Ä–∏–Ω—è—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ —Å VES –∑–∞ –ø–µ—Ä–∏–æ–¥
    –≠–ª–µ–º–µ–Ω—Ç—ã –º–µ—Ç—Ä–∏–∫ —Å–æ–¥–µ—Ä–∂–∞—Ç –ø–æ–ª—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–µ —Ä–∞—Å—á—ë—Ç–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä: vin, given_date/time, received_date/time,
    given_by, received_by, brand, model), –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞—é—Ç—Å—è –±–µ–∑ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è.
    """
    f = _parse_mes_filters(request, allow_line=False)
    res = get_ves_mes(
        start=f["start"],
        end=f["end"],
        brands=f["brands"] or None,
        models=f["models"] or None,
        vin=f["vin"],
    ) or {}

    payload = {
        "filters": {
            "start_date": f["start_date"],
            "end_date": f["end_date"],
            "brands": f["brands"],
            "models": f["models"],
            "vin": f["vin"] or "",
        },
        "overall": res.get("overall", {}),
    }
    return JsonResponse(payload, json_dumps_params={"ensure_ascii": False})


@login_required
@require_GET
def ves_list_api(request):
    """
    GET /api/mes/ves/list?metric=ves_in|wip_ves|ves_out
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞–≥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ VIN-—ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –∞–ª–∏–∞—Å—ã: "in"->"ves_in", "out"->"ves_out", "wip"|"ves_wip"->"wip_ves".
    """
    f = _parse_mes_filters(request, allow_line=False)
    metric = (request.GET.get("metric") or "ves_in").strip().lower()

    # –ê–ª–∏–∞—Å—ã –Ω–∞ —Å–ª—É—á–∞–π –∏–Ω–æ–≥–æ –Ω–µ–π–º–∏–Ω–≥–∞ –≤ –∑–∞–ø—Ä–æ—Å–∞—Ö
    aliases = {
        "in": "ves_in",
        "out": "ves_out",
        "wip": "wip_ves",
        "ves_wip": "wip_ves",
    }

    res = get_ves_mes(
        start=f["start"],
        end=f["end"],
        brands=f["brands"] or None,
        models=f["models"] or None,
        vin=f["vin"],
    ) or {}
    overall = res.get("overall", {}) or {}

    key = metric if metric in overall else aliases.get(metric, metric)
    if key not in overall:
        return JsonResponse({
            "ok": False,
            "error": "unknown metric",
            "metric": metric,
            "available": sorted(list(overall.keys())),
        }, status=400)

    bucket = overall.get(key, {}) or {}
    items = list(bucket.get("items", []) or [])
    items = _filter_items_by_time(items, f["start"], f["end"])

    total = len(items)
    lo = (f["page"] - 1) * f["per_page"]
    hi = lo + f["per_page"]

    return JsonResponse({
        "filters": {
            "start_date": f["start_date"],
            "end_date": f["end_date"],
            "brands": f["brands"],
            "models": f["models"],
            "vin": f["vin"] or "",
            "metric": key,
        },
        "pagination": {"page": f["page"], "per_page": f["per_page"], "total": total},
        "items": items[lo:hi],
    }, json_dumps_params={"ensure_ascii": False})


# ==== MES: DASHBOARD SUMMARY (combined) ====

@login_required
@require_GET
def mes_summary_api(request):
    """
    GET /api/mes/summary

    –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π JSON –ø–æ –≤—Å–µ–º MES-—Å–µ–∫—Ü–∏—è–º: TRIM, BQA, QA, UUD, VES.
    –§–∏–ª—å—Ç—Ä—ã –ø–µ—Ä–∏–æ–¥–∞ (start_date/end_date) –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –∫–æ –≤—Å–µ–º.
    –§–∏–ª—å—Ç—Ä—ã brand/model/vin –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫ –Ω–∏–∂–Ω–µ–º—É –±–ª–æ–∫—É (bottom),
    –∫–∞–∫ –º—ã –¥–æ–≥–æ–≤–∞—Ä–∏–≤–∞–ª–∏—Å—å: –≤–µ—Ä—Ö–Ω–∏–π –±–ª–æ–∫ (top) ‚Äî totals –∑–∞ –≤—Å–µ –±—Ä–µ–Ω–¥—ã/–º–æ–¥–µ–ª–∏/–ª–∏–Ω–∏–∏.

    Query params:
      - start_date, end_date: YYYY-MM-DD (–µ—Å–ª–∏ –æ–±–∞ –ø—É—Å—Ç—ã–µ ‚Äî —Å–µ–≥–æ–¥–Ω—è)
      - brand: multi (?brand=gwm&brand=chery) ‚Äî –≤–ª–∏—è–µ—Ç –¢–û–õ–¨–ö–û –Ω–∞ bottom
      - model: multi ‚Äî –≤–ª–∏—è–µ—Ç –¢–û–õ–¨–ö–û –Ω–∞ bottom
      - vin: —Ç–æ—á–Ω—ã–π VIN ‚Äî –≤–ª–∏—è–µ—Ç –¢–û–õ–¨–ö–û –Ω–∞ bottom
      - line: gwm|chery|changan ‚Äî –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫ TRIM –≤ bottom (–≤ top –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º)
      - sections: csv –∏–∑ {trim,bqa,qa,uud,ves}; –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –≤—Å–µ
      - include_items: 0|1 ‚Äî –µ—Å–ª–∏ 1, –æ—Ç–¥–∞—ë–º —Å–ø–∏—Å–∫–∏ items; –∏–Ω–∞—á–µ —Ç–æ–ª—å–∫–æ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –±–µ–∑ –º–∞—Å—Å–∏–≤–æ–≤

    –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
      {
        "filters": {...},
        "summary": {
          "top": { "trim": {...}, "bqa": {...}, ... },
          "bottom": { "trim": {...}, "bqa": {...}, ... }
        }
      }
    """
    f = _parse_mes_filters(request, allow_line=True)

    include_items = (request.GET.get("include_items") or "").strip().lower() in {"1","true","yes","on"}
    sections_raw = (request.GET.get("sections") or "").strip()
    wanted = {s.strip().lower() for s in sections_raw.split(",") if s.strip()} or {"trim","bqa","qa","uud","ves"}
    allowed = {"trim","bqa","qa","uud","ves"}
    sections = wanted & allowed

    def _safe(calc, **kwargs):
        try:
            return calc(**kwargs) or {}
        except Exception:
            return {}

    # --- TOP: totals –∑–∞ –ø–µ—Ä–∏–æ–¥ –±–µ–∑ brand/model/vin/line ---
    top: dict = {}
    if "trim" in sections:
        top["trim"] = _safe(
            get_trim_mes,
            start=f["start"], end=f["end"],
            line=None, brands=None, models=None, vin=None,
        )
    if "bqa" in sections:
        top["bqa"] = _safe(
            get_bqa_mes,
            start=f["start"], end=f["end"],
            brands=None, models=None, line=None, vin=None,
        )
    if "qa" in sections:
        top["qa"] = _safe(
            get_qa_mes,
            start=f["start"], end=f["end"],
            brands=None, models=None, vin=None,
        )
    if "uud" in sections:
        top["uud"] = _safe(
            get_uud_mes,
            start=f["start"], end=f["end"],
            brands=None, models=None, vin=None,
        )
    if "ves" in sections:
        top["ves"] = _safe(
            get_ves_mes,
            start=f["start"], end=f["end"],
            brands=None, models=None, vin=None,
        )

    # --- BOTTOM: –ø—Ä–∏–º–µ–Ω—è–µ–º brand/model/vin; line —Ç–æ–ª—å–∫–æ –∫ TRIM ---
    bottom: dict = {}
    if "trim" in sections:
        bottom["trim"] = _safe(
            get_trim_mes,
            start=f["start"], end=f["end"],
            line=f["line"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"],
        )
    if "bqa" in sections:
        bottom["bqa"] = _safe(
            get_bqa_mes,
            start=f["start"], end=f["end"],
            brands=f["brands"] or None, models=f["models"] or None, line=f["line"], vin=f["vin"],
        )
    if "qa" in sections:
        bottom["qa"] = _safe(
            get_qa_mes,
            start=f["start"], end=f["end"],
            brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"],
        )
    if "uud" in sections:
        bottom["uud"] = _safe(
            get_uud_mes,
            start=f["start"], end=f["end"],
            brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"],
        )
    if "ves" in sections:
        bottom["ves"] = _safe(
            get_ves_mes,
            start=f["start"], end=f["end"],
            brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"],
        )

    # --- optionally strip items arrays to keep payload small ---
    def _strip_items(obj: dict) -> dict:
        if include_items:
            return obj
        def prune(x):
            if isinstance(x, dict):
                return {k: prune(v) for k, v in x.items() if k != "items"}
            if isinstance(x, list):
                return [prune(i) for i in x]
            return x
        return prune(obj)

    response = {
        "filters": {
            "start_date": f["start_date"],
            "end_date": f["end_date"],
            "brands": f["brands"],
            "models": f["models"],
            "vin": f["vin"] or "",
            "line": f["line"] or "",
            "sections": sorted(list(sections)),
            "include_items": bool(include_items),
        },
        "summary": {
            "top": _strip_items(top),
            "bottom": _strip_items(bottom),
        }
    }

    return JsonResponse(response, json_dumps_params={"ensure_ascii": False})


# ==== MES: DASHBOARD PAGE VIEWS (template-rendered) ====

@login_required
@permission_required('users.access_to_indicators', raise_exception=True)
def mes_dashboard_view(request):
    """
    –°—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –æ–±—â–∏–º –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º –¥–∞—à–±–æ—Ä–¥–æ–º MES.
    - –í–µ—Ä—Ö–Ω–∏–π –±–ª–æ–∫ (top): —Ç–æ—Ç–∞–ª—ã –ø–æ –≤—Å–µ–º –±—Ä–µ–Ω–¥–∞–º/–º–æ–¥–µ–ª—è–º/–ª–∏–Ω–∏—è–º –∑–∞ –ø–µ—Ä–∏–æ–¥.
    - –ù–∏–∂–Ω–∏–π –±–ª–æ–∫ (bottom): —Ç–µ –∂–µ –º–µ—Ç—Ä–∏–∫–∏, –Ω–æ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏ brand/model/vin (+ line –¥–ª—è TRIM).
    –î–∞–Ω–Ω—ã–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–¥–≥—Ä—É–∂–∞—é—Ç—Å—è —Ñ—Ä–æ–Ω—Ç–æ–º —á–µ—Ä–µ–∑ /api/mes/summary.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ GET-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–¥–ª—è –ø—Ä–µ–¥–∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏ –∞–≤—Ço–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è):
      ?start_date=YYYY-MM-DD&amp;end_date=YYYY-MM-DD  (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Å–µ–≥–æ–¥–Ω—è..—Å–µ–≥–æ–¥–Ω—è)
      ?brand=gwm&amp;brand=chery                      (–º—É–ª—å—Ç–∏, –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è)
      ?model=Tiggo%204                              (–º—É–ª—å—Ç–∏)
      ?line=gwm|chery|changan                       (—Ç–æ–ª—å–∫–æ –¥–ª—è TRIM –≤ –Ω–∏–∂–Ω–µ–º –±–ª–æ–∫–µ)
      ?vin=VIN
      ?sections=trim,bqa,qa,uud,ves
      ?refresh_ms=15000
      ?include_items=0|1  (–ø—Ä–æ–±—Ä–æ—Å –¥–ª—è /api/mes/summary)
    """
    data = request.GET
    # –ü–µ—Ä–∏–æ–¥
    start_date = (data.get("start_date") or "").strip()
    end_date   = (data.get("end_date") or "").strip()
    if not start_date and not end_date:
        today = _tz.localdate()
        start_date = end_date = today.isoformat()

    # –§–∏–ª—å—Ç—Ä—ã
    brands_selected = [b.strip().lower() for b in data.getlist("brand") if b.strip()]
    models_selected = [m.strip() for m in data.getlist("model") if m.strip()]
    vin  = (data.get("vin") or "").strip().upper()
    line = (data.get("line") or "").strip().lower()
    sections_req = [s.strip().lower() for s in (data.get("sections") or "").split(",") if s.strip()]
    sections = sections_req or ["trim", "bqa", "qa", "uud", "ves"]
    # –ê–≤—Ç–æ–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    try:
        refresh_ms = int(data.get("refresh_ms", "15000"))
    except Exception:
        refresh_ms = 15000
    include_items = (data.get("include_items") or "").strip().lower() in {"1","true","yes","on"}

    # –û–ø—Ü–∏–∏ —Å–µ–ª–µ–∫—Ç–æ–≤
    # –î–ª—è –º–æ–¥–µ–ª–µ–π –±–µ—Ä—ë–º distinct –∏–∑ TraceData; –µ—Å–ª–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —É–∂–µ –≤—ã–±—Ä–∞–Ω—ã –±—Ä–µ–Ω–¥—ã ‚Äî —É—á—Ç—ë–º –∏—Ö –º–∞–ø–ø–∏–Ω–≥.
    BRAND_MAP = {"gwm": ["haval", "tank"], "chery": ["chery"], "changan": ["changan"]}
    trace_qs = TraceData.objects.all()
    if brands_selected:
        mapped = list(chain.from_iterable(BRAND_MAP.get(b, [b]) for b in brands_selected))
        trace_qs = trace_qs.filter(brand__in=mapped)
    models_options = list(
        trace_qs.exclude(model__isnull=True)
                .exclude(model="")
                .values_list("model", flat=True)
                .distinct()
                .order_by("model")
    )

    def _rev(name: str, default: str) -> str:
        try:
            return reverse(name)
        except Exception:
            return default

    api_map = {
        "summary": _rev("mes_summary_api", "/api/mes/summary"),
        "trim": {
            "overview": _rev("trim_overview_api", "/api/mes/trim/overview"),
            "list":     _rev("trim_list_api", "/api/mes/trim/list"),
        },
        "bqa": {
            "overview": _rev("bqa_overview_api", "/api/mes/bqa/overview"),
            "list":     _rev("bqa_list_api", "/api/mes/bqa/list"),
        },
        "qa": {
            "overview": _rev("qa_overview_api", "/api/mes/qa/overview"),
            "list":     _rev("qa_list_api", "/api/mes/qa/list"),
        },
        "uud": {
            "overview": _rev("uud_overview_api", "/api/mes/uud/overview"),
            "list":     _rev("uud_list_api", "/api/mes/uud/list"),
        },
        "ves": {
            "overview": _rev("ves_overview_api", "/api/mes/ves/overview"),
            "list":     _rev("ves_list_api", "/api/mes/ves/list"),
        },
    }

    ctx = {
        "filters": {
            "start_date": start_date,
            "end_date": end_date,
            "brands": brands_selected,
            "models": models_selected,
            "vin": vin,
            "line": line,
            "sections": sections,
            "include_items": include_items,
        },
        "options": {
            "brands": ["gwm", "chery", "changan"],
            "models": models_options,
            "lines":  ["gwm", "chery", "changan"],
        },
        "api": api_map,
        "refresh_ms": refresh_ms,
        "enable_particles": True,
        "enable_background": True,
        "enable_white_square": False,
    }
    return render(request, "users/mes/mes_dashboard.html", ctx)


@login_required
@permission_required('users.access_to_indicators', raise_exception=True)
def mes_metric_list_view(request, section: str | None = None):
    """
    –°—Ç—Ä–∞–Ω–∏—Ü–∞ ¬´VIN‚Äë–ª–∏—Å—Ç –ø–æ –º–µ—Ç—Ä–∏–∫–µ¬ª (–ø–æ –∫–ª–∏–∫—É –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫—É).
    –†–µ–Ω–¥–µ—Ä–∏—Ç —Ç–∞–±–ª–∏—Ü—É —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π; –¥–∞–Ω–Ω—ã–µ —Ç—è–Ω—É—Ç—Å—è —Ñ—Ä–æ–Ω—Ç–æ–º –∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ list‚ÄëAPI.
    GET:
      ?section=trim|bqa|qa|uud|ves
      ?metric=...            (–Ω–∞–ø—Ä–∏–º–µ—Ä: trim_in|wip_trim|trim_out, bqa_in|bqa_wip_all, qa_in|sign_off, ...)
      ?start_date, ?end_date
      ?brand, ?model (multi)
      ?vin
      ?line (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è TRIM)
    """
    section = (section or request.GET.get("section") or "trim").strip().lower()
    if section not in {"trim", "bqa", "qa", "uud", "ves"}:
        section = "trim"

    # –≤—ã—Ç–∞—â–∏–º —Ñ–∏–ª—å—Ç—Ä—ã –∏ default –º–µ—Ç—Ä–∏–∫—É
    f = _parse_mes_filters(request, allow_line=(section == "trim"))
    default_metric = {
        "trim": "trim_in",
        "bqa":  "bqa_in",
        "qa":   "qa_in",
        "uud":  "uud_in",
        "ves":  "ves_in",
    }[section]
    metric = (request.GET.get("metric") or default_metric).strip().lower()

    def _rev(name: str, default: str) -> str:
        try:
            return reverse(name)
        except Exception:
            return default

    api_list_url = {
        "trim": _rev("trim_list_api", "/api/mes/trim/list"),
        "bqa":  _rev("bqa_list_api",  "/api/mes/bqa/list"),
        "qa":   _rev("qa_list_api",   "/api/mes/qa/list"),
        "uud":  _rev("uud_list_api",  "/api/mes/uud/list"),
        "ves":  _rev("ves_list_api",  "/api/mes/ves/list"),
    }[section]

    api_table_url = _rev("mes_metric_table_api", "/api/mes/table")

    ctx = {
        "section": section,
        "metric": metric,
        "api_list_url": api_list_url,
        "api_table_url": api_table_url,
        "filters": {
            "start_date": f["start_date"],
            "end_date":   f["end_date"],
            "brands":     f["brands"],
            "models":     f["models"],
            "vin":        f["vin"] or "",
            "line":       f["line"] or "",
            "page":       f["page"],
            "per_page":   f["per_page"],
        },
        # –¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ñ–ª–∞–≥–∏, —á—Ç–æ–±—ã —à–∞–±–ª–æ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª —Å—Ç–∏–ª—é –¥—Ä—É–≥–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        # "enable_particles": True,
        # "enable_background": True,
        # "enable_white_square": False,
    }
    return render(request, "users/mes/metric_list.html", ctx)


# ==== MES: Dynamic table API (columns + items) ====

KEY_TITLES = {
    "vin": "VIN",
    "brand": "–ë—Ä–µ–Ω–¥",
    "model": "–ú–æ–¥–µ–ª—å",
    "line": "–õ–∏–Ω–∏—è",
    "date": "–î–∞—Ç–∞",
    "time": "–í—Ä–µ–º—è",
    "controller": "–ö–æ–Ω—Ç—Ä–æ–ª—ë—Ä",
    "controller_out": "–ö–æ–Ω—Ç—Ä–æ–ª—ë—Ä OUT",
    "controller_in": "–ö–æ–Ω—Ç—Ä–æ–ª—ë—Ä IN",
    "controller_give": "–ö—Ç–æ –ø–µ—Ä–µ–¥–∞–ª",
    "controller_receive": "–ö—Ç–æ –ø—Ä–∏–Ω—è–ª",
    "controller_finish": "–ó–∞–≤–µ—Ä—à–∏–ª",
    "trim_out_date": "–î–∞—Ç–∞ TRIM OUT",
    "trim_out_time": "–í—Ä–µ–º—è TRIM OUT",
    "in_date": "–î–∞—Ç–∞ –ø–µ—Ä–µ–¥–∞—á–∏",
    "in_time": "–í—Ä–µ–º—è –ø–µ—Ä–µ–¥–∞—á–∏",
    "out_date": "–î–∞—Ç–∞ –ø—Ä–∏—ë–º–∫–∏",
    "out_time": "–í—Ä–µ–º—è –ø—Ä–∏—ë–º–∫–∏",
    "step1_date": "–î–∞—Ç–∞ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è",
    "step1_time": "–í—Ä–µ–º—è –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è",
    "step3_date": "–î–∞—Ç–∞ —Ä–µ–º–æ–Ω—Ç–∞",
    "step3_time": "–í—Ä–µ–º—è —Ä–µ–º–æ–Ω—Ç–∞",
    # —Ä–µ–∑–µ—Ä–≤ –Ω–∞ –±—É–¥—É—â–µ–µ:
    "saved_by": "–°–æ—Ö—Ä–∞–Ω–∏–ª",
    "controller_login": "–õ–æ–≥–∏–Ω –∫–æ–Ω—Ç—Ä–æ–ª—ë—Ä–∞",
}

def _infer_columns_from_items(items: list[dict]) -> list[dict]:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã: [{key, title}, ...]
    –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–ª—é—á–∏ (KEY_TITLES); –ø–æ—Ä—è–¥–æ–∫ ‚Äî –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π, –∑–∞—Ç–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ –ø–æ—è–≤–ª–µ–Ω–∏—é.
    """
    if not items:
        # –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –Ω–∞–±–æ—Ä ‚Äî —Ç–æ–ª—å–∫–æ VIN
        return [{"key": "vin", "title": KEY_TITLES["vin"]}]

    # –∫–ª—é—á–∏, –≤—Å—Ç—Ä–µ—á–∞—é—â–∏–µ—Å—è –≤ –¥–∞–Ω–Ω—ã—Ö
    seen: list[str] = []
    for it in items:
        if not isinstance(it, dict):
            continue
        for k in it.keys():
            if k in KEY_TITLES and k not in seen:
                seen.append(k)

    preferred_order = [
        "vin", "brand", "model", "line",
        "date", "time",
        "trim_out_date", "trim_out_time",
        "in_date", "in_time",
        "out_date", "out_time",
        "step1_date", "step1_time",
        "step3_date", "step3_time",
        "controller", "controller_out", "controller_in",
        "controller_give", "controller_receive", "controller_finish",
        "saved_by", "controller_login",
    ]

    ordered = [k for k in preferred_order if k in seen] + [k for k in seen if k not in preferred_order]
    return [{"key": k, "title": KEY_TITLES.get(k, k)} for k in ordered]

def _resolve_metric_key(section: str, metric: str, overall: dict) -> str | None:
    """
    –ü—Ä–∏–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫—É –∫ –∫–ª—é—á—É, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–µ–º—É –≤ overall, —Å —É—á—ë—Ç–æ–º –∞–ª–∏–∞—Å–æ–≤.
    """
    section = (section or "").lower().strip()
    metric  = (metric or "").lower().strip()

    # –¥–µ—Ñ–æ–ª—Ç—ã –ø–æ —Å–µ–∫—Ü–∏—è–º
    defaults = {"trim": "trim_in", "bqa": "bqa_in", "qa": "qa_in", "uud": "uud_in", "ves": "ves_in"}
    if not metric:
        metric = defaults.get(section, "trim_in")

    aliases = {}
    if section == "ves":
        aliases = {"in": "ves_in", "out": "ves_out", "wip": "wip_ves", "ves_wip": "wip_ves"}
    elif section == "uud":
        aliases = {
            "uud_wip": "wip_uud",
            "wip": "wip_uud",
            "in_wip_today": "uud_in_wip_today",
            "in_wip_all": "uud_in_wip_all",
            "out_wip_today": "uud_out_wip_today",
            "out_wip_all": "uud_out_wip_all",
        }
    # –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–µ–∫—Ü–∏–π –∞–ª–∏–∞—Å—ã –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è

    key = metric if metric in (overall or {}) else aliases.get(metric, metric)
    return key if key in (overall or {}) else None

@login_required
@require_GET
def mes_metric_table_api(request):
    """
    GET /api/mes/table
      ?section=trim|bqa|qa|uud|ves
      ?metric=...
      ?start_date=YYYY-MM-DD&end_date=YYYY-MM-DD
      ?brand=...&model=... (multi)
      ?line=... (—Ç–æ–ª—å–∫–æ –¥–ª—è TRIM)
      ?vin=VIN
      ?page=1&per_page=100

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    {
      "filters": {...},
      "pagination": {...},
      "columns": [{"key":"vin","title":"VIN"}, ...],
      "items": [ {...}, ... ]
    }
    """
    section = (request.GET.get("section") or "trim").strip().lower()
    allow_line = (section == "trim")
    f = _parse_mes_filters(request, allow_line=allow_line)

    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å—á—ë—Ç –ø–æ —Å–µ–∫—Ü–∏–∏
    calc_map = {
        "trim": lambda: get_trim_mes(start=f["start"], end=f["end"], line=f["line"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"]),
        "bqa":  lambda: get_bqa_mes(start=f["start"], end=f["end"], line=f["line"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"]),
        "qa":   lambda: get_qa_mes(start=f["start"], end=f["end"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"]),
        "uud":  lambda: get_uud_mes(start=f["start"], end=f["end"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"]),
        "ves":  lambda: get_ves_mes(start=f["start"], end=f["end"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"]),
    }
    if section not in calc_map:
        section = "trim"

    try:
        res = calc_map[section]() or {}
    except Exception:
        res = {}

    overall = res.get("overall", {}) or {}
    metric = (request.GET.get("metric") or "").strip().lower()
    key = _resolve_metric_key(section, metric, overall)
    if not key:
        return JsonResponse({
            "ok": False,
            "error": "unknown metric",
            "available": sorted(list(overall.keys())),
        }, status=400)

    bucket = overall.get(key, {}) or {}
    items = list(bucket.get("items", []) or [])
    items = _filter_items_by_time(items, f["start"], f["end"])

    # –Ø–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ª–∏–Ω–∏–∏ –¥–ª—è TRIM (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –∞–≥–≥—Ä–µ–≥–∞—Ç–æ—Ä –≤–µ—Ä–Ω—É–ª –≤—Å–µ –ª–∏–Ω–∏–∏)
    if allow_line and f["line"]:
        items = [it for it in items if (it.get("line") or "").strip().lower() == f["line"]]

    total = len(items)
    lo = (f["page"] - 1) * f["per_page"]
    hi = lo + f["per_page"]
    items_page = items[lo:hi]

    columns = _infer_columns_from_items(items_page if items_page else items)

    return JsonResponse({
        "filters": {
            "section": section,
            "metric": key,
            "start_date": f["start_date"],
            "end_date": f["end_date"],
            "brands": f["brands"],
            "models": f["models"],
            "vin": f["vin"] or "",
            "line": f["line"] or "",
        },
        "pagination": {"page": f["page"], "per_page": f["per_page"], "total": total},
        "columns": columns,
        "items": items_page,
    }, json_dumps_params={"ensure_ascii": False})


# ===== TRIM MES JSON APIs =====

from datetime import datetime, time
from django.utils import timezone

ALLOWED_LINES = {"gwm", "chery", "changan"}

def _parse_trim_filters(request):
    """
    Common filter parser for TRIM APIs.
    Accepts:
      - start_date, end_date: YYYY-MM-DD **–∏–ª–∏** ISO datetime (e.g. 2025-09-22T00:00)
      - brand: multi (?brand=gwm&brand=chery) ‚Äî top-level brands
      - model: multi (?model=Tiggo%204)
      - line: one of gwm|chery|changan (applies mainly to TRIM IN/WIP; TRIM OUT uses brand/model mapping)
      - vin: exact VIN (optional)
      - page, per_page: for list endpoint
    Returns dict with timezone-aware datetimes for 'start'/'end'.
    """
    from django.utils.dateparse import parse_date, parse_datetime

    data = request.GET if request.method == "GET" else request.POST

    # --- Period ---
    start_s = (data.get("start_date") or "").strip()
    end_s   = (data.get("end_date") or "").strip()

    # 1) —Å–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∫–∞–∫ ISO datetime; 2) –∏–Ω–∞—á–µ –∫–∞–∫ date (–±–µ—Ä—ë–º –≥—Ä–∞–Ω–∏—Ü—ã —Å—É—Ç–æ–∫)
    start_dt = parse_datetime(start_s) if start_s else None
    end_dt   = parse_datetime(end_s)   if end_s   else None

    if start_dt or end_dt:
        start = timezone.make_aware(start_dt) if (start_dt and not timezone.is_aware(start_dt)) else start_dt
        end   = timezone.make_aware(end_dt)   if (end_dt   and not timezone.is_aware(end_dt))   else end_dt
    else:
        # –¥–æ–ø—É—Å–∫–∞–µ–º –≤—Ö–æ–¥ –≤–∏–¥–∞ 2025-09-22T00:00 ‚Äî –≤–æ–∑—å–º—ë–º —á–∞—Å—Ç—å –¥–æ 'T'
        if "T" in start_s:
            start_s = start_s.split("T", 1)[0]
        if "T" in end_s:
            end_s = end_s.split("T", 1)[0]
        start_d = parse_date(start_s) if start_s else None
        end_d   = parse_date(end_s)   if end_s   else None
        if not start_d and not end_d:
            # default to today
            today = timezone.localdate()
            start = timezone.make_aware(datetime.combine(today, time.min))
            end   = timezone.make_aware(datetime.combine(today, time.max))
        else:
            start = timezone.make_aware(datetime.combine(start_d, time.min)) if start_d else None
            end   = timezone.make_aware(datetime.combine(end_d,   time.max)) if end_d   else None

    # --- Brand/model filters (top-level brands for our MES calculators) ---
    brands = [b.strip().lower() for b in data.getlist("brand") if (b or "").strip()] or None
    models = [m.strip() for m in data.getlist("model") if (m or "").strip()] or None

    # --- Line, VIN ---
    line = (data.get("line") or "").strip().lower() or None
    if line and line not in ALLOWED_LINES:
        line = None
    vin = (data.get("vin") or "").strip().upper() or None

    # --- Pagination for list endpoint ---
    try:
        per_page = int(data.get("per_page", 100))
    except Exception:
        per_page = 100
    try:
        page = max(1, int(data.get("page", 1)))
    except Exception:
        page = 1

    return {
        "start": start,
        "end": end,
        "brands": brands,
        "models": models,
        "line": line,
        "vin": vin,
        "page": page,
        "per_page": per_page,
        "raw": {"start_date": (data.get("start_date") or "").strip(), "end_date": (data.get("end_date") or "").strip()},
    }


@login_required
@require_GET
def trim_overview_api(request):
    """
    GET /api/mes/trim/overview
    Query:
      start_date=YYYY-MM-DD&amp;end_date=YYYY-MM-DD
      &brand=gwm&amp;brand=chery
      &model=Tiggo%204
      &line=gwm|chery|changan
      &vin=VIN
    Returns aggregated counts for TRIM: overall and by lines.
    """
    f = _parse_trim_filters(request)

    payload = get_trim_mes(
        start=f["start"], end=f["end"],
        line=f["line"], brands=f["brands"], models=f["models"], vin=f["vin"]
    ) or {}

    # Controls whether to include items (VIN lists) in response
    include_items = (request.GET.get("include_items") or "").strip().lower() in {"1", "true", "yes", "on"}

    overall_raw = payload.get("overall", {}) or {}
    by_line_raw = payload.get("by_line", {}) or {}

    # Normalize overall: always return counts; optionally include items
    metrics = ("trim_in", "wip_trim", "trim_out")
    overall_norm: dict = {}
    for m in metrics:
        node = overall_raw.get(m, {}) or {}
        # node may be a dict with "count"/"items" or a bare number
        if isinstance(node, dict):
            cnt = int(node.get("count", 0) or 0)
            if include_items:
                overall_norm[m] = {"count": cnt, "items": list(node.get("items", []) or [])}
            else:
                overall_norm[m] = {"count": cnt}
        else:
            # bare number fallback
            cnt = int(node or 0)
            overall_norm[m] = {"count": cnt} if not include_items else {"count": cnt, "items": []}

    # Compact per-line counts for UI (backward compatible: numbers only)
    lines = {ln: {"trim_in": 0, "wip_trim": 0, "trim_out": 0} for ln in ALLOWED_LINES}
    try:
        for ln in ALLOWED_LINES:
            lines[ln]["trim_in"]  = int(((by_line_raw.get("trim_in", {})  or {}).get(ln, {}) or {}).get("count", 0) or 0)
            lines[ln]["wip_trim"] = int(((by_line_raw.get("wip_trim", {}) or {}).get(ln, {}) or {}).get("count", 0) or 0)
            lines[ln]["trim_out"] = int(((by_line_raw.get("trim_out", {}) or {}).get(ln, {}) or {}).get("count", 0) or 0)
    except Exception:
        # fail-safe: keep zeros if structure differs
        pass

    # Optional detailed per-line VIN lists (non-breaking extra field)
    if include_items:
        lines_items = {ln: {"trim_in": [], "wip_trim": [], "trim_out": []} for ln in ALLOWED_LINES}
        try:
            for ln in ALLOWED_LINES:
                lines_items[ln]["trim_in"]  = list((((by_line_raw.get("trim_in", {})  or {}).get(ln, {}) or {}).get("items", []) or []))
                lines_items[ln]["wip_trim"] = list((((by_line_raw.get("wip_trim", {}) or {}).get(ln, {}) or {}).get("items", []) or []))
                lines_items[ln]["trim_out"] = list((((by_line_raw.get("trim_out", {}) or {}).get(ln, {}) or {}).get("items", []) or []))
        except Exception:
            pass

    resp = {
        "filters": {
            "brands": f["brands"] or [],
            "models": f["models"] or [],
            "line": f["line"] or "",
            "vin": f["vin"] or "",
            "start_date": f["raw"]["start_date"],
            "end_date": f["raw"]["end_date"],
        },
        "overall": overall_norm,
        "by_line": lines,
    }
    if include_items:
        resp["by_line_items"] = lines_items

    return JsonResponse(resp, json_dumps_params={"ensure_ascii": False})


@login_required
@require_GET
def trim_list_api(request):
    """
    GET /api/mes/trim/list
    Query:
      metric=trim_in|wip_trim|trim_out   (required)
      start_date, end_date, brand, model, line, vin
      page (default 1), per_page (default 100)
    Returns a paginated list of VIN items for the chosen metric.
    """
    metric = (request.GET.get("metric") or "").strip().lower()
    if metric not in {"trim_in", "wip_trim", "trim_out"}:
        return JsonResponse({"ok": False, "error": "metric must be trim_in|wip_trim|trim_out"}, status=400)

    f = _parse_trim_filters(request)
    payload = get_trim_mes(
        start=f["start"], end=f["end"],
        line=f["line"], brands=f["brands"], models=f["models"], vin=f["vin"]
    ) or {}

    items = list(((payload.get("overall", {}).get(metric, {}) or {}).get("items", []) or []))

    # Optional explicit line filter for UI (safe even if aggregator already handled this)
    if f["line"]:
        items = [it for it in items if (it.get("line") or "").strip().lower() == f["line"]]

    total = len(items)
    start_idx = (f["page"] - 1) * f["per_page"]
    end_idx = start_idx + f["per_page"]
    page_items = items[start_idx:end_idx]

    return JsonResponse({
        "filters": {
            "metric": metric,
            "brands": f["brands"] or [],
            "models": f["models"] or [],
            "line": f["line"] or "",
            "vin": f["vin"] or "",
            "start_date": f["raw"]["start_date"],
            "end_date": f["raw"]["end_date"],
        },
        "pagination": {"page": f["page"], "per_page": f["per_page"], "total": total},
        "items": page_items,
    }, json_dumps_params={"ensure_ascii": False})


@login_required
@permission_required('users.access_to_indicators', raise_exception=True)
def mes_metric_table_view(request):
    """
    HTML-—Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π —Ç–∞–±–ª–∏—Ü–µ–π –ø–æ MES-–º–µ—Ç—Ä–∏–∫–µ.
    –¢—è–Ω–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ /api/mes/table —Å —Ç–µ–º–∏ –∂–µ GET-–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.
    """
    section = (request.GET.get("section") or "trim").strip().lower()
    allow_line = (section == "trim")

    f = _parse_mes_filters(request, allow_line=allow_line)

    default_metric = {
        "trim": "trim_in",
        "bqa":  "bqa_in",
        "qa":   "qa_in",
        "uud":  "uud_in",
        "ves":  "ves_in",
    }.get(section, "trim_in")

    metric = (request.GET.get("metric") or default_metric).strip().lower()

    try:
        api_table_url = reverse("mes_metric_table_api")
    except Exception:
        api_table_url = "/api/mes/table"

    try:
        api_table_export_url = reverse("mes_metric_table_export")
    except Exception:
        api_table_export_url = "/api/mes/table/export"

    ctx = {
        "section": section,
        "metric": metric,
        "api_table_url": api_table_url,
        "api_table_export_url": api_table_export_url,
        "filters": {
            "start_date": f["start_date"],
            "end_date":   f["end_date"],
            "brands":     f["brands"],
            "models":     f["models"],
            "vin":        f["vin"] or "",
            "line":       f["line"] or "",
            "page":       f["page"],
            "per_page":   f["per_page"],
        },
    }
    return render(request, "users/mes/metric_table.html", ctx)









@login_required
@require_GET
def mes_metric_table_export(request):
    """
    GET /api/mes/table/export
      –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ç–µ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —á—Ç–æ –∏ /api/mes/table,
      –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç Excel (.xlsx) —Å —Ç–µ–º–∏ –∂–µ –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏ –¥–∞–Ω–Ω—ã–º–∏ (–±–µ–∑ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏).
    """
    section = (request.GET.get("section") or "trim").strip().lower()
    allow_line = (section == "trim")
    f = _parse_mes_filters(request, allow_line=allow_line)

    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å—á—ë—Ç –ø–æ —Å–µ–∫—Ü–∏–∏
    calc_map = {
        "trim": lambda: get_trim_mes(start=f["start"], end=f["end"], line=f["line"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"]),
        "bqa":  lambda: get_bqa_mes(start=f["start"], end=f["end"], line=f["line"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"]),
        "qa":   lambda: get_qa_mes(start=f["start"], end=f["end"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"]),
        "uud":  lambda: get_uud_mes(start=f["start"], end=f["end"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"]),
        "ves":  lambda: get_ves_mes(start=f["start"], end=f["end"], brands=f["brands"] or None, models=f["models"] or None, vin=f["vin"]),
    }
    if section not in calc_map:
        section = "trim"

    try:
        res = calc_map[section]() or {}
    except Exception:
        res = {}

    overall = res.get("overall", {}) or {}
    metric = (request.GET.get("metric") or "").strip().lower()
    key = _resolve_metric_key(section, metric, overall)
    if not key:
        return JsonResponse({"ok": False, "error": "unknown metric", "available": sorted(list(overall.keys()))}, status=400)

    bucket = overall.get(key, {}) or {}
    items = list(bucket.get("items", []) or [])

    # –Ø–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ª–∏–Ω–∏–∏ –¥–ª—è TRIM
    if allow_line and f["line"]:
        items = [it for it in items if (it.get("line") or "").strip().lower() == f["line"]]

    # –ö–æ–ª–æ–Ω–∫–∏ –ø–æ –ø–æ–ª–Ω–æ–º—É –Ω–∞–±–æ—Ä—É items
    columns = _infer_columns_from_items(items)

    # === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Excel ===
    from openpyxl import Workbook
    from openpyxl.utils import get_column_letter
    from openpyxl.styles import Font, Alignment as XLAlignment

    wb = Workbook()
    ws = wb.active
    ws.title = "–ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏"

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ + –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤
    title = f"–ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏ {section.upper()} ‚Äî {key}"
    ws["A1"] = title
    ws["A1"].font = Font(bold=True)
    ws.append([])  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞

    # —Å—Ç—Ä–æ–∫–∞ —Å –ø–µ—Ä–∏–æ–¥–æ–º/—Ñ–∏–ª—å—Ç—Ä–∞–º–∏ (–≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã)
    meta = f"–ü–µ—Ä–∏–æ–¥: {f['start_date']} ‚Ä¶ {f['end_date']}"
    if f["brands"]:
        meta += f" | –ë—Ä–µ–Ω–¥—ã: {', '.join(f['brands'])}"
    if f["models"]:
        meta += f" | –ú–æ–¥–µ–ª–∏: {', '.join(f['models'])}"
    if f["vin"]:
        meta += f" | VIN: {f['vin']}"
    if allow_line and f["line"]:
        meta += f" | –õ–∏–Ω–∏—è: {f['line']}"
    ws.append([meta])
    ws.append([])

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
    header_row = [c.get("title") or c.get("key") for c in columns]
    ws.append(header_row)
    for i in range(1, len(header_row) + 1):
        cell = ws.cell(row=ws.max_row, column=i)
        cell.font = Font(bold=True)
        cell.alignment = XLAlignment(horizontal="center")

    # –î–∞–Ω–Ω—ã–µ
    keys = [c["key"] for c in columns]
    for it in items:
        row = []
        for k in keys:
            v = it.get(k, "")
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–∫–∏/—Å–ª–æ–∂–Ω—ã–µ —Ç–∏–ø—ã –≤ —Å—Ç—Ä–æ–∫—É
            if isinstance(v, (list, tuple, set)):
                v = ", ".join(str(x) for x in v)
            elif isinstance(v, dict):
                v = str(v)
            row.append(v if v is not None else "")
        ws.append(row)

    # –ê–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ –≤ –∫–æ–ª–æ–Ω–∫–µ (–æ–≥—Ä–∞–Ω–∏—á–∏–º 60 —Å–∏–º–≤–æ–ª–∞–º–∏)
    for idx, _ in enumerate(header_row, start=1):
        max_len = max((len(str(ws.cell(row=r, column=idx).value or "")) for r in range(1, ws.max_row + 1)), default=10)
        ws.column_dimensions[get_column_letter(idx)].width = min(max(10, max_len + 2), 60)

    # –û—Ç–≤–µ—Ç
    from django.http import HttpResponse
    filename = f"mes_{section}_{key}_{f['start_date']}_{f['end_date']}.xlsx".replace("..", ".").replace("/", "-")
    response = HttpResponse(content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    response["Content-Disposition"] = f'attachment; filename="{filename}"'
    wb.save(response)
    return response








# UUD SHUCKRAT

from supplies.models import TraceData
from vehicle_history.models import VINHistory
from django.db.models import Q
from io import BytesIO
from openpyxl import Workbook
from openpyxl.utils import get_column_letter
from openpyxl.styles import Font, Alignment
from django.utils import timezone as dj_tz
from openpyxl.styles import Alignment, Font, PatternFill




@login_required
@permission_required('users.access_to_the_uud_table', raise_exception=True)
def uud_report(request):
    """
    –í–∫–ª–∞–¥–∫–∏ —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è –ø–æ steps –ü–û–°–õ–ï–î–ù–ï–ô —Å–µ—Å—Å–∏–∏:
      - step1 (–û—Ç–¥–∞–ª–∏ –Ω–∞ –£–£–î) ‚Äî –±–µ–∑ —É—á—ë—Ç–∞ –ø–µ—Ä–∏–æ–¥–∞ (–≤—Å–µ –∑–∞—Å—Ç—Ä—è–≤—à–∏–µ –Ω–∞ step1)
      - step2/step3/done ‚Äî –ø–æ —Å–≤–æ–∏–º *_at –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ.
    defects_by_vin —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –¥–µ—Ñ–µ–∫—Ç—ã –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –¥–∞—Ç–∞–º –∏ —Ç–µ–ø–µ—Ä—å –≤–∫–ª—é—á–∞–µ—Ç 'comment'
    (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: comment ‚Üí custom_defect_explanation ‚Üí custom_detail_explanation).
    """
    UUD_ZONE = "–£–£–î"
    UUD_POST = "–£–£–î"

    def _parse_dt(dt_str):
        if not dt_str:
            return None
        try:
            s = str(dt_str).replace("Z", "+00:00")
            dt = datetime.fromisoformat(s)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt
        except Exception:
            return None

    def _date_or_none(dt):
        try:
            return dt.date()
        except Exception:
            return None

    def _brand_model(vin: str):
        if not vin:
            return "", ""
        t = (TraceData.objects
             .filter(Q(vin_rk__iexact=vin) | Q(vin_c__iexact=vin))
             .order_by("-date_added")
             .only("brand", "model")
             .first())
        return ((t.brand or "") if t else "", (t.model or "") if t else "")

    def _safe_entry_index(s: dict) -> int:
        idx = s.get("entry_index")
        if isinstance(idx, int):
            return idx
        sid = s.get("id") or ""
        try:
            tail = str(sid).rsplit("-", 1)[-1]
            return int(tail)
        except Exception:
            return 0

    def _last_session(sessions: list) -> dict | None:
        if not sessions:
            return None

        def keyer(s):
            return (_safe_entry_index(s),
                    _parse_dt(s.get("created_at")) or datetime.min.replace(tzinfo=timezone.utc))
        return max((s for s in sessions if isinstance(s, dict)), key=keyer, default=None)

    def _comment_from_defect(d: dict) -> str:
        """comment ‚Üí custom_defect_explanation ‚Üí custom_detail_explanation (–µ—Å–ª–∏ –æ–±–µ –∫–∞—Å—Ç–æ–º–Ω—ã–µ –µ—Å—Ç—å ‚Äî –±–µ—Ä—ë–º custom_defect_explanation)"""
        if not isinstance(d, dict):
            return ""
        comment = (d.get("comment") or "").strip()
        if comment:
            return comment
        c_def = (d.get("custom_defect_explanation") or "").strip()
        c_det = (d.get("custom_detail_explanation") or "").strip()
        if c_def and c_det:
            return c_def
        return c_def or c_det or ""

    def _iter_defects_from_history(history: dict):
        """
        yield dict(zone, post, status, detail, defect, grade, date, time, by, comment)
        - –°–±–æ—Ä–∫–∞:  detail <- unit,  defect <- name
        - –ü–æ—Å—Ç–∞–≤–∫–∏: detail <- detail, defect <- defect
        - status –∏–∑ extra.UUD.status (–µ—Å–ª–∏ –µ—Å—Ç—å)
        - comment –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: comment ‚Üí custom_defect_explanation ‚Üí custom_detail_explanation
        - date/time/by –∏–∑ entry.date_added / entry.controller
        """
        if not isinstance(history, dict):
            return

        # --- –¶–µ—Ö —Å–±–æ—Ä–∫–∏
        assembly = history.get("–¶–µ—Ö —Å–±–æ—Ä–∫–∏") or {}
        if isinstance(assembly, str):
            try:
                assembly = json.loads(assembly)
            except Exception:
                assembly = {}
        if isinstance(assembly, dict):
            for post_name, entries in assembly.items():
                if not isinstance(entries, list):
                    continue
                for entry in entries:
                    controller = (entry.get("controller") or "").strip()
                    dt = _parse_dt(entry.get("date_added"))
                    for d in (entry.get("defects") or []):
                        extra = d.get("extra") or {}
                        uud = extra.get("UUD") or {}
                        yield {
                            "zone":   "–¶–µ—Ö —Å–±–æ—Ä–∫–∏",
                            "post":   post_name,
                            "status": (uud.get("status") or "").strip(),
                            "detail": (d.get("unit") or "").strip(),
                            "defect": (d.get("name") or "").strip(),
                            "grade":  (d.get("grade") or "").strip(),
                            "date":   (dt.date().isoformat() if dt else ""),
                            "time":   (dt.strftime("%H:%M") if dt else ""),
                            "by":     controller,
                            "comment": _comment_from_defect(d),
                        }

        # --- –¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏
        supplies = history.get("–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏") or {}
        if isinstance(supplies, str):
            try:
                supplies = json.loads(supplies)
            except Exception:
                supplies = {}
        if isinstance(supplies, dict):
            for post_name, entries in supplies.items():
                if not isinstance(entries, list):
                    continue
                for entry in entries:
                    controller = (entry.get("controller") or "").strip()
                    dt = _parse_dt(entry.get("date_added"))
                    for d in (entry.get("defects") or []):
                        extra = d.get("extra") or {}
                        uud = extra.get("UUD") or {}
                        yield {
                            "zone":   "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏",
                            "post":   post_name,
                            "status": (uud.get("status") or "").strip(),
                            "detail": (d.get("detail") or "").strip(),
                            "defect": (d.get("defect") or "").strip(),
                            "grade":  (d.get("grade") or "").strip(),
                            "date":   (dt.date().isoformat() if dt else ""),
                            "time":   (dt.strftime("%H:%M") if dt else ""),
                            "by":     controller,
                            "comment": _comment_from_defect(d),
                        }

    # ---- –ø–µ—Ä–∏–æ–¥ (–¥–ª—è step2/3/4 –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞; step1 –µ–≥–æ –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç) ----
    q_date  = (request.GET.get("date")  or "").strip()
    q_start = (request.GET.get("start") or "").strip()
    q_end   = (request.GET.get("end")   or "").strip()

    if q_start and q_end:
        try:
            start_date = datetime.strptime(q_start, "%Y-%m-%d").date()
            end_date   = datetime.strptime(q_end,   "%Y-%m-%d").date()
            if end_date < start_date:
                start_date, end_date = end_date, start_date
        except ValueError:
            start_date = end_date = timezone.now().date()
        date_label = f"{start_date.isoformat()} ‚Ä¶ {end_date.isoformat()}"
    else:
        if q_date:
            try:
                start_date = end_date = datetime.strptime(q_date, "%Y-%m-%d").date()
            except ValueError:
                start_date = end_date = timezone.now().date()
        else:
            start_date = end_date = timezone.now().date()
        date_label = start_date.isoformat()

    def _in_range(dt):
        d = _date_or_none(dt)
        return (dt and d and start_date <= d <= end_date)

    # ---- —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ----
    rows1, rows2, rows3, rows4 = [], [], [], []
    active_now = 0
    defects_by_vin = {}

    for vh in VINHistory.objects.only("vin", "history"):
        vin = (vh.vin or "").strip().upper()
        if not vin:
            continue

        history = vh.history or {}
        if isinstance(history, str):
            try:
                history = json.loads(history)
            except Exception:
                continue

        # –≤—Å–µ –¥–µ—Ñ–µ–∫—Ç—ã (–±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –¥–∞—Ç), —Ç–µ–ø–µ—Ä—å —Å comment
        vin_defects = list(_iter_defects_from_history(history))
        vin_defects.sort(key=lambda r: (r["date"], r["time"]), reverse=True)
        defects_by_vin[vin] = vin_defects

        # –ø–æ—Å–ª–µ–¥–Ω—è—è —Å–µ—Å—Å–∏—è –£–£–î
        zone = history.get(UUD_ZONE) or {}
        if isinstance(zone, str):
            try:
                zone = json.loads(zone)
            except Exception:
                zone = {}
        sessions = zone.get(UUD_POST) or []
        if not isinstance(sessions, list) or not sessions:
            continue

        if any((s.get("steps") or "").strip().lower() != "done" for s in sessions if isinstance(s, dict)):
            active_now += 1

        last = _last_session(sessions)
        if not last:
            continue

        extra = last.get("extra_data") or {}
        steps_raw = (last.get("steps") or "").strip().lower()
        brand, model = _brand_model(vin)

        t1 = _parse_dt(extra.get("step1_at"))
        t2 = _parse_dt(extra.get("step2_at"))
        t3 = _parse_dt(extra.get("step3_at"))
        t4 = _parse_dt(extra.get("step4_at"))

        if steps_raw == "step1":
            rows1.append({
                "vin": vin, "brand": brand, "model": model,
                "date": t1.date().isoformat() if t1 else "",
                "time": t1.strftime("%H:%M") if t1 else "",
                "by":   (extra.get("step1_by") or "").strip(),
            })
        elif steps_raw == "step2" and _in_range(t2):
            rows2.append({
                "vin": vin, "brand": brand, "model": model,
                "date": t2.date().isoformat() if t2 else "",
                "time": t2.strftime("%H:%M") if t2 else "",
                "by":   (extra.get("step2_by") or "").strip(),
            })
        elif steps_raw == "step3" and _in_range(t3):
            rows3.append({
                "vin": vin, "brand": brand, "model": model,
                "date": t3.date().isoformat() if t3 else "",
                "time": t3.strftime("%H:%M") if t3 else "",
                "by":   (extra.get("step3_by") or "").strip(),
            })
        elif steps_raw in ("done", "step4") and _in_range(t4):
            rows4.append({
                "vin": vin, "brand": brand, "model": model,
                "date": t4.date().isoformat() if t4 else "",
                "time": t4.strftime("%H:%M") if t4 else "",
                "by":   (extra.get("step4_by") or "").strip(),
            })

    # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
    for rows in (rows1, rows2, rows3, rows4):
        rows.sort(key=lambda r: (r["date"], r["time"]), reverse=True)

    payload = {
        "date_local": date_label,
        "start_date": start_date.isoformat(),
        "end_date": end_date.isoformat(),
        "step1_rows": rows1, "step1_count": len(rows1),
        "step2_rows": rows2, "step2_count": len(rows2),
        "step3_rows": rows3, "step3_count": len(rows3),
        "step4_rows": rows4, "step4_count": len(rows4),
        "active_now": active_now,
        "defects_by_vin": defects_by_vin,  # –≤–∫–ª—é—á–∞–µ—Ç comment
    }

    wants_json = (request.headers.get("X-Requested-With") == "XMLHttpRequest"
                  or request.GET.get("format") == "json")
    if wants_json:
        return JsonResponse(payload, status=200, safe=False)
    return render(request, "users/uud/uud_report.html", payload)


@login_required
@permission_required('users.access_to_the_uud_table', raise_exception=True)
def uud_report_export(request):
    """
    –≠–∫—Å–ø–æ—Ä—Ç Excel:
      - ¬´–û–∂–∏–¥–∞—é—Ç —Ä–µ–º–æ–Ω—Ç–∞¬ª (step1) ‚Äî –±–µ–∑ –ø–µ—Ä–∏–æ–¥–∞ (–≤—Å–µ –∑–∞—Å—Ç—Ä—è–≤—à–∏–µ –Ω–∞ step1 –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ—Å—Å–∏–∏)
      - ¬´–£–£–î –Ω–∞—á–∞–ª–∞ —Ä–µ–º–æ–Ω—Ç¬ª (step2), ¬´–ñ–¥—ë—Ç –ø—Ä–∏—ë–º–∞ –Ω–∞ –ª–∏–Ω–∏—é¬ª (step3), ¬´–õ–∏–Ω–∏—è –ø—Ä–∏–Ω—è–ª–∞¬ª (done) ‚Äî –ø–æ —Å–≤–æ–µ–º—É *_at –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ.
      - –ö–æ–ª–æ–Ω–∫–∞ ¬´–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π¬ª –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É: comment ‚Üí custom_defect_explanation ‚Üí custom_detail_explanation.
      - –£—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã: VIN (q), –ë—Ä–µ–Ω–¥ (brand[]), –ú–æ–¥–µ–ª—å (model[]).
    """
    UUD_ZONE = "–£–£–î"
    UUD_POST = "–£–£–î"

    # ---------- helpers ----------
    def _parse_dt(dt_str):
        if not dt_str:
            return None
        try:
            s = str(dt_str).replace("Z", "+00:00")
            dt = datetime.fromisoformat(s)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=dj_tz.utc)
            return dt
        except Exception:
            return None

    def _date_or_none(dt):
        try:
            return dt.date()
        except Exception:
            return None

    def _brand_model(vin):
        if not vin:
            return "", ""
        t = (TraceData.objects
             .filter(Q(vin_rk__iexact=vin) | Q(vin_c__iexact=vin))
             .order_by("-date_added")
             .only("brand", "model")
             .first())
        return ((t.brand or "") if t else "", (t.model or "") if t else "")

    def _safe_entry_index(s: dict) -> int:
        idx = s.get("entry_index")
        if isinstance(idx, int):
            return idx
        sid = s.get("id") or ""
        try:
            tail = str(sid).rsplit("-", 1)[-1]
            return int(tail)
        except Exception:
            return 0

    def _last_session(sessions: list) -> dict | None:
        def keyer(s):
            return (_safe_entry_index(s),
                    _parse_dt(s.get("created_at")) or datetime.min.replace(tzinfo=dj_tz.utc))
        return max((s for s in sessions if isinstance(s, dict)), key=keyer, default=None)

    def _comment_from_defect(d: dict) -> str:
        comment = (d.get("comment") or "").strip()
        if comment:
            return comment
        c_def = (d.get("custom_defect_explanation") or "").strip()
        c_det = (d.get("custom_detail_explanation") or "").strip()
        if c_def and c_det:
            return c_def
        return c_def or c_det or ""

    # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–µ—Ñ–µ–∫—Ç—ã (–≤–∫–ª—é—á–∞—è comment)
    def _iter_defects_from_history(history: dict):
        if not isinstance(history, dict):
            return

        # –¶–µ—Ö —Å–±–æ—Ä–∫–∏
        assembly = history.get("–¶–µ—Ö —Å–±–æ—Ä–∫–∏") or {}
        if isinstance(assembly, str):
            try:
                assembly = json.loads(assembly)
            except Exception:
                assembly = {}
        if isinstance(assembly, dict):
            for post_name, entries in assembly.items():
                if not isinstance(entries, list):
                    continue
                for entry in entries:
                    controller = (entry.get("controller") or "").strip()
                    dt = _parse_dt(entry.get("date_added"))
                    for d in (entry.get("defects") or []):
                        extra = d.get("extra") or {}
                        uud = extra.get("UUD") or {}
                        yield {
                            "zone": "–¶–µ—Ö —Å–±–æ—Ä–∫–∏",
                            "post": post_name,
                            "status": (uud.get("status") or "").strip(),
                            "detail": (d.get("unit") or "").strip(),
                            "defect": (d.get("name") or "").strip(),
                            "grade":  (d.get("grade") or "").strip(),
                            "date":   (dt.date().isoformat() if dt else ""),
                            "time":   (dt.strftime("%H:%M") if dt else ""),
                            "by":     controller,
                            "comment": _comment_from_defect(d),
                        }

        # –¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏
        supplies = history.get("–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏") or {}
        if isinstance(supplies, str):
            try:
                supplies = json.loads(supplies)
            except Exception:
                supplies = {}
        if isinstance(supplies, dict):
            for post_name, entries in supplies.items():
                if not isinstance(entries, list):
                    continue
                for entry in entries:
                    controller = (entry.get("controller") or "").strip()
                    dt = _parse_dt(entry.get("date_added"))
                    for d in (entry.get("defects") or []):
                        extra = d.get("extra") or {}
                        uud = extra.get("UUD") or {}
                        yield {
                            "zone": "–¶–µ—Ö –ø–æ—Å—Ç–∞–≤–∫–∏",
                            "post": post_name,
                            "status": (uud.get("status") or "").strip(),
                            "detail": (d.get("detail") or "").strip(),
                            "defect": (d.get("defect") or "").strip(),
                            "grade":  (d.get("grade") or "").strip(),
                            "date":   (dt.date().isoformat() if dt else ""),
                            "time":   (dt.strftime("%H:%M") if dt else ""),
                            "by":     controller,
                            "comment": _comment_from_defect(d),
                        }

    # ---------- —Ñ–∏–ª—å—Ç—Ä—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ ----------
    q = (request.GET.get("q") or "").strip().upper()

    # –ø–æ–¥–¥–µ—Ä–∂–∏–º –∏ brand=... –∏ brand[]=...
    def _get_multi(name: str):
        vals = request.GET.getlist(name)
        if not vals:
            vals = request.GET.getlist(f"{name}[]")
        # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∫–∞–∫ –≤–∞–ª–∏–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        return [ (v or "").strip() for v in vals if v is not None ]

    brands_raw = _get_multi("brand")
    models_raw = _get_multi("model")

    brands_set = set(brands_raw) if brands_raw else None
    models_set = set(models_raw) if models_raw else None

    # ---------- –ø–µ—Ä–∏–æ–¥ ----------
    q_date  = (request.GET.get("date")  or "").strip()
    q_start = (request.GET.get("start") or "").strip()
    q_end   = (request.GET.get("end")   or "").strip()

    if q_start and q_end:
        try:
            start_date = datetime.strptime(q_start, "%Y-%m-%d").date()
            end_date   = datetime.strptime(q_end,   "%Y-%m-%d").date()
            if end_date < start_date:
                start_date, end_date = end_date, start_date
        except ValueError:
            start_date = end_date = dj_tz.now().date()
        date_label = f"{start_date.isoformat()} ‚Ä¶ {end_date.isoformat()}"
        filename_suffix = f"{start_date.isoformat()}_{end_date.isoformat()}"
    else:
        if q_date:
            try:
                start_date = end_date = datetime.strptime(q_date, "%Y-%m-%d").date()
            except ValueError:
                start_date = end_date = dj_tz.now().date()
        else:
            start_date = end_date = dj_tz.now().date()
        date_label = start_date.isoformat()
        filename_suffix = start_date.isoformat()

    # —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ª–∏—Å—Ç–æ–≤: (vin, brand, model, date, time, by, defects_list)
    sheets_data = {"step1": [], "step2": [], "step3": [], "done": []}

    def _in_range(dt):
        d = _date_or_none(dt)
        return (dt and d and start_date <= d <= end_date)

    # ---------- —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö ----------
    for vh in VINHistory.objects.only("vin", "history"):
        vin = (vh.vin or "").strip().upper()
        if not vin:
            continue

        history = vh.history or {}
        if isinstance(history, str):
            try:
                history = json.loads(history)
            except Exception:
                continue

        defects = list(_iter_defects_from_history(history))
        defects.sort(key=lambda r: (r["date"], r["time"]), reverse=True)

        zone = history.get(UUD_ZONE) or {}
        if isinstance(zone, str):
            try:
                zone = json.loads(zone)
            except Exception:
                zone = {}
        sessions = zone.get(UUD_POST) or []
        if not isinstance(sessions, list) or not sessions:
            continue

        last = _last_session(sessions)
        if not last:
            continue

        extra = last.get("extra_data") or {}
        steps_raw = (last.get("steps") or "").strip().lower()
        brand, model = _brand_model(vin)

        t1 = _parse_dt(extra.get("step1_at"))
        t2 = _parse_dt(extra.get("step2_at"))
        t3 = _parse_dt(extra.get("step3_at"))
        t4 = _parse_dt(extra.get("step4_at"))

        row1 = (vin, brand, model, t1.date().isoformat() if t1 else "", t1.strftime("%H:%M") if t1 else "",
                (extra.get("step1_by") or "").strip(), defects)
        row2 = (vin, brand, model, t2.date().isoformat() if t2 else "", t2.strftime("%H:%M") if t2 else "",
                (extra.get("step2_by") or "").strip(), defects)
        row3 = (vin, brand, model, t3.date().isoformat() if t3 else "", t3.strftime("%H:%M") if t3 else "",
                (extra.get("step3_by") or "").strip(), defects)
        row4 = (vin, brand, model, t4.date().isoformat() if t4 else "", t4.strftime("%H:%M") if t4 else "",
                (extra.get("step4_by") or "").strip(), defects)

        if steps_raw == "step1":
            sheets_data["step1"].append(row1)
        elif steps_raw == "step2" and _in_range(t2):
            sheets_data["step2"].append(row2)
        elif steps_raw == "step3" and _in_range(t3):
            sheets_data["step3"].append(row3)
        elif steps_raw in ("done", "step4") and _in_range(t4):
            sheets_data["done"].append(row4)

    for k in sheets_data:
        sheets_data[k].sort(key=lambda r: (r[3], r[4]), reverse=True)

    # ---------- –æ–±—â–∏–π –ø—Ä–µ–¥–∏–∫–∞—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (VIN/–ë—Ä–µ–Ω–¥/–ú–æ–¥–µ–ª—å) ----------
    def _row_passes_filters(row):
        # row = (vin, brand, model, date, time, by, defects)
        vin_val   = (row[0] or "").upper()
        brand_val = row[1] or ""
        model_val = row[2] or ""
        if q and q not in vin_val:
            return False
        if brands_set is not None and brand_val not in brands_set:
            return False
        if models_set is not None and model_val not in models_set:
            return False
        return True

    # –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –î–û –∑–∞–ø–∏—Å–∏ –Ω–∞ –ª–∏—Å—Ç—ã
    for key in ("step1", "step2", "step3", "done"):
        sheets_data[key] = [r for r in sheets_data[key] if _row_passes_filters(r)]

    # ---------- workbook ----------
    wb = Workbook()
    ws_step1 = wb.active
    ws_step1.title = "–û–∂–∏–¥–∞—é—Ç —Ä–µ–º–æ–Ω—Ç–∞"
    ws_step2 = wb.create_sheet("–£–£–î –Ω–∞—á–∞–ª–∞ —Ä–µ–º–æ–Ω—Ç")
    ws_step3 = wb.create_sheet("–ñ–¥—ë—Ç –ø—Ä–∏—ë–º–∞ –Ω–∞ –ª–∏–Ω–∏—é")
    ws_done  = wb.create_sheet("–õ–∏–Ω–∏—è –ø—Ä–∏–Ω—è–ª–∞")

    STATUS_MAP = {
        "impossible":   ("–ù–µ–≤–æ–∑–º–æ–∂–Ω–æ",   "000000", "FFFFFF"),
        "resolved":     ("–£—Å—Ç—Ä–∞–Ω–µ–Ω–æ",    "198754", "FFFFFF"),
        "not_resolved": ("–ù–µ —É—Å—Ç—Ä–∞–Ω–µ–Ω–æ", "DC3545", "FFFFFF"),
        "checking":     ("–ü—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è",  "FFC107", "000000"),
        "":             ("‚Äî",            "E9ECEF", "6C757D"),
        None:           ("‚Äî",            "E9ECEF", "6C757D"),
    }

    def _write_sheet(ws, data_rows):
        # –ü–µ—Ä–∏–æ–¥ –Ω–∞ –≤—Å—é —à–∏—Ä–∏–Ω—É (1..10), —Å—á—ë—Ç—á–∏–∫ –≤ –∫–æ–ª. 11
        ws.merge_cells(start_row=1, start_column=1, end_row=1, end_column=10)
        c = ws.cell(row=1, column=1, value=f"–ü–µ—Ä–∏–æ–¥: {date_label}")
        c.font = Font(bold=True)
        c.alignment = Alignment(horizontal="center")
        ws.cell(row=1, column=11, value=f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(data_rows)}").font = Font(bold=True)

        headers = [
            "VIN", "–ë—Ä–µ–Ω–¥", "–ú–æ–¥–µ–ª—å", "–î–∞—Ç–∞ (–£–£–î)", "–í—Ä–µ–º—è (–£–£–î)", "–ö–æ–Ω—Ç—Ä–æ–ª–µ—Ä (–£–£–î)",
            "–°—Ç–∞—Ç—É—Å –¥–µ—Ñ–µ–∫—Ç–∞", "–î–µ—Ç–∞–ª—å", "–î–µ—Ñ–µ–∫—Ç", "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π"
        ]
        ws.append(headers)

        cur = 3
        for vin, brand, model, date_s, time_s, by, defects in data_rows:
            dlist = defects if defects else [None]
            group_len = max(1, len(dlist))
            start_row = cur

            for i, d in enumerate(dlist):
                row = [
                    vin   if i == 0 else "",
                    brand if i == 0 else "",
                    model if i == 0 else "",
                    date_s if i == 0 else "",
                    time_s if i == 0 else "",
                    by if i == 0 else "",
                ]

                if d:
                    status_raw = (d.get("status") or "").strip() or ""
                    title, bg, fg = STATUS_MAP.get(status_raw, STATUS_MAP[""])
                    detail = d.get("detail") or "‚Äî"
                    defect = d.get("defect") or "‚Äî"
                    comment = d.get("comment") or "‚Äî"
                else:
                    title, bg, fg = STATUS_MAP[""]
                    detail = "‚Äî"; defect = "‚Äî"; comment = "‚Äî"

                row.extend([title, detail, defect, comment])
                ws.append(row)

                # –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
                status_cell = ws.cell(row=cur, column=7)
                status_cell.fill = PatternFill(start_color=bg, end_color=bg, fill_type="solid")
                status_cell.font = Font(color=fg, bold=True)
                status_cell.alignment = Alignment(horizontal="center")

                # –ø–µ—Ä–µ–Ω–æ—Å –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
                ws.cell(row=cur, column=10).alignment = Alignment(wrap_text=True, vertical="top")

                cur += 1

            # merge –ø–µ—Ä–≤—ã—Ö 6 –∫–æ–ª–æ–Ω–æ–∫ (VIN..–ö–æ–Ω—Ç—Ä–æ–ª–µ—Ä) –Ω–∞ –¥–ª–∏–Ω—É –≥—Ä—É–ø–ø—ã
            if group_len > 1:
                for col in range(1, 7):
                    ws.merge_cells(start_row=start_row, start_column=col,
                                   end_row=start_row + group_len - 1, end_column=col)
                    top_cell = ws.cell(row=start_row, column=col)
                    top_cell.alignment = Alignment(horizontal="center", vertical="center")

        # –∞–≤—Ç–æ—à–∏—Ä–∏–Ω–∞
        for col_cells in ws.columns:
            col_idx = col_cells[0].column
            letter = get_column_letter(col_idx)
            max_len = 0
            for c in col_cells:
                if c.value is not None:
                    max_len = max(max_len, len(str(c.value)))
            ws.column_dimensions[letter].width = min(max_len + 2, 60)

        # –ø—Ä–∏–º–µ—á–∞–Ω–∏–µ (1..10)
        note_row = ws.max_row + 2
        ws.merge_cells(start_row=note_row, start_column=1, end_row=note_row, end_column=10)
        nc = ws.cell(row=note_row, column=1, value=(
            "–î–∞–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–∞ —Ç–æ–ª—å–∫–æ –Ω–∞ –º–æ–º–µ–Ω—Ç —Å–∫–∞—á–∏–≤–∞–Ω–∏—è ‚Äî "
            f"{dj_tz.localtime(dj_tz.now()).strftime('%Y-%m-%d %H:%M')}"
        ))
        nc.font = Font(italic=True, color="6C757D")
        nc.alignment = Alignment(horizontal="left", vertical="center")

    _write_sheet(ws_step1, sheets_data["step1"])
    _write_sheet(ws_step2, sheets_data["step2"])
    _write_sheet(ws_step3, sheets_data["step3"])
    _write_sheet(ws_done,  sheets_data["done"])

    bio = BytesIO()
    wb.save(bio)
    bio.seek(0)
    resp = HttpResponse(
        bio.getvalue(),
        content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )
    resp["Content-Disposition"] = f'attachment; filename="uud_report_{filename_suffix}.xlsx"'
    return resp





